{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology - Project\n",
    "Authors: CÃ©cile MACAIRE & Ludivine ROBERT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from lexicon\n",
    "def read_data(file):\n",
    "    \"\"\"Read data file with pandas dataframe\"\"\"\n",
    "    return pd.read_csv(file, sep='\\t')\n",
    "\n",
    "def lemma_lexicon(dataframe):\n",
    "    \"\"\"Lemmatization of lexicon with scapy\"\"\"\n",
    "    terms = dataframe['pilot']\n",
    "    lemma = []\n",
    "    for el in terms:\n",
    "        doc = spacy_nlp(el.lower())\n",
    "        tmp = [token.lemma_ for token in doc]\n",
    "        lemma.append(' '.join(tmp))\n",
    "    dataframe['lemma'].replace(lemma)\n",
    "    return dataframe\n",
    "  \n",
    "def select_data(dataframe):\n",
    "    \"\"\"We keep only columns pattern, pilot and lemma\"\"\"\n",
    "    return dataframe[['pattern', 'pilot', 'lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text\n",
    "def read_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return f.read()\n",
    "        \n",
    "def lemma_posttag(file):\n",
    "    \"\"\"Convert post-tag scapy into corresponding pattern from lexicon\"\"\"\n",
    "    text = read_file(file)\n",
    "    doc_a = spacy_nlp(text)\n",
    "    doc = spacy_nlp(text.lower())\n",
    "    new_pos = []\n",
    "    pos = []\n",
    "    lemma = []\n",
    "    t = []\n",
    "    original = [token.text for token in doc_a]\n",
    "    for token in doc:\n",
    "        t.append(token.text)\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        if token.pos_ == 'NOUN' or token.pos_ == 'PROPN':\n",
    "            new_pos.append('N')\n",
    "        elif token.pos_ == 'VERB':\n",
    "            new_pos.append('V')\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            new_pos.append('A')\n",
    "        elif token.pos_ == 'CCONJ' or token.pos_ == 'SCONJ':\n",
    "            new_pos.append('C')\n",
    "        elif token.pos_ == 'PART' or token.pos_ == 'ADP':\n",
    "            new_pos.append('P')\n",
    "        else:\n",
    "            new_pos.append('')\n",
    "    frame = pd.DataFrame({'tokens': original,'tokens_lower':t, 'lemma':lemma, 'pos':pos, 'pattern':new_pos})\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Define rules from terms according to their pattern\"\"\"\n",
    "    new_terms = []\n",
    "    for terms in terms_dataframe['lemma']:\n",
    "        # Get the same structure of terms as in text dataframe\n",
    "        tmp = ' '.join(terms.split('-'))\n",
    "        new_terms.append(tmp.split(' '))\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for j, t in enumerate(new_terms):\n",
    "            # Case 1: term of size 3 seperated by dashes (ex: text-to-speech) and followed by 1 or 2 Nouns is a term \n",
    "            if len(t) == 3 and len(text_dataframe['lemma']) >= i+3:\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == 'to' or text_dataframe['lemma'][i+2] == 'of' and text_dataframe['lemma'][i+3] == '-' and text_dataframe['lemma'][i+4] == t[2]:\n",
    "                    # followed by 2 nouns (ex: text-to-speech modal synthesis)\n",
    "                    if text_dataframe['pattern'][i+5] == 'N':\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    else:\n",
    "                        # followed by 1 noun (ex: text-to-speech system)\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']' \n",
    "            # Case 2: term of size 2 separated by dashes (ex: encoder-decoder) and followed by 0,1,2 or 3 nouns is a term\n",
    "            elif len(t) >= 2 and len(text_dataframe['lemma']) >= i+3 and i != 0:\n",
    "                if token == 'front' and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == 'end':\n",
    "                    if text_dataframe['pattern'][i-1] == 'N':\n",
    "                        text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                if token == t[0] and text_dataframe['lemma'][i+1] == '-' and text_dataframe['lemma'][i+2] == t[1]:\n",
    "                    # followed by 3 nouns (ex: HMM-based generation synthesis approach)\n",
    "                    if len(t) == 5:\n",
    "                        if text_dataframe['pattern'][i+3] == 'N' and text_dataframe['pattern'][i+4] == 'N' and text_dataframe['pattern'][i+5] == 'N':\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+5] = text_dataframe['tokens'][i+5]+']'\n",
    "                    # followed by 2 nouns (ex: HMM-based generation synthesis)\n",
    "                    elif len(t) == 4:\n",
    "                        if text_dataframe['pattern'][i+3] == 'N' and text_dataframe['pattern'][i+4] == 'N':\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+4] = text_dataframe['tokens'][i+4]+']'\n",
    "                    # followed by 1 noun (ex: cross-lingual adaptation)\n",
    "                    elif len(t) == 3:\n",
    "                        if text_dataframe['pattern'][i+3] == 'N':\n",
    "                            text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                            text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                    # followed by nothing (ex: mel-spectrogram)\n",
    "                    elif len(t) == 2:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "        if token == 'data' or token == 'datum' or token == 'speaker' or token == 'dataset' or token == 'database' or token == 'feature' or token == 'corpus' or token == 'language' and i != 0 and len(text_dataframe['lemma']) >= i+1:\n",
    "            if text_dataframe['pattern'][i-1] == 'N' or text_dataframe['pattern'][i-1] == 'A':\n",
    "                text_dataframe['tokens'][i-1] = '['+text_dataframe['tokens'][i-1]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif text_dataframe['pattern'][i+1] == 'N':\n",
    "                text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_4 = ['system', 'model', 'synthesis', 'translation', 'recognition', 'signal', 'research', 'processing']\n",
    "def annotate(terms_dataframe, text_dataframe):\n",
    "    \"\"\"Annotate the terms of the text thanks to list of terms + applied rules\"\"\"\n",
    "    rules(terms_dataframe, text_dataframe)  # apply rules\n",
    "    for i, token in enumerate(text_dataframe['lemma']):\n",
    "        for term in terms_dataframe['lemma']:\n",
    "            term = term.split(' ')\n",
    "            # Case 1: if terms of length 4, we check if each word from text corresponds to each word in the term\n",
    "            if len(term) == 4:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) > i+4:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2] and text_dataframe['lemma'][i+3] == term[3]:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+3] = text_dataframe['tokens'][i+3]+']'\n",
    "                        i += 3\n",
    "            # Case 2: terms of length 3\n",
    "            elif len(term) == 3:\n",
    "                term_1 = term[0]\n",
    "                if token == term_1 and len(text_dataframe['lemma']) > i+3:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1] and text_dataframe['lemma'][i+2] == term[2]:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+2] = text_dataframe['tokens'][i+2]+']'\n",
    "                        i += 2\n",
    "            # Case 3: terms of length 2\n",
    "            elif len(term) == 2:\n",
    "                if token == term[0] and len(text_dataframe['lemma']) > i+2:\n",
    "                    if text_dataframe['lemma'][i+1] == term[1]:\n",
    "                        text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                        text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "                        i += 1\n",
    "            # Case 4: term of length 1\n",
    "            elif token == term[0] and i > 1 and text_dataframe['lemma'][i-1] == 'of' and text_dataframe['lemma'][i-2] == 'sequence':\n",
    "                text_dataframe['tokens'][i-2] = '['+text_dataframe['tokens'][i-2]\n",
    "                text_dataframe['tokens'][i] = text_dataframe['tokens'][i]+']'\n",
    "            elif token == term[0] and len(term) == 1 and len(text_dataframe['lemma']) >= i+1:\n",
    "                if text_dataframe['lemma'][i+1] in rule_4:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]\n",
    "                    text_dataframe['tokens'][i+1] = text_dataframe['tokens'][i+1]+']'\n",
    "                else:\n",
    "                    text_dataframe['tokens'][i] = '['+text_dataframe['tokens'][i]+']'\n",
    "    return text_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_annotated_text(text_dataframe):\n",
    "    \"\"\"Return the text from the annotated text dataframe with the correct annotation of brackets\"\"\"\n",
    "    content = ' '.join(text_dataframe['tokens'].to_list())\n",
    "    compt = 0\n",
    "    compt2 = 0\n",
    "    string = ''\n",
    "    for i in content:\n",
    "        if i == '[':\n",
    "            if compt == 0:\n",
    "                compt += 1\n",
    "                string += i\n",
    "            elif compt >= 1:\n",
    "                compt += 1\n",
    "        elif i == ']':\n",
    "            if compt-1 != compt2:\n",
    "                compt2 += 1\n",
    "            else:\n",
    "                string += i\n",
    "                compt = 0\n",
    "                compt2 = 0\n",
    "        else:\n",
    "            string += i\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tokens  tokens_lower         lemma    pos pattern\n",
      "0        [TUNDRA]        tundra        tundra  PROPN       N\n",
      "1               :             :             :  PUNCT        \n",
      "2               A             a             a    DET        \n",
      "3   [Multilingual  multilingual  multilingual    ADJ       A\n",
      "4       [Corpus]]        corpus        corpus   NOUN       N\n",
      "5              of            of            of    ADP       P\n",
      "6           Found         found          find   VERB       V\n",
      "7          [Data]          data         datum   NOUN       N\n",
      "8             for           for           for    ADP       P\n",
      "9            [TTS           tts           tts  PROPN       N\n",
      "10      Research]      research      research  PROPN       N\n",
      "11        Created       created        create   VERB       V\n",
      "12           with          with          with    ADP       P\n",
      "13         [Light         light         light    ADJ       A\n",
      "14   Supervision]   supervision   supervision   NOUN       N\n",
      "15           \\n\\n          \\n\\n          \\n\\n  SPACE        \n",
      "16         [[Text          text          text   NOUN       N\n",
      "17              -             -             -  PUNCT        \n",
      "18             to            to            to    ADP       P\n",
      "19              -             -             -  PUNCT        \n",
      "20     [Speech]]]        speech        speech   NOUN       N\n",
      "21           \\n\\n          \\n\\n          \\n\\n  SPACE        \n",
      "22       Abstract      abstract      abstract    ADJ       A\n",
      "23             \\n            \\n            \\n  SPACE        \n",
      "24   [Simple4All]    simple4all    simple4all  PROPN       N\n",
      "25       [Tundra]        tundra        tundra  PROPN       N\n",
      "26              (             (             (  PUNCT        \n",
      "27        version       version       version   NOUN       N\n",
      "28            1.0           1.0           1.0    NUM        \n",
      "29              )             )             )  PUNCT        \n",
      "30             is            is            be    AUX        \n",
      "31            the           the           the    DET        \n",
      "32          first         first         first    ADJ       A\n",
      "33        release       release       release   NOUN       N\n",
      "34             of            of            of    ADP       P\n",
      "35              a             a             a    DET        \n",
      "36   standardised  standardised  standardised    ADJ       A\n",
      "37  [multilingual  multilingual  multilingual    ADJ       A\n",
      "38      [corpus]]        corpus        corpus   NOUN       N\n",
      "39       designed      designed        design   VERB       V\n",
      "40            for           for           for    ADP       P\n",
      "41         [[text          text          text   NOUN       N\n",
      "42              -             -             -  PUNCT        \n",
      "43             to            to            to    ADP       P\n",
      "44              -             -             -  PUNCT        \n",
      "45        [speech        speech        speech   NOUN       N\n",
      "46    research]]]      research      research   NOUN       N\n",
      "47           with          with          with    ADP       P\n",
      "48      imperfect     imperfect     imperfect   NOUN       N\n",
      "49             or            or            or  CCONJ       C\n",
      "[TUNDRA] : A [Multilingual Corpus] of Found [Data] for [TTS Research] Created with [Light Supervision] \n",
      "\n",
      " [Text - to - Speech] \n",
      "\n",
      " Abstract        \n",
      " [Simple4All] [Tundra] ( version 1.0 ) is the first release of a standardised [multilingual corpus] designed for [text - to - speech research] with imperfect or found [data] . \n",
      " The [corpus] consists of approximately 60 hours of [speech data] from audiobooks in 14 [languages] , as well as utterance - level alignments obtained with a lightly - supervised process . \n",
      " Future versions of the [corpus] will include finer - grained alignment and prosodic annotation , all of which will be made freely available . \n",
      " This paper gives a general outline of the [data] collected so far , as well as a detailed description of how this has been done , emphasizing the [minimal language] - specific knowledge and manual intervention used to compile the [corpus] . \n",
      " To demonstrate its potential use , [text - to - speech systems] have been built for all [languages] using unsupervised or lightly supervised methods , also briefly presented in the paper . \n",
      " Index Terms : [multilingual corpus] , [light supervision] , [imperfect data] , found [data] , [text - to - speech] , [audiobook data] \n",
      "\n",
      " Introduction \n",
      " Building a [text - to - speech] ( [TTS] ) conversion system for a [new language] has in the past been an expensive and time - consuming activity . \n",
      " Using data - driven methods to build , for example , a statistical parametric [waveform] generation module or [TTS] back - end , can alleviate to some extent the lack of expert linguistic knowledge . \n",
      " Even then , however , a recording script must be prepared , a voice talent recruited and high - quality [speech] recording carefully supervised . \n",
      " Also problematic is the text - processing component of the system , i.e. the [TTS front - end] , if none is available for the [target language] . \n",
      " A front - end is made up of rule - based or statistical modules ; acquiring the [expert knowledge] required either to manually specify those rules , or to annotate a learning [sample] on which to train the statistical [models] , represents a major obstacle to creating a [TTS system] for a new [target language] and requires highly specialised knowledge . \n",
      " Such non - trivial tasks include , for example , specifying a [phoneme] - set or part of [speech] ( POS ) tag - set for a [language] where one has not already been defined ; annotating plain text with POS tags , as required to train a POS tagger and annotating the surface forms of words with [phonemes] to build a [pronunciation] [lexicon] . \n",
      " One of the primary goals of the project Simple4All1 is to produce freely available tools for building [TTS systems] with little or no expert supervision from freely available existing [data] . \n",
      " These tools enable us to sidestep the expense associated with engineering a [speech corpus] in each new [target language] from scratch , in the case where data is not readily available . \n",
      " Our toolkit includes modules for handling imperfect recording conditions , segmenting [audio] into manageable chunks , and aligning those chunks with a chapter or book - level text transcription . \n",
      " We here explain how these tools have been applied to existing [audiobook data] in 14 [languages] , most of it freely available , to create a [multilingual corpus] with minimal manual intervention and [language] - specific [expert knowledge] . \n",
      " The result of this processing is a standardised [multilingual database] of â found â [data] , which we release under the name [Tundra] . \n",
      " There has been much recent interest in in using found [data] to produce [TTS systems] , in particular , [speech data] from audiobook recordings . \n",
      " We note that the [Arctic databases] have provided a valuable resource for research into [TTS] using conventional purpose - recorded [databases] , in that they are freely available and serve as a common point of reference for benchmarking . \n",
      " In view of this significant and growing interest in building [TTS systems] from found [data] , we feel there is a need for a similarly standardised and freely - [available corpus] of found [data] . We present [Tundra] to the [TTS] researchommunity in the hope that it can start to fill that need . \n",
      " Our toolkit also includes modules for selecting a subset of utterances with a uniform speaking style , and constructing [TTS systems] from text and [speech data] without reliance on [language] - specific [expert knowledge] or on conventional linguistic resources such as [lexicons] , phonesets , [part - of - speech taggersetc] . \n",
      " In order to show that it is feasible to build voices on corpora built with such minimal expert supervision , we also present a demonstration of [TTS systems] that we have built by applying these tools to [Tundra] . \n",
      " We do not present detailed explanation , evaluation and analysis of these demo systems here due to space limitations , and refer interested readers to , where such details will be given . \n",
      " An initial public version of the [Simple4All] tools used to compile the [corpus] and build the demo voices is due to be released in November 2013 . \n",
      "\n",
      " www.simple4all.org/    \n",
      "\n",
      " [Corpus Construction] \n",
      " In this section we describe the pipeline of [data processing] involved in building the [Tundra corpus] , from [speech] denoisingand deverberation to lightly supervised [speech] and text alignment . \n",
      " All the steps presented in the following subsections are based solely on found [speech] and text resources and could be easily applied to any other resource , even by non - expert users . \n",
      " As regards [language dependency] , the only step which requires familiarity with at least the script of the [target language] is the first step of matching 10 minutes of [speech] with an orthographic transcript . \n",
      " All the other processes can be performed by the users with little or no training in [speech processing] and without relying on any [target language] knowledge . \n",
      "\n",
      " [Speech] Pre - processing \n",
      " Conventional [TTS] corpora deliver [speech] recorded in noise - free non - reverberant environments , and thus lead to high - quality [synthetic speech] . \n",
      " Found [data] , on the other hand are usually recorded in sub - optimal conditions , and without professional recording equipment . \n",
      " Therefore , when building [TTS systems] on this type of [data] , some pre - processing steps are in order . \n",
      " For [Tundra] , recordings which casual listening suggested were sub - optimal went through the following pre - processing steps , applied to each recording session individually,2 so that variations in between them can be normalised : \n",
      " Noise reduction : uses a multi - band noise gate removal with a 20dB noise reduction threshold , a [frequency] smoothing of 150 Hz and 0.15 second decay time . \n",
      " The noise profile was selected from the initial silence segments of each [speech] file . \n",
      " Normalisation : DC offset was removed , and the recordings were normalised to a maximum amplitude of -0.1 dB , so that the average energy level is the same across different recording sessions . \n",
      " Deverberation : was performed using a RMS based algorithm , with a smoothing of 40 ms and a release of 400ms . \n",
      "\n",
      " Lightly - supervised [Audio] Segmentation \n",
      " Current parametric [TTS systems] generally use [training data] which is segmented into sentence - length chunks , and rarely make use of contexts beyond the current sentence . \n",
      " The small length of the [training data] is also a limitation of the forced alignment algorithm while training . \n",
      " Although several algorithms have been proposed to enable the use of longer [speech] segments , we still consider that sentence - length utterances are the building blocks of [TTS] , and longer segments can be easily obtained by concatenating the former , thus ensuring a paragraph or maybe chapter level analysis or training . \n",
      " presents a lightly supervised method for the segmentation of [speech] into sentences . The method uses a small amount of manually [labelled] [data] , in which the silence between sentences is marked for around 5 to 10 minutes of [speech] . \n",
      " Silence marking is a trivial task and requires no technical knowledge . \n",
      " Using the initial [training data] , standard Gaussian mixture [models] ( GMMs ) with 16 components are trained for [speech] and silence respectively . \n",
      " The observation [vectors] consist of energy , 12 dimensional MFCCs , their [delta features] , and the number of zero crossings in a frame . \n",
      " The distinction between [speech] and silence is made by calculating the [log likelihood] ratio ( LLR ) of each frame . \n",
      " The framewise LLR is smoothed using a moving median filter . \n",
      " While doing sentence level segmentation , an important aspect is to discriminate between within - sentence breaks , and [sentence boundary] breaks . \n",
      " Therefore , the trained GMMs likelihood scores are evaluated on the [training data] , and the durations of the [sentence boundary] silence segments and the durations of within - sentence silence segments are computed . \n",
      " Two Gaussian PDFs are then fitted to the two [model] durations . \n",
      " The intersection point of the two PDFs is used as a duration threshold to classify silent segments as either sentence - internal or [sentence boundary] breaks . \n",
      " Results presented in showed that this method when applied to an English audiobook , successfully identified most of the [sentence boundaries] . \n",
      " We also evaluate it in this paper by comparing [speech] - based segmentation results against the text based ones . \n",
      "\n",
      " Audiobooks are usually distributed in chapter - size chunks which correspond to one recording session . \n",
      "\n",
      " Lightly - supervised [Speech] and Text Alignment \n",
      " In   we first introduced a method for the automatic alignment of [speech data] with unsynchronised , imperfect transcripts , for a domain where no initial [acoustic models] are available . \n",
      " As opposed to , where existing high - quality [acoustic] and [language models] are used , our method requires only relatively low - quality [grapheme] - based [acoustic models] trained solely on the [speech] resource to be aligned . \n",
      " To overcome the lack of good [acoustic models] , the [ASR] decoding network is limited to a sequence of words derived from the approximate transcript , similar to . \n",
      " This sequence is called a skip network . \n",
      " The confidence of the alignment is ranked based on the [acoustic] scores obtained in the decoding process with different degrees of freedom included in the skip network . \n",
      " Manual intervention is limited to matching the first 10 minutes of [speech] with the correct text transcription , to provide [data] for training the initial [acoustic models] , similar to . \n",
      " This [feature] makes the method easily applicable in any [language] employing an alphabetic writing system , and enables the use of found [data] without the hassle of manually transcribing its entirety . \n",
      " Initial results on the English audiobook A Tramp Abroad by Mark Twain3 showed an average 55 % [confident data] , with a WER of 1 % and SER of 8 % . \n",
      " Since then , the [acoustic model] training has been extended to tri - [grapheme] and lightly supervised discriminative training , which led to an average of75 % [confident data] with similar word and sentence error rates . \n",
      " One major [loss] in sentence accuracy rates is due to utterance initial and final word deletions and insertions , which can not be correctly detected by the current confidence measure . However , previous studies showed that phone errors less than 1 % do not degrade the quality of the [synthetic speech] . \n",
      " The output of the alignment process is a set of segmented [speech] files with their corresponding orthographic transcripts , including punctuation , and also a time alignment of the segments within the initial [speech data] . \n",
      "\n",
      " The [Corpus] \n",
      " The procedures described above have been applied to a number of freely available found resources . \n",
      " Audiobooks were a first choice , as they are a readily available in [multiple languages] and are generally read by a [single speaker] and recorded with equipment of at least reasonable quality . \n",
      " Another advantage would be that by using cohesive and expressive [spoken data] as the basis for training a [TTS system] might yield more cohesive and expressive multi - utterance [TTS] output , fact which explains the high interest in them lately . \n",
      " This latter advantage is not especially made use of in the demo voices presented here , but is the subject of on - going work for us elsewhere . \n",
      " To emphasise the utility of audiobooks in [TTS] systems , in Fig .   we present a comparison between standard [TTS] corpora and audiobooks with respect to logF0 in 4 [different languages] . \n",
      " The standard [TTS] corpora are : a subset of the [database] called â Nina â in , a subset of a [corpus] of Finnish [speech] recorded from a [female speaker] specifically for [TTS] purposes , SEV neutral [ 19 ] and RSS [ 20 ] . \n",
      "\n",
      " http://librivox.org/a-tramp-abroad-by-mark-twain/ \n",
      "\n",
      "\n",
      " Table : [Simple4All] [Tundra Corpus overview] \n",
      "\n",
      " Figure : logF0 comparison of conventional [TTS] corpora versus [audiobook data] in four [languages] : English ( EN ) , Spanish ( ES ) , Finnish ( FI ) and Romanian ( RM ) . \n",
      " A denotes the [audiobook data] , and S denotes the standard [TTS database] . \n",
      " The standard [corpora speaker] genders are the same as the selected audiobooks . \n",
      "\n",
      " Figure : logF0 boxplots for all [languages] . [Language codes] are given in Table \n",
      "\n",
      " It can be easily observed that the audiobooks have a greater standard deviation compared with conventional corpora , which means that they could easily provide a much richer prosodic context . \n",
      " This aspect can also be noticed from Fig . where logF0 distributions are plotted for all the [languages] of the [corpus] . \n",
      " As a result , [Tundra] 1.0 includes 14 audiobooks in 14 [languages] : Bulgarian , Danish , Dutch , English , Finnish , French , German , Hungarian , Italian , Polish , Portuguese , Romanian , Russian and Spanish . \n",
      " [Language selection] was based on the availability of both [speech] and [text data] , as well as the [language] having an alphabetic writing system ( in this case , Latin and Cyrillic alphabets ) . \n",
      " Important resources for these are the Librivox and Gutenberg4 projects , which are the sources for most of the [data] used to compile [Tundra] . \n",
      " The complete list [speech] and text sources can be found here http://tundra.simple4all.org/. \n",
      "\n",
      " http://librivox.org and http://gutenberg.org/ \n",
      "\n",
      " Table presents an overview of the [entire corpus] , including title and author of the audiobook , [speaker gender] and total duration . \n",
      " There are 8 male and 6 [female speakers] , and the aligned [corpus] amounts to approximately 60 hours of [speech] . \n",
      " For the final set of utterances included in this [corpus] , each audiobook underwent the steps described in the Section and which are schematically depicted in Fig . \n",
      " Audiobook chapters were converted from mp3 to wav format and then cleaned if the overall quality was considered low . \n",
      " The first 10 minutes of [speech] were then annotated with silence segments and manually transcribed . \n",
      " Manual transcription proved to be a trivial task , and based on the book text , the authors were able to perform it , although they do not speak most of the [languages] included in the [corpus] . \n",
      " For the Cyrillic writing [system languages] ( i.e. Bulgarian and Russian ) , [native speakers] were asked to correct an initial transcription provided by the authors . \n",
      " [Data] was then segmented using the VAD algorithm , and the resulting number of [speech] utterances is presented in Table alongside the text - based segmentation . \n",
      "\n",
      " For example , the Spanish and [Romanian data] are professional recordings which did not require any pre - processing . \n",
      " We currently decide whether to pre - process recordings based on informal listening , but aim to automate this with an objective measure of [speech quality] in future versions of our toolkit .               \n",
      "\n",
      " The difference between the number of VAD and text utterances results from the writing style of the book ( i.e. mostly dialogue , or mostly descriptive ) and the fact that in the alignment process , in order to obtain the [most data] from the audiobook , segmented utterances which are shorter than a specified threshold ( 5 seconds for these [data] ) are concatenated . \n",
      " After the alignment process , an average of 68 % of the [data] were considered confident and included in the [final corpus] . \n",
      " Table   presents the duration of the aligned [data] and its percentage from the total duration . This percentage appears to be highly dependent on : \n",
      " a ) the total [amount of data] available : see the low percentage of the Danish audiobook which has only 2.1 hours ; \n",
      " b ) [speaker gender] : female voices seem to have a lower alignment percentage ; \n",
      " c ) [grapheme] - to - [phoneme language] complexity : see English and French versus Italian and German ; \n",
      " and d ) [speaker characteristics] : speaking rhythm , degree of expresivity , as well as general voice quality also affect the results . \n",
      " SER and WER values for the aligned audiobooks could not be exactly determined , as this would have required their full manual transcription , which is outside the scope of this [corpus building] procedure . \n",
      " However , one chapter from each audiobook in the [languages] spoken by the authors was evaluated , and the errors tend to be similar to those in , meaning a less than 1 % WER and a 8 % SER . \n",
      " Higher error rates were reported for the noisier [speech data] ( see Table for general signal - to - noise ratios ) . \n",
      " To be useful as a standardised [TTS corpus] , [Tundra] is also partitioned into training and [test sets] . \n",
      " To ensure a satisfactory amount of [testing data] even for the shortest audiobook , the [test data] were selected from the final chapters / parts of the audiobooks , so that they amount to at least 10 % of the aligned duration of it . \n",
      " The entire segmented and [aligned corpus] , along with the chapter - wise time alignment and training / [test set] division of can be downloaded from http://tundra.simple4all.org \n",
      "\n",
      " Spanish and Romanian also have very simple G2P rules , but the [speakers] â greater expressivity limits the alignner âs performance . \n",
      " This being a subjective measure , we encourage readers to listen to [samples] of the audiobooks . \n",
      "         \n",
      " Figure : Outline of [corpus construction] and voice building \n",
      "\n",
      " Demo \n",
      " To show the feasibility of using a [corpus] that has been compiled with such minimal intervention and [language] - specific expertise , we have used it to build demo [TTS] voices in the corpuslanguages . \n",
      " To build these voices we first select a subset of utterances spoken in a homogenous style using a slightly supervised active learning - based approach . \n",
      " We then employ a toolkit which has been specifically designed to construct [TTS front - ends] while making as few implicit assumptions about the [target language] as possible , and to be configurable with minimal effort and [expert knowledge] to suit arbitrary new [target languages] . \n",
      " The modules of our toolkit therefore rely where possible on resources which are intended to be universal . \n",
      " For example , to tokenise [input text] we rely on character properties given in the Unicode [character database] â a regular expression defined over these properties has so far produced sensible tokenisations in a variety of alphabetic ( Latin - based , Cyrillic ) and alphasyllabic ( Brahmic ) scripts . ) \n",
      " A [letter] - based approach is used , in which the names of [letters] are used directly as the names of [speech] modelling units ( in place of the [phonemes] of a conventional front - end ) . \n",
      " This has given good results for [languages] with transparent alphabetic orthographies such as Romanian , Spanish and Finnish , and can give acceptable results even for [languages] with less transparent orthographies , such as English . \n",
      " Furthermore , our tools make no use of expert - specified categories of [letter] and word , such as [phonetic] categories ( vowel , nasal , approximant , etc . ) and part of [speech] categories ( noun , verb , adjective , etc . ) . \n",
      " Instead , we use [features] that are designed to stand in for such [expert knowledge] but which are derived fully automatically from the distributional analysis of plain text in the [target language] . \n",
      " [Samples] of the voices can be heard at http://tundra.simple4all.org/demo/. \n",
      " For reasons of space we refer readers interested in full presentation and evaluation of thesesystems to . \n",
      "\n",
      " Conclusion \n",
      " We have introduced a first version of the [Simple4All] [Tundra corpus] , and described its construction from readily available [speech data] . \n",
      " 14 audiobooks in 14 [languages] have been so far included in the [corpus] along with their orthographic transcripts . \n",
      " [Tundra] will be extended in the future with other types of imperfect , found [data] , such as lectures , or parliamentary [speech] , [data] which have a higher degree of spontaneity and expressivity . \n",
      " We will also aim at making available finer - grained alignments of the [data] , and also more elaborate prosodic annotations , such as style diarisation , emphasis or sentiment analysis . \n",
      " The [TTS systems] built from this [corpus] demonstrate a first application of   the [Tundra corpus] , and support its usefulness . \n",
      "\n",
      " Acknowledgements \n",
      " The research leading to these results has received funding from the European Community âs Seventh Framework Programme ( FP7/2007 - 2013 ) under grant agreement No 287678 . \n",
      " The research presented here has made use of the resources provided by the Edinburgh Compute and [Data Facility] ( ECDF : http://www.ecdf.ed.ac.uk ) . \n",
      " The ECDF is partially supported by the eDIKT initiative ( http://www.edikt.org.uk ) . \n",
      " We would like to thank Mihai Nae from Cartea Sonora for releasing the [Romanian data] , as well as to all the volunteers at Librivox and Gutenberg for dedicating their time to distribute this wide variety of [data] . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    \"\"\"Main -> to modify by putting all steps in one fonction\"\"\"\n",
    "    init_data = read_data('tts-lexicon3.tsv')\n",
    "    change_lemma = lemma_lexicon(init_data)\n",
    "    data = select_data(change_lemma)\n",
    "    text_dataframe = lemma_posttag('test.txt')\n",
    "    annotate(data, text_dataframe)\n",
    "    print(text_dataframe.head(50))\n",
    "#     print(' '.join(text_dataframe['tokens'].to_list()))\n",
    "    print(construct_annotated_text(text_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
