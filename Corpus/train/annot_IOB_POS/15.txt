Learning VERB (O) to ADP (O) Speak VERB (O) Fluently ADV (O) in ADP (O) a NOUN (O) Foreign PROPN (O) Language NOUN (O) : [Multilingual ADJ (B) Speech NOUN (I) Synthesis PROPN (I)] and CCONJ (O) [Cross PROPN - Language PROPN (B) Voice PROPN (I)] Cloning VERB (O) 

 Abstract PROPN (O) 

 We PRON (O) present NOUN (O) a NOUN (O) multispeaker NOUN , (O) [multilingual ADJ (B) text NOUN - to ADP - speech NOUN (I) (TTS PROPN) (I) synthesis NOUN (I) model NOUN (I)] based VERB (O) on ADP (O) [Tacotron PROPN (B)] that DET (O) is AUX (O) able ADJ (O) to ADP (O) produce NOUN (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] in ADP (O) multiple NOUN (O) languages NOUN . (O) 
Moreover ADV , (O) the DET (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) transfer NOUN (O) voices NOUN (O) across ADP (O) languages NOUN , (O) e.g. ADV (O) synthesize VERB (O) fluent ADJ (O) Spanish PROPN (O) [speech NOUN (B)] using VERB (O) an DET (O) [English PROPN (B) speaker NOUN (I)] ’s PART voice NOUN , (O) without ADP (O) training NOUN (O) on ADP (O) any DET (O) bilingual ADJ (O) or CCONJ (O) parallel NOUN (O) examples NOUN . (O) 
Such ADJ (O) transfer NOUN (O) works VERB (O) across ADP (O) distantly ADV (O) related ADJ (O) languages NOUN , (O) e.g. ADV (O) English PROPN (O) and CCONJ (O) Mandarin PROPN . (O) 
Critical PROPN (O) to ADP (O) achieving VERB (O) this DET (O) result NOUN (O) are AUX (O) : 1 X . (O) using VERB (O) a NOUN (O) [phonemic NOUN (B) input NOUN (I) representation NOUN (I)] to PART (O) encourage VERB (O) sharing NOUN (O) of ADP (O) model NOUN (O) capacity NOUN (O) across ADP (O) languages NOUN , (O) and CCONJ (O) 2 NUM . (O) incorporating VERB (O) an DET (O) [adversarial ADJ (B) loss NOUN (I)] term NOUN (O) to ADP (O) encourage VERB (O) the DET (O) model NOUN (O) to ADP (O) disentangle NOUN (O) its DET (O) representation NOUN (O) of ADP (O) [speaker NOUN (B) identity NOUN (I)] (which DET (O) is AUX (O) perfectly ADV (O) correlated VERB (O) with ADP (O) language NOUN (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)]) from ADP (O) the DET (O) [speech NOUN (B) content NOUN (I)] . 
Further ADV (O) scaling VERB (O) up NOUN (O) the DET (O) model NOUN (O) by ADP (O) training NOUN (O) on ADP (O) [multiple NOUN (B) speakers NOUN (I)] of ADP (O) each DET (O) language NOUN , (O) and CCONJ (O) incorporating NOUN (O) an DET (O) autoencoding NOUN (O) input NOUN (O) to ADP (O) help NOUN (O) stabilize VERB (O) attention NOUN (O) during ADP (O) training NOUN , (O) results VERB (O) in ADP (O) a NOUN (O) model NOUN (O) which DET (O) can VERB (O) be AUX (O) used VERB (O) to ADP (O) consistently ADV (O) synthesize VERB (O) [intelligible ADJ (B) speech NOUN (I)] for ADP (O) [training NOUN (B) speakers NOUN (I)] in ADP (O) all DET (O) languages NOUN (O) seen VERB (O) during ADP (O) training NOUN , (O) and CCONJ (O) in ADP (O) native NOUN (O) or CCONJ (O) foreign ADJ (O) accents NOUN . (O) 
Index NOUN (O) Terms NOUN (O) : [speech NOUN (B) synthesis NOUN (I)] , [end NOUN - to ADP - end NOUN (B)] , [adversarial ADJ (B) loss NOUN (I)] 

 Introduction NOUN (O) 

 Recent ADJ (O) [end NOUN - to ADP - end NOUN (B) neural NOUN (I) TTS PROPN (I) models NOUN (I)] have AUX (O) been AUX (O) extended ADJ (O) to ADP (O) enable NOUN (O) control NOUN (O) of ADP (O) [speaker NOUN (B) identity NOUN (I)] as SCONJ (O) well INTJ (O) as SCONJ (O) [unlabelled ADJ (B) speech NOUN (I) attributes VERB (I)] , e.g. ADV (O) [prosody NOUN (B)] , by ADP (O) conditioning NOUN (O) synthesis NOUN (O) on ADP (O) latent NOUN (O) representations NOUN (O) in ADP (O) addition NOUN (O) to ADP (O) text NOUN . (O) 
Extending VERB (O) such ADJ (O) models NOUN (O) to ADP (O) support NOUN (O) multiple NOUN , (O) unrelated ADJ (O) languages NOUN (O) is AUX (O) nontrivial NOUN (O) when ADV (O) using VERB (O) [language NOUN - dependent ADJ (B) input NOUN (I) representations NOUN (I)] or CCONJ (O) model NOUN (O) components NOUN , (O) especially ADV (O) when ADV (O) the DET (O) amount NOUN (O) of ADP (O) [training NOUN (B) data NOUN (I)] per ADP (O) language NOUN (O) is AUX (O) imbalanced VERB . (O) 
For ADP (O) example NOUN , (O) there PRON (O) is AUX (O) no DET (O) overlap NOUN (O) in ADP (O) the DET (O) text NOUN (O) representation NOUN (O) between ADP (O) languages NOUN (O) like INTJ (O) Mandarin PROPN (O) and CCONJ (O) English PROPN . (O) 
Furthermore ADV , (O) recordings VERB (O) from ADP (O) [bilingual PROPN (B) speakers NOUN (I)] are AUX (O) expensive ADJ (O) to ADP (O) collect VERB . (O) 
It PRON (O) is AUX (O) therefore ADV (O) most ADJ (O) common ADJ (O) for ADP (O) each DET (O) speaker NOUN (O) in ADP (O) the DET (O) training NOUN (O) set NOUN (O) to ADP (O) speak VERB (O) only ADV (O) one NUM (O) language NOUN , (O) so CCONJ (O) [speaker NOUN (B) identity NOUN (I)] is AUX (O) perfectly ADV (O) correlated VERB (O) with ADP (O) language NOUN . (O) 
This DET (O) makes VERB (O) it PRON (O) difficult ADJ (O) to ADP (O) transfer NOUN (O) voices NOUN (O) across ADP (O) different ADJ (O) languages NOUN , (O) a NOUN (O) [desirable ADJ (B) feature NOUN (I)] when ADV (O) the DET (O) number NOUN (O) of ADP (O) available ADJ (O) [training NOUN (B) voices NOUN (I)] for ADP (O) a NOUN (O) particular ADJ (O) language NOUN (O) is AUX (O) small ADJ . (O) 
Moreover ADV , (O) for ADP (O) languages NOUN (O) with ADP (O) borrowed VERB (O) or CCONJ (O) shared VERB (O) words NOUN , (O) such ADJ (O) as SCONJ (O) proper NOUN (O) nouns NOUN (O) in ADP (O) Spanish PROPN (O) (ES PROPN) (O) and CCONJ (O) English PROPN (O) (EN PROPN) , (O) pronunciations NOUN (O) of ADP (O) the DET (O) same ADJ (O) text NOUN (O) might VERB (O) be AUX (O) different ADJ . (O) 
This DET (O) adds VERB (O) more ADJ (O) ambiguity NOUN (O) when ADV (O) a NOUN (O) naively ADV (O) trained VERB (O) model NOUN (O) sometimes ADV (O) generates VERB (O) [accented ADJ (B) speech NOUN (I)] for ADP (O) a NOUN (O) [particular ADJ (B) speaker NOUN (I)] . 
Zen PROPN (O) et NOUN (O) al PROPN . (O) proposed VERB (O) a NOUN (O) speaker NOUN (O) and CCONJ (O) language NOUN (O) factorization NOUN (O) for ADP (O) [HMM PROPN - based VERB (B) parametric NOUN (I) TTS PROPN (I) system NOUN (I)] , aiming VERB (O) to ADP (O) transfer NOUN (O) a NOUN (O) voice NOUN (O) from ADP (O) one NUM (O) language NOUN (O) to ADP (O) others NOUN . (O) 
proposed VERB (O) a NOUN (O) multilingual ADJ (O) parametric NOUN (O) [neural NOUN (B) TTS PROPN (I) system NOUN (I)] , which DET (O) used VERB (O) a NOUN (O) unified ADJ (O) [input NOUN (B) representation NOUN (I)] and CCONJ (O) shared VERB (O) parameters NOUN (O) across ADP (O) languages NOUN , (O) however ADV (O) the DET (O) voices NOUN (O) used VERB (O) for ADP (O) each DET (O) language NOUN (O) were AUX (O) disjoint NOUN . (O) 
described VERB (O) a NOUN (O) similar ADJ (O) bilingual ADJ (O) Chinese PROPN (O) and CCONJ (O) English PROPN (O) [neural NOUN (B) TTS PROPN (I) system NOUN (I)] trained VERB (O) on ADP (O) [speech NOUN (B)] from ADP (O) a NOUN (O) [bilingual PROPN (B) speaker NOUN (I)] , allowing VERB (O) it PRON (O) to ADP (O) [synthesize VERB (B) speech NOUN (I)] in ADP (O) both DET (O) languages NOUN (O) using VERB (O) the DET (O) [same ADJ (B) voice NOUN (I)] . 
studied VERB (O) learning NOUN (O) pronunciation NOUN (O) from ADP (O) a NOUN (O) [bilingual PROPN (B) TTS PROPN (I) model NOUN (I)] . 
Most ADJ (O) recently ADV , (O) presented VERB (O) a NOUN (O) [multilingual ADJ (B) neural NOUN (I) TTS PROPN (I) model NOUN (I)] which DET (O) supports VERB (O) voice NOUN (O) cloning VERB (O) across ADP (O) English PROPN , (O) Spanish PROPN , (O) and CCONJ (O) German ADJ . (O) 
It PRON (O) used VERB (O) [language NOUN - specific ADJ (B) text NOUN (I)] and CCONJ (O) [speaker NOUN (B) encoders NOUN (I)] , and CCONJ (O) incorporated ADJ (O) a NOUN (O) secondary ADJ (O) fine ADV - tuning NOUN (O) step NOUN (O) to ADP (O) optimize NOUN (O) a NOUN (O) [speaker NOUN (B) identity NOUN - preserving NOUN (I) loss NOUN (I)] , ensuring VERB (O) that DET (O) the DET (O) model NOUN (O) could VERB (O) output NOUN (O) a NOUN (O) [consistent ADJ (B) voice NOUN (I)] regardless ADV (O) of ADP (O) language NOUN . (O) 
We PRON (O) also ADV (O) note NOUN (O) that SCONJ (O) the DET (O) sound NOUN (O) quality NOUN (O) is AUX (O) not PART (O) on ADP (O) par NOUN (O) with ADP (O) recent ADJ (O) [neural NOUN (B) TTS PROPN (I) systems NOUN (I)] , potentially ADV (O) because SCONJ (O) of ADP (O) its DET (O) use NOUN (O) of ADP (O) the DET (O) [WORLD NOUN (B) vocoder NOUN (I)] for ADP (O) [waveform PROPN (B) synthesis NOUN (I)] . 
Our DET (O) work NOUN (O) is AUX (O) most ADJ (O) similar ADJ (O) to PART , (O) which DET (O) describes VERB (O) a NOUN (O) [multilingual ADJ (B) TTS PROPN (I) model NOUN (I)] based VERB (O) on ADP (O) [Tacotron PROPN (B) 2 NUM (I)] which DET (O) uses VERB (O) a NOUN (O) Unicode PROPN (O) encoding NOUN (O) “ PUNCT (O) [byte NOUN (B)] ” PUNCT (O) [input NOUN (B) representation NOUN (I)] to PART (O) train NOUN (O) a NOUN (O) model NOUN (O) on ADP (O) one NUM (O) speaker NOUN (O) of ADP (O) each DET (O) of ADP (O) English PROPN , (O) Spanish PROPN , (O) and CCONJ (O) Mandarin PROPN . (O) 
In ADP (O) this DET (O) paper NOUN , (O) we PRON (O) evaluate VERB (O) different ADJ (O) [input NOUN (B) representations NOUN (I)] , scale NOUN (O) up NOUN (O) the DET (O) number NOUN (O) of ADP (O) [training NOUN (B) speakers NOUN (I)] for ADP (O) each DET (O) language NOUN , (O) and CCONJ (O) extend VERB (O) the DET (O) model NOUN (O) to ADP (O) support NOUN (O) [cross ADJ - lingual ADJ (B) voice NOUN (I)] cloning VERB . (O) 
The DET (O) model NOUN (O) is AUX (O) trained VERB (O) in ADP (O) a NOUN (O) single ADJ (O) stage NOUN , (O) with ADP (O) no DET (O) [language NOUN - specific ADJ (B) components NOUN (I)] , and CCONJ (O) obtains NOUN (O) naturalness NOUN (O) on ADP (O) par NOUN (O) with ADP (O) baseline NOUN (O) monolingual NOUN (O) models NOUN . (O) 
Our DET (O) contributions NOUN (O) include VERB (O) : (1 X) (O) Evaluating VERB (O) the DET (O) effect NOUN (O) of ADP (O) using VERB (O) different ADJ (O) text NOUN (O) [input NOUN (B) representations NOUN (I)] in ADP (O) a NOUN (O) [multilingual ADJ (B) TTS PROPN (I) model NOUN (I)] . 
(2 X) (O) Introducing NOUN (O) a NOUN (O) per ADP - input NOUN (O) [token NOUN (B) speaker NOUN - adversarial ADJ (I) loss NOUN (I)] to PART (O) enable NOUN (O) [cross ADJ - lingual ADJ (B) voice NOUN (I) transfer NOUN (I)] when ADV (O) only ADV (O) one NUM (O) [training NOUN (B) speaker NOUN (I)] is AUX (O) available ADJ (O) for ADP (O) each DET (O) language NOUN . (O) 
(3 X) (O) Incorporating NOUN (O) an DET (O) explicit NOUN (O) [language NOUN (B) embedding NOUN (I)] to PART (O) the DET (O) input NOUN , (O) which DET (O) enables VERB (O) moderate ADJ (O) control NOUN (O) of ADP (O) [speech NOUN (B) accent NOUN (I)] , independent ADJ (O) of ADP (O) [speaker NOUN (B) identity NOUN (I)] , when ADV (O) the DET (O) [training NOUN (B) data NOUN (I)] contains VERB (O) [multiple NOUN (B) speakers NOUN (I)] per ADP (O) language NOUN . (O) 
We PRON (O) evaluate VERB (O) the DET (O) contribution NOUN (O) of ADP (O) each DET (O) component NOUN , (O) and CCONJ (O) demonstrate NOUN (O) the DET (O) proposed VERB (O) model NOUN ’s PUNCT (O) ability NOUN (O) to ADP (O) disentangle NOUN (O) speakers NOUN (O) from ADP (O) languages NOUN (O) and CCONJ (O) consistently ADV (O) synthesize VERB (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] for ADP (O) all DET (O) speakers NOUN , (O) despite SCONJ (O) the DET (O) perfect ADJ (O) correlation NOUN (O) to ADP (O) the DET (O) original ADJ (O) language NOUN (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] . 

 Model NOUN (O) Structure NOUN (O) 

 We PRON (O) base NOUN (O) our DET (O) [multilingual ADJ (B) TTS PROPN (I) model NOUN (I)] on ADP (O) [Tacotron PROPN (B) 2 NUM (I)] , which DET (O) uses VERB (O) an DET (O) [attention NOUN - based VERB (B) sequence NOUN - to ADP - sequence NOUN (I) model NOUN (I)] to PART (O) generate NOUN (O) a NOUN (O) sequence NOUN (O) of ADP (O) [log PROPN - mel PROPN (B) spectrogram PROPN (I) frames VERB (I)] based VERB (O) on ADP (O) an DET (O) input NOUN (O) text NOUN (O) sequence NOUN . (O) The DET (O) architecture NOUN (O) is AUX (O) illustrated VERB (O) in ADP (O) Figure NOUN (O) 1 NUM . (O) 
It PRON (O) augments NOUN (O) the DET (O) base NOUN (O) [Tacotron PROPN (B) 2 NUM (I) model NOUN (I)] with ADP (O) [additional ADJ (B) speaker NOUN (I)] and CCONJ , (O) optionally ADV , (O) language NOUN (O) embedding NOUN (O) inputs VERB (O) (bottom NOUN (O) right ADV) , (O) an DET (O) adversarially ADV - trained VERB (O) [speaker NOUN (B) classifier NOUN (I)] (top NOUN (O) right ADV) , (O) and CCONJ (O) a NOUN (O) [variational NOUN (B) autoencoder NOUN (I) residual ADJ (I) encoder NOUN (I)] (top NOUN (O) left VERB) (O) which DET (O) conditions NOUN (O) the DET (O) [decoder NOUN (B)] on ADP (O) a NOUN (O) latent NOUN (O) embedding NOUN (O) computed VERB (O) from ADP (O) the DET (O) [target NOUN (B) spectrogram NOUN (I)] during ADP (O) training NOUN (O) (top NOUN (O) left VERB) . (O) 
Finally ADV , (O) similar ADJ (O) to ADP (O) [Tacotron PROPN (B) 2 NUM (I)] , we PRON (O) separately ADV (O) train NOUN (O) a NOUN (O) [WaveRNN PUNCT (B) neural NOUN (I) vocoder NOUN (I)] . 

 [Input NOUN (B) representations NOUN (I)] 

 [End NOUN - to ADP - end NOUN (B) TTS PROPN (I) models NOUN (I)] have AUX (O) typically ADV (O) used VERB (O) character NOUN (O) or CCONJ (O) [phoneme NOUN (B) input NOUN (I) representations NOUN (I)] , or CCONJ (O) hybrids X (O) between ADP (O) them PRON . (O) 
Recently ADV , (O) proposed VERB (O) using VERB (O) inputs VERB (O) derived VERB (O) from ADP (O) the DET (O) UTF-8 PROPN (O) [byte NOUN (B)] encoding VERB (O) in ADP (O) [multilingual ADJ (B) settings NOUN (I)] . 
We PRON (O) evaluate VERB (O) the DET (O) effects NOUN (O) of ADP (O) using VERB (O) these DET (O) representations NOUN (O) for ADP (O) [multilingual ADJ (B) TTS PROPN (I)] . 

 Characters NOUN (O) / [Graphemes PROPN (B)] 

 Embeddings NOUN (O) corresponding VERB (O) to ADP (O) each DET (O) character NOUN (O) or CCONJ (O) [grapheme NOUN (B)] are AUX (O) the DET (O) default NOUN (O) inputs VERB (O) for ADP (O) [end NOUN - to ADP - end NOUN (B) TTS PROPN (I) models NOUN (I)] , requiring VERB (O) the DET (O) model NOUN (O) to ADP (O) implicitly ADV (O) learn VERB (O) how ADV (O) to ADP (O) pronounce NOUN (O) input NOUN (O) words NOUN (O) (i.e. X (O) [grapheme NOUN - to ADP - phoneme NOUN (B) conversion NOUN (I)]) as SCONJ (O) part NOUN (O) of ADP (O) the DET (O) synthesis NOUN (O) task NOUN . (O) 
Extending VERB (O) a NOUN (O) [grapheme NOUN - based VERB (B) input NOUN (I) vocabulary PROPN (I)] to PART (O) a NOUN (O) [multilingual ADJ (B) setting NOUN (I)] is AUX (O) straightforward PROPN , (O) by ADP (O) simply ADV (O) concatenating VERB (O) [grapheme NOUN (B) sets VERB (I)] in ADP (O) the DET (O) [training NOUN (B) corpus NOUN (I)] for ADP (O) each DET (O) language NOUN . (O) 
This DET (O) can VERB (O) grow VERB (O) quickly ADV (O) for ADP (O) languages NOUN (O) with ADP (O) large ADJ (O) alphabets NOUN , (O) e.g. ADV (O) our DET (O) Mandarin PROPN (O) vocabulary NOUN (O) contains VERB (O) over ADP (O) 4.5k NOUN (O) tokens NOUN . (O) We PRON (O) simply ADV (O) concatenate NOUN (O) all DET (O) [graphemes NOUN (B)] appearing VERB (O) in ADP (O) the DET (O) [training NOUN (B) corpus NOUN (I)] , leading VERB (O) to ADP (O) a NOUN (O) total NOUN (O) of ADP (O) 4,619 NUM (O) tokens NOUN . (O) 
Equivalent PROPN (O) [graphemes NOUN (B)] are AUX (O) shared VERB (O) across ADP (O) languages NOUN . (O) 
During ADP (O) inference NOUN (O) all DET (O) previously ADV (O) unseen ADJ (O) characters NOUN (O) are AUX (O) mapped VERB (O) to ADP (O) a NOUN (O) special ADJ (O) out SCONJ - of ADP - vocabulary NOUN (O) (OOV PROPN) (O) symbol NOUN . (O) 

 UTF-8 PROPN (O) Encoded VERB (O) [Bytes NOUN (B)] 

 Following VERB (O) we PRON (O) experiment NOUN (O) with ADP (O) an DET (O) [input NOUN (B) representation NOUN (I)] based VERB (O) on ADP (O) the DET (O) UTF-8 PROPN (O) text NOUN (O) encoding NOUN , (O) which DET (O) uses VERB (O) 256 NUM (O) possible ADJ (O) values NOUN (O) as SCONJ (O) each DET (O) input NOUN (O) token NOUN (O) where ADV (O) the DET (O) mapping NOUN (O) from ADP (O) [graphemes NOUN (B)] to PART (O) [bytes NOUN (B)] is AUX (O) [language NOUN - dependent ADJ (B)] . 
For ADP (O) languages NOUN (O) with ADP (O) single-[byte NOUN (B)] characters NOUN (O) (e.g. ADV , (O) English PROPN) , (O) this DET (O) representation NOUN (O) is AUX (O) equivalent NOUN (O) to ADP (O) the DET (O) [grapheme NOUN (B) representation NOUN (I)] . 
However ADV , (O) for ADP (O) languages NOUN (O) with ADP (O) multi-[byte NOUN (B)] characters NOUN (O) (such ADJ (O) as SCONJ (O) Mandarin PROPN) (O) the DET (O) [TTS PROPN (B) model NOUN (I)] must VERB (O) learn VERB (O) to ADP (O) attend VERB (O) to ADP (O) a NOUN (O) consistent ADJ (O) [sequence NOUN (B) of ADP (I) bytes PROPN (I)] to PART (O) correctly ADV (O) generate NOUN (O) the DET (O) corresponding VERB (O) [speech NOUN (B)] . 
On ADP (O) the DET (O) other ADJ (O) hand NOUN , (O) using VERB (O) a NOUN (O) UTF-8 PROPN (O) [byte NOUN (B) representation NOUN (I)] may VERB (O) promote VERB (O) sharing NOUN (O) of ADP (O) representations NOUN (O) between ADP (O) languages NOUN (O) due ADJ (O) to ADP (O) the DET (O) smaller ADJ (O) number NOUN (O) of ADP (O) input NOUN (O) tokens NOUN . (O) 

 [Phonemes PROPN (B)] 

 Using VERB (O) [phoneme NOUN (B)] inputs VERB (O) simplifies NOUN (O) the DET (O) [TTS PROPN (B) task NOUN (I)] , as SCONJ (O) the DET (O) model NOUN (O) no DET (O) longer ADJ (O) needs VERB (O) to ADP (O) learn VERB (O) complicated ADJ (O) pronunciation NOUN (O) rules VERB (O) for ADP (O) languages NOUN (O) such ADJ (O) as SCONJ (O) English PROPN . (O) 
Similar PROPN (O) to ADP (O) our DET (O) [grapheme NOUN - based VERB (B) model NOUN (I)] , equivalent ADJ (O) [phonemes NOUN (B)] are AUX (O) shared VERB (O) across ADP (O) languages NOUN . (O) 
We PRON (O) concatenate NOUN (O) all DET (O) possible ADJ (O) [phoneme NOUN (B) symbols NOUN (I)] , for ADP (O) a NOUN (O) total NOUN (O) of ADP (O) 88 NUM (O) tokens NOUN . (O) 
To NOUN (O) support NOUN (O) Mandarin PROPN , (O) we PRON (O) include VERB (O) tone NOUN (O) information NOUN (O) by ADP (O) learning NOUN (O) [phoneme NOUN - independent ADJ (B) embeddings NOUN (I)] for ADP (O) each DET (O) of ADP (O) the DET (O) 4 NUM (O) possible ADJ (O) tones NOUN , (O) and CCONJ (O) broadcast NOUN (O) each DET (O) tone NOUN (O) embedding NOUN (O) to ADP (O) all DET (O) [phoneme NOUN (B) embeddings NOUN (I)] inside ADV (O) the DET (O) corresponding VERB (O) syllable ADJ . (O) 
For ADP (O) English PROPN (O) and CCONJ (O) Spanish PROPN , (O) tone NOUN (O) embeddings NOUN (O) are AUX (O) replaced VERB (O) by ADP (O) stress NOUN (O) embeddings NOUN (O) which DET (O) include VERB (O) primary NOUN (O) and CCONJ (O) secondary ADJ (O) stresses NOUN . (O) 
A PROPN (O) special ADJ (O) symbol NOUN (O) is AUX (O) used VERB (O) when ADV (O) there PRON (O) is AUX (O) no DET (O) tone NOUN (O) or CCONJ (O) stress NOUN . (O) 

 [Residual PROPN (B) encoder NOUN (I)] 

 Following VERB , (O) we PRON (O) augment NOUN (O) the DET (O) [TTS PROPN (B) model NOUN (I)] by ADP (O) incorporating VERB (O) a NOUN (O) [variational NOUN (B) autoencoder NOUN (I) residual ADJ (I) encoder NOUN (I)] which DET (O) encodes VERB (O) the DET (O) latent NOUN (O) factors NOUN (O) in ADP (O) the DET (O) [training NOUN (B) audio NOUN (I)] , e.g. ADV (O) [prosody NOUN (B)] or CCONJ (O) background NOUN (O) noise NOUN , (O) which DET (O) is AUX (O) not PART (O) well ADV - explained VERB (O) by ADP (O) the DET (O) conditioning NOUN (O) inputs VERB (O) : the DET (O) text NOUN (O) representation NOUN , (O) speaker NOUN , (O) and CCONJ (O) language NOUN (O) embeddings NOUN . (O) 
We PRON (O) follow NOUN (O) the DET (O) structure NOUN (O) from ADP , (O) except SCONJ (O) we PRON (O) use NOUN (O) a NOUN (O) standard NOUN (O) single ADJ (O) [Gaussian PROPN (B) prior ADV (I) distribution NOUN (I)] and CCONJ (O) reduce VERB (O) the DET (O) latent NOUN (O) dimension NOUN (O) to ADP (O) 16 NUM . (O) 
In ADP (O) our DET (O) experiments NOUN , (O) we PRON (O) observe VERB (O) that SCONJ (O) feeding NOUN (O) in ADP (O) the DET (O) prior ADJ (O) mean VERB (O) (all DET (O) zeros NOUN) (O) during ADP (O) inference NOUN , (O) significantly ADV (O) improves VERB (O) stability NOUN (O) of ADP (O) [cross ADJ - lingual ADJ (B) speaker NOUN (I) transfer NOUN (I)] and CCONJ (O) leads VERB (O) to ADP (O) improved VERB (O) naturalness NOUN (O) as SCONJ (O) shown VERB (O) by ADP (O) [MOS PROPN (B) evaluations NOUN (I)] in ADP (O) Section NOUN (O) 3.4 NUM . (O) 

 Adversarial ADJ (O) training NOUN (O) 

 One NUM (O) of ADP (O) the DET (O) challenges VERB (O) for ADP (O) [multilingual ADJ (B) TTS PROPN (I)] is AUX (O) [data NOUN (B) sparsity NOUN (I)] , where ADV (O) some DET (O) languages NOUN (O) may VERB (O) only ADV (O) have AUX (O) [training NOUN (B) data NOUN (I)] for ADP (O) a NOUN (O) [few ADJ (B) speakers NOUN (I)] . 
In ADP (O) the DET (O) extreme NOUN (O) case NOUN (O) where ADV (O) there PRON (O) is AUX (O) only ADV (O) one NUM (O) speaker NOUN (O) per ADP (O) language NOUN (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] , the DET (O) [speaker NOUN (B) identity NOUN (I)] is AUX (O) essentially ADV (O) the DET (O) same ADJ (O) as SCONJ (O) the DET (O) language NOUN (O) i PRON (O) d. PROPN (O) 
To NOUN (O) encourage VERB (O) the DET (O) model NOUN (O) to ADP (O) learn VERB (O) disentangled VERB (O) representations NOUN (O) of ADP (O) the DET (O) text NOUN (O) and CCONJ (O) [speaker NOUN (B) identity NOUN (I)] , we PRON (O) proactively ADV (O) discourage NOUN (O) the DET (O) text NOUN (O) encoding NOUN (O) t NOUN (O) s NOUN (O) from ADP (O) also ADV (O) capturing NOUN (O) [speaker NOUN (B) information NOUN (I)] . 
We PRON (O) employ NOUN (O) domain NOUN (O) adversarial ADJ (O) training NOUN (O) to ADP (O) encourage VERB (O) t NOUN (O) i PRON (O) to ADP (O) encode NOUN (O) text NOUN (O) in ADP (O) a NOUN (O) speaker NOUN - independent ADJ (O) manner NOUN (O) by ADP (O) introducing VERB (O) a NOUN (O) [speaker NOUN (B) classifier NOUN (I)] based VERB (O) on ADP (O) the DET (O) text NOUN (O) encoding NOUN (O) and CCONJ (O) a NOUN (O) [gradient NOUN (B) reversal NOUN (I) layer NOUN (I)] . 
Note NOUN (O) that DET (O) the DET (O) [speaker NOUN (B) classifier NOUN (I)] is AUX (O) optimized VERB (O) with ADP (O) a NOUN (O) different ADJ (O) objective NOUN (O) than SCONJ (O) the DET (O) rest NOUN (O) of ADP (O) the DET (O) model NOUN (O) : 
where ADV (O) si NOUN (O) is AUX (O) the DET (O) [speaker NOUN (B) label NOUN (I)] i PRON (O) and CCONJ (O) ψ PROPN (O) s NOUN (O) are AUX (O) the DET (O) parameters VERB (O) for ADP (O) [speaker NOUN (B) classifier NOUN (I)] . 
To PART (O) train NOUN (O) the DET (O) full ADJ (O) model NOUN , (O) we PRON (O) insert ADJ (O) a NOUN (O) [gradient NOUN (B) reversal NOUN (I) layer NOUN (I)] prior ADV (O) to ADP (O) this DET (O) [speaker NOUN (B) classifier NOUN (I)] , which DET (O) scales VERB (O) the DET (O) gradient NOUN (O) by ADP (O) −λ PROPN . (O) 
Following PROPN , (O) we PRON (O) also ADV (O) explore VERB (O) inserting VERB (O) another DET (O) adversarial ADJ (O) layer NOUN (O) on ADP (O) top NOUN (O) of ADP (O) the DET (O) [variational NOUN (B) autoencoder NOUN (I)] to PART (O) encourage VERB (O) it PRON (O) to ADP (O) learn VERB (O) speaker NOUN - independent ADJ (O) representations NOUN . (O) 
However ADV , (O) we PRON (O) found VERB (O) that SCONJ (O) this DET (O) layer NOUN (O) has AUX (O) no DET (O) effect NOUN (O) after ADP (O) decreasing VERB (O) the DET (O) latent NOUN (O) space NOUN (O) dimension NOUN . (O) 
We PRON (O) impose VERB (O) this DET (O) [adversarial ADJ (B) loss NOUN (I)] separately ADV (O) on ADP (O) each DET (O) element NOUN (O) of ADP (O) the DET (O) encoded VERB (O) text NOUN (O) sequence NOUN , (O) in ADP (O) order NOUN (O) to ADP (O) encourage VERB (O) the DET (O) model NOUN (O) to ADP (O) learn VERB (O) a NOUN (O) speaker NOUN (O) and CCONJ (O) [language NOUN - independent ADJ (B) text NOUN (I)] embedding VERB (O) space NOUN . (O) 
In ADP (O) contrast NOUN (O) to PART , (O) which DET (O) disentangled VERB (O) [speaker NOUN (B) identity NOUN (I)] from ADP (O) background NOUN (O) noise NOUN , (O) some DET (O) input NOUN (O) tokens VERB (O) are AUX (O) highly ADV (O) [language NOUN - dependent ADJ (B)] which DET (O) can VERB (O) lead NOUN (O) to ADP (O) unstable ADJ (O) adversarial ADJ (O) classifier NOUN (O) gradients NOUN . (O) 
We PRON (O) address NOUN (O) this DET (O) by ADP (O) clipping VERB (O) gradients VERB (O) computed VERB (O) at ADP (O) the DET (O) [reversal NOUN (B) layer NOUN (I)] to PART (O) limit NOUN (O) the DET (O) impact NOUN (O) of ADP (O) such ADJ (O) outliers NOUN . (O) 

 Experiments NOUN (O) 

 We PRON (O) train NOUN (O) models NOUN (O) using VERB (O) a NOUN (O) [proprietary ADJ (B) dataset NOUN (I)] composed VERB (O) of ADP (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] in ADP (O) three NUM (O) languages NOUN (O) : (1 X) (O) 385 NUM (O) hours NOUN (O) of ADP (O) English PROPN (O) (EN PROPN) (O) from ADP (O) 84 NUM (O) [professional ADJ (B) voice NOUN (I)] actors NOUN (O) with ADP (O) accents VERB (O) from ADP (O) the DET (O) United PROPN (O) States PROPN , (O) Great ADJ (O) Britain PROPN , (O) Australia PROPN , (O) and CCONJ (O) Singapore PROPN (O) ; (2 X) (O) 97 NUM (O) hours NOUN (O) of ADP (O) Spanish PROPN (O) (ES PROPN) (O) from ADP (O) 3 NUM (O) [female NOUN (B) speakers NOUN (I)] include VERB (O) Castilian PROPN (O) and CCONJ (O) US PROPN (O) Spanish PROPN (O) ; (3 X) (O) 68 NUM (O) hours NOUN (O) of ADP (O) Mandarin PROPN (O) (CN PROPN) (O) from ADP (O) 5 NUM (O) speakers NOUN . (O) 

 Model NOUN (O) and CCONJ (O) training NOUN (O) setup NOUN (O) 

 The DET (O) [synthesizer NOUN (B) network NOUN (I)] uses VERB (O) the DET (O) [Tacotron PROPN (B) 2 NUM (I) architecture NOUN (I)] , with ADP (O) additional ADJ (O) inputs VERB (O) consisting VERB (O) of ADP (O) learned VERB (O) speaker NOUN (O) (64-dim NUM) (O) and CCONJ (O) language NOUN (O) embeddings NOUN (O) (3-dim NUM) , (O) concatenated VERB (O) and CCONJ (O) passed VERB (O) to ADP (O) the DET (O) [decoder NOUN (B)] at ADP (O) each DET (O) step NOUN . (O) 
The DET (O) generated VERB (O) [speech NOUN (B)] is AUX (O) represented VERB (O) as SCONJ (O) a NOUN (O) sequence NOUN (O) of ADP (O) 128-dim NUM (O) [log PROPN - mel PROPN (B) spectrogram PROPN (I) frames VERB (I)] , computed VERB (O) from ADP (O) 50ms NOUN (O) windows PROPN (O) shifted VERB (O) by ADP (O) 12.5ms PROPN . (O) 
The DET (O) [variational NOUN (B) residual ADJ (I) encoder NOUN (I) architecture NOUN (I)] closely ADV (O) follows VERB (O) the DET (O) attribute NOUN (O) [encoder NOUN (B)] in ADP . (O) 
It PRON (O) maps NOUN (O) a NOUN (O) variable NOUN (O) length NOUN (O) [mel X (B) spectrogram PROPN (I)] to PART (O) two NUM (O) [vectors NOUN (B)] parameterizing VERB (O) the DET (O) mean VERB (O) and CCONJ (O) log NOUN (O) variance NOUN (O) of ADP (O) the DET (O) [Gaussian PROPN (B) posterior NOUN (I)] . 
The DET (O) [speaker NOUN (B) classifiers NOUN (I)] are AUX (O) fully ADV - connected VERB (O) networks NOUN (O) with ADP (O) one NUM (O) 256 NUM (O) unit NOUN (O) hidden VERB (O) layer NOUN (O) followed VERB (O) by ADP (O) a NOUN (O) [softmax PROPN (B)] predicting VERB (O) the DET (O) [speaker NOUN (B) identity NOUN (I)] . 
The DET (O) synthesizer NOUN (O) and CCONJ (O) [speaker NOUN (B) classifier NOUN (I)] are AUX (O) trained VERB (O) with ADP (O) weight NOUN (O) 1.0 NUM (O) and CCONJ (O) 0.02 NUM (O) respectively ADV . (O) 
As SCONJ (O) described VERB (O) in ADP (O) the DET (O) previous ADJ (O) section NOUN (O) we PRON (O) apply VERB (O) gradient NOUN (O) clipping VERB (O) with ADP (O) factor NOUN (O) 0.5 NUM (O) to ADP (O) the DET (O) [gradient NOUN (B) reversal NOUN (I) layer NOUN (I)] . 
The DET (O) entire ADJ (O) model NOUN (O) is AUX (O) trained VERB (O) jointly ADV (O) with ADP (O) a NOUN (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 256 NUM , (O) using VERB (O) the DET (O) [Adam PROPN (B) optimizer NOUN (I)] configured VERB (O) with ADP (O) an DET (O) initial NOUN (O) learning NOUN (O) rate NOUN (O) of ADP (O) 10 NUM (O) −3 PROPN , (O) and CCONJ (O) an DET (O) exponential NOUN (O) decay NOUN (O) that SCONJ (O) halves VERB (O) the DET (O) learning NOUN (O) rate NOUN (O) every DET (O) 12.5k NUM (O) steps NOUN , (O) starting VERB (O) at ADP (O) 50k NUM (O) steps NOUN . (O) 
[Waveforms PROPN (B)] are AUX (O) synthesized VERB (O) using VERB (O) a NOUN (O) [WaveRNN PUNCT (B) vocoder NOUN (I)] which DET (O) generates VERB (O) 16-bit NUM (O) signals NOUN (O) sampled VERB (O) at ADP (O) 24 NUM (O) kHz PROPN (O) conditioned VERB (O) on ADP (O) [spectrograms NOUN (B)] predicted VERB (O) by ADP (O) the DET (O) [TTS PROPN (B) model NOUN (I)] . 
We PRON (O) synthesize VERB (O) 100 NUM (O) samples NOUN (O) per ADP (O) model NOUN , (O) and CCONJ (O) have AUX (O) each DET (O) one NUM (O) rated VERB (O) by ADP (O) 6 NUM (O) raters NOUN . (O) 

 Evaluation NOUN (O) 

 To ADP (O) evaluate VERB (O) [synthesized VERB (B) speech NOUN (I)] , we PRON (O) rely VERB (O) on ADP (O) crowdsourced VERB (O) [Mean PROPN (B) Opinion NOUN (I) Score PROPN (I) (MOS PROPN) (I) evaluations NOUN (I)] of ADP (O) [speech NOUN (B) naturalness NOUN (I)] via ADP (O) subjective ADJ (O) listening VERB (O) tests NOUN . (O) 
Ratings NOUN (O) follow NOUN (O) the DET (O) Absolute PROPN (O) Category NOUN (O) Rating NOUN (O) scale NOUN , (O) with ADP (O) scores NOUN (O) from ADP (O) 1 NUM (O) to ADP (O) 5 NUM (O) in ADP (O) 0.5 NUM (O) point NOUN (O) increments NOUN . (O) 
For ADP (O) [cross ADJ - language ADJ (B) voice NOUN (I)] cloning VERB , (O) we PRON (O) also ADV (O) evaluate VERB (O) whether SCONJ (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] resembles VERB (O) the DET (O) identity NOUN (O) of ADP (O) the DET (O) [reference NOUN (B) speaker NOUN (I)] by ADP (O) pairing VERB (O) each DET (O) synthesized VERB (O) utterance NOUN (O) with ADP (O) a NOUN (O) reference NOUN (O) utterance NOUN (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] for ADP (O) subjective ADJ (O) [MOS PROPN (B) evaluation NOUN (I)] of ADP (O) [speaker NOUN (B) similarity NOUN (I)] , as SCONJ (O) in ADP . (O) 
Although SCONJ (O) rater NOUN (O) instructions NOUN (O) explicitly ADV (O) asked VERB (O) for ADP (O) the DET (O) content NOUN (O) to ADP (O) be AUX (O) ignored VERB , (O) note NOUN (O) that SCONJ (O) this DET (O) similarity NOUN (O) evaluation NOUN (O) is AUX (O) more ADJ (O) challenging NOUN (O) than SCONJ (O) the DET (O) one NUM (O) in ADP (O) because SCONJ (O) the DET (O) reference NOUN (O) and CCONJ (O) target NOUN (O) examples VERB (O) are AUX (O) spoken VERB (O) in ADP (O) different ADJ (O) languages NOUN , (O) and CCONJ (O) raters NOUN (O) are AUX (O) not PART (O) bilingual ADJ . (O) 
We PRON (O) found VERB (O) that SCONJ (O) low NOUN (O) fidelity PROPN (O) [audio NOUN (B)] tended VERB (O) to ADP (O) result NOUN (O) in ADP (O) high ADJ (O) variance NOUN (O) similarity NOUN (O) [MOS PROPN (B)] so CCONJ (O) we PRON (O) always ADV (O) use NOUN (O) [WaveRNN PUNCT (B) outputs NOUN (I)] . 
For ADP (O) each DET (O) language NOUN , (O) we PRON (O) chose VERB (O) one NUM (O) speaker NOUN (O) to ADP (O) use NOUN (O) for ADP (O) similarity NOUN (O) tests NOUN . (O) 
As SCONJ (O) shown VERB (O) in ADP (O) Table NOUN (O) 1 NUM , (O) the DET (O) [EN NOUN (B) speaker NOUN (I)] is AUX (O) found VERB (O) to ADP (O) be AUX (O) dissimilar NOUN (O) to ADP (O) the DET (O) ES PROPN (O) and CCONJ (O) [CN PROPN (B) speakers NOUN (I)] ([MOS PROPN (B)] below ADP (O) 2.0 NUM) , (O) while SCONJ (O) the DET (O) ES PROPN (O) and CCONJ (O) [CN PROPN (B) speakers NOUN (I)] are AUX (O) slightly ADV (O) similar ADJ (O) ([MOS PROPN (B)] around ADV (O) 2.0 NUM) . (O) 
The DET (O) [CN PROPN (B) speaker NOUN (I)] has AUX (O) more ADJ (O) natural ADJ (O) variability NOUN (O) compared VERB (O) to ADP (O) EN PROPN (O) and CCONJ (O) ES PROPN , (O) leading VERB (O) to ADP (O) a NOUN (O) lower ADJ (O) self NOUN (O) similarity NOUN . (O) 
The DET (O) scores NOUN (O) are AUX (O) consistent ADJ (O) when ADV (O) EN PROPN (O) and CCONJ (O) CN PROPN (O) raters NOUN (O) evaluate VERB (O) the DET (O) same ADJ (O) EN PROPN (O) and CCONJ (O) CN PROPN (O) test NOUN (O) set VERB . (O) 
The DET (O) observation NOUN (O) is AUX (O) consistent ADJ (O) with ADP (O) : raters NOUN (O) are AUX (O) able ADJ (O) to ADP (O) discriminate NOUN (O) between ADP (O) speakers NOUN (O) across ADP (O) languages NOUN . (O) 
However ADV , (O) when ADV (O) rating NOUN (O) [synthetic NOUN (B) speech NOUN (I)] , we PRON (O) observed VERB (O) that SCONJ (O) English PROPN (O) speaking VERB (O) raters NOUN (O) often ADV (O) considered VERB (O) “ PUNCT (O) heavy ADJ (O) accented VERB (O) ” PUNCT (O) synthetic NOUN (O) CN PROPN (O) [speech NOUN (B)] to PART (O) sound NOUN (O) more ADJ (O) similar ADJ (O) to ADP (O) the DET (O) target NOUN (O) EN PROPN (O) speaker NOUN , (O) compared VERB (O) to ADP (O) more ADJ (O) [fluent NOUN (B) speech NOUN (I)] from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] . 
This DET (O) indicates VERB (O) that SCONJ (O) accent NOUN (O) and CCONJ (O) [speaker NOUN (B) identity NOUN (I)] are AUX (O) not PART (O) fully ADV (O) disentangled VERB . (O) 
We PRON (O) encourage VERB (O) readers NOUN (O) to ADP (O) listen VERB (O) to ADP (O) samples NOUN (O) on ADP (O) the DET (O) companion NOUN (O) webpage NOUN . (O) 

 Comparing VERB (O) [input NOUN (B) representations NOUN (I)] 

 We PRON (O) first ADJ (O) build NOUN (O) and CCONJ (O) evaluate VERB (O) models NOUN (O) comparing VERB (O) the DET (O) performance NOUN (O) of ADP (O) different ADJ (O) text NOUN (O) [input NOUN (B) representations NOUN (I)] . 
For ADP (O) all DET (O) three NUM (O) languages NOUN , (O) [byte NOUN (B)]-based VERB models NOUN (O) always ADV (O) use NOUN (O) a NOUN (O) 256-dim NUM (O) [softmax PROPN (B) output NOUN (I)] . 
Monolingual PROPN (O) character NOUN (O) and CCONJ (O) [phoneme NOUN (B) models NOUN (I)] each DET (O) use NOUN (O) a NOUN (O) different ADJ (O) input NOUN (O) vocabulary NOUN (O) corresponding VERB (O) to ADP (O) the DET (O) training NOUN (O) language NOUN . (O) 
Table NOUN (O) 2 NUM (O) compares VERB (O) monolingual NOUN (O) and CCONJ (O) [multilingual ADJ (B) model NOUN (I)] performance NOUN (O) using VERB (O) different ADJ (O) [input NOUN (B) representations NOUN (I)] . 
For ADP (O) Mandarin PROPN , (O) the DET (O) [phoneme NOUN - based VERB (B) model NOUN (I)] performs VERB (O) significantly ADV (O) better ADJ (O) than SCONJ (O) char PROPN (O) or CCONJ (O) [byte NOUN (B)]-based VERB variants NOUN (O) due ADJ (O) to ADP (O) rare ADJ (O) and CCONJ (O) OOV PROPN (O) words NOUN . (O) 
Compared VERB (O) to ADP (O) the DET (O) monolingual NOUN (O) system NOUN , (O) [multilingual ADJ (B) phoneme NOUN - based VERB (I) systems NOUN (I)] have AUX (O) similar ADJ (O) performance NOUN (O) on ADP (O) ES PROPN (O) and CCONJ (O) CN PROPN (O) but CCONJ (O) are AUX (O) slightly ADV (O) worse ADJ (O) on ADP (O) EN PROPN . (O) 
CN PROPN (O) has AUX (O) a NOUN (O) larger ADJ (O) gap NOUN (O) to ADP (O) ground NOUN (O) truth NOUN (O) (top NOUN) (O) due ADJ (O) to ADP (O) unseen ADJ (O) word NOUN (O) segmentation NOUN (O) (for ADP (O) simplicity NOUN , (O) we PRON (O) did AUX (O) n’t PROPN (O) add VERB (O) word NOUN (O) boundary ADJ (O) during ADP (O) training NOUN) . (O) 
The DET (O) multispeaker NOUN (O) model NOUN (O) (bottom NOUN) (O) performs VERB (O) about ADP (O) the DET (O) same ADJ (O) as SCONJ (O) the DET (O) [single ADJ (B) speaker NOUN (I)] per ADP - language NOUN (O) variant NOUN (O) (middle PROPN) . (O) 
Overall ADV , (O) when ADV (O) using VERB (O) [phoneme NOUN (B) inputs VERB (I)] all DET (O) the DET (O) languages NOUN (O) obtain VERB (O) [MOS PROPN (B) scores NOUN (I)] above ADV (O) 4.0 NUM . (O) 

 [Cross NOUN - language NOUN (B) voice NOUN (I)] cloning VERB (O) 

 We PRON (O) evaluate VERB (O) how ADV (O) well INTJ (O) the DET (O) multispeaker NOUN (O) models NOUN (O) can VERB (O) be AUX (O) used VERB (O) to ADP (O) clone NOUN (O) a NOUN (O) speaker NOUN ’s PUNCT (O) voice NOUN (O) into ADP (O) a NOUN (O) new ADJ (O) language NOUN (O) by ADP (O) simply ADV (O) passing NOUN (O) in ADP (O) [speaker NOUN (B) embeddings NOUN (I)] corresponding VERB (O) to ADP (O) a NOUN (O) different ADJ (O) language NOUN (O) from ADP (O) the DET (O) input NOUN (O) text NOUN . (O) 
Table NOUN (O) 3 NUM (O) shows VERB (O) voice NOUN (O) cloning VERB (O) performance NOUN (O) from ADP (O) an DET (O) [EN NOUN (B) speaker NOUN (I)] in ADP (O) the DET (O) [most ADJ (B) data NOUN (I)]-poor PROPN scenario NOUN (O) (129 NUM (O) hours NOUN) , (O) where ADV (O) only ADV (O) a NOUN (O) [single ADJ (B) speaker NOUN (I)] is AUX (O) available ADJ (O) for ADP (O) each DET (O) training NOUN (O) language NOUN (O) (1EN NUM (O) 1ES NUM (O) 1CN NUM) (O) without ADP (O) using VERB (O) the DET (O) [speaker NOUN - adversarial ADJ (B) loss NOUN (I)] . 
Using VERB (O) [byte NOUN (B) inputs VERB (I)] 3 NUM (O) it PRON (O) was AUX (O) possible ADJ (O) to ADP (O) clone NOUN (O) the DET (O) [EN NOUN (B) speaker NOUN (I)] to PART (O) ES PROPN (O) with ADP (O) high ADJ (O) similarity NOUN (O) [MOS PROPN (B)] , albeit SCONJ (O) with ADP (O) significantly ADV (O) reduced VERB (O) naturalness NOUN . (O) 
However ADV , (O) cloning VERB (O) the DET (O) [EN NOUN (B) voice NOUN (I)] to PART (O) CN PROPN (O) failed VERB (O) 4 NUM , (O) as SCONJ (O) did AUX (O) cloning VERB (O) to ADP (O) ES PROPN (O) and CCONJ (O) CN PROPN (O) using VERB (O) [phoneme NOUN (B)] inputs VERB . (O) 
Adding VERB (O) the DET (O) [adversarial ADJ (B) speaker NOUN (I) classifier NOUN (I)] enabled VERB (O) [cross ADJ - language ADJ (B) cloning VERB (I)] of ADP (O) the DET (O) [EN NOUN (B) speaker NOUN (I)] to PART (O) CN PROPN (O) with ADP (O) very ADV (O) high ADJ (O) similarity NOUN (O) [MOS PROPN (B)] for ADP (O) both DET (O) [byte NOUN (B)] and CCONJ (O) [phoneme NOUN (B) models NOUN (I)] . 
However ADV , (O) naturalness NOUN (O) [MOS PROPN (B)] remains VERB (O) much ADJ (O) lower ADJ (O) than SCONJ (O) using VERB (O) the DET (O) [native NOUN (B) speaker NOUN (I)] identity NOUN , (O) with ADP (O) the DET (O) naturalness NOUN (O) listening VERB (O) test NOUN (O) failing VERB (O) entirely ADV (O) in ADP (O) the DET (O) CN PROPN (O) case NOUN (O) with ADP (O) [byte NOUN (B) inputs VERB (I)] as SCONJ (O) a NOUN (O) result NOUN (O) of ADP (O) rater NOUN (O) comments NOUN (O) that SCONJ (O) the DET (O) [speech NOUN (B)] sounded VERB (O) like INTJ (O) a NOUN (O) foreign ADJ (O) language NOUN . (O) 
According VERB (O) to ADP (O) rater NOUN (O) comments NOUN (O) on ADP (O) the DET (O) [phoneme NOUN (B) system NOUN (I)] , most ADJ (O) of ADP (O) the DET (O) degradation NOUN (O) came VERB (O) from ADP (O) mismatched VERB (O) accent NOUN (O) and CCONJ (O) pronunciation NOUN , (O) not PART (O) fidelity PROPN . (O) 
CN PROPN (O) raters NOUN (O) commented VERB (O) that SCONJ (O) it PRON (O) sounded VERB (O) like INTJ (O) “ PUNCT (O) a NOUN (O) foreigner NOUN (O) speaking VERB (O) Chinese PROPN (O) ” PUNCT . (O) 
More ADJ (O) interestingly ADV , (O) few ADJ (O) ES PROPN (O) raters NOUN (O) commented VERB (O) that SCONJ (O) “ PUNCT (O) The DET (O) voice NOUN (O) does AUX (O) not PART (O) sound NOUN (O) robotic ADJ (O) but CCONJ (O) instead ADV (O) sounds VERB (O) like INTJ (O) an DET (O) English PROPN (O) [native NOUN (B) speaker NOUN (I)] who PRON (O) is AUX (O) learning NOUN (O) to ADP (O) pronounce NOUN (O) the DET (O) words NOUN (O) in ADP (O) Spanish PROPN . (O) ” PUNCT (O) 
Based VERB (O) on ADP (O) these DET (O) results VERB , (O) we PRON (O) only ADV (O) use NOUN (O) [phoneme NOUN (B) inputs VERB (I)] in ADP (O) the DET (O) following VERB (O) experiments VERB (O) since SCONJ (O) this DET (O) guarantees VERB (O) that SCONJ (O) pronunciations NOUN (O) are AUX (O) correct ADJ (O) and CCONJ (O) results VERB (O) in ADP (O) more ADJ (O) [fluent NOUN (B) speech NOUN (I)] . 
Table NOUN (O) 4 NUM (O) evaluates VERB (O) voice NOUN (O) cloning VERB (O) performance NOUN (O) of ADP (O) the DET (O) full ADJ (O) [multilingual ADJ (B) model NOUN (I)] (84EN NUM (O) 3ES NUM (O) 5CN NUM) , (O) which DET (O) is AUX (O) trained VERB (O) on ADP (O) the DET (O) [full ADJ (B) dataset NOUN (I)] with ADP (O) increased VERB (O) [speaker NOUN (B) coverage NOUN (I)] , and CCONJ (O) uses VERB (O) the DET (O) [speaker NOUN - adversarial ADJ (B) loss NOUN (I)] and CCONJ (O) speaker NOUN (O) / language NOUN (O) embeddings NOUN . (O) 
Incorporating PROPN (O) the DET (O) [adversarial ADJ (B) loss NOUN (I)] forces NOUN (O) the DET (O) text NOUN (O) representation NOUN (O) to ADP (O) be AUX (O) less ADJ (O) [language NOUN - specific ADJ (B)] , instead ADV (O) relying VERB (O) on ADP (O) the DET (O) [language NOUN (B) embedding NOUN (I)] to PART (O) capture NOUN (O) [language NOUN - dependent ADJ (B) information NOUN (I)] . 
Across PROPN (O) all DET (O) language NOUN (O) pairs NOUN , (O) the DET (O) model NOUN (O) [synthesizes NOUN (B) speech NOUN (I)] in ADP (O) all DET (O) voices NOUN (O) with ADP (O) naturalness NOUN (O) [MOS PROPN (B)] above ADV (O) 3.85 NUM , (O) demonstrating VERB (O) that SCONJ (O) increasing VERB (O) [training NOUN (B) speaker NOUN (I)] diversity NOUN (O) improves VERB (O) generalization NOUN . (O) 
In ADP (O) most ADJ (O) cases NOUN (O) synthesizing NOUN (O) EN PROPN (O) and CCONJ (O) ES PROPN (O) [speech NOUN (B)] (except SCONJ (O) EN NOUN - to ADP - ES NOUN) (O) approaches VERB (O) the DET (O) ground NOUN (O) truth NOUN (O) scores NOUN . (O) 
In ADP (O) contrast NOUN , (O) naturalness NOUN (O) of ADP (O) CN PROPN (O) [speech NOUN (B)] is AUX (O) consistently ADV (O) lower ADJ (O) than SCONJ (O) the DET (O) ground NOUN (O) truth NOUN . (O) 
The DET (O) high ADJ (O) naturalness NOUN (O) and CCONJ (O) similarity NOUN (O) [MOS PROPN (B) scores NOUN (I)] in ADP (O) the DET (O) top NOUN (O) row NOUN (O) of ADP (O) Table NOUN (O) 4 NUM (O) indicate VERB (O) that SCONJ (O) the DET (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) successfully ADV (O) transfer NOUN (O) the DET (O) [EN NOUN (B) voice NOUN (I)] to PART (O) both DET (O) ES PROPN (O) and CCONJ (O) CN PROPN (O) almost ADV (O) without ADP (O) accent NOUN . (O) 
When ADV (O) consistently ADV (O) conditioning NOUN (O) on ADP (O) the DET (O) EN PROPN (O) [language NOUN (B) embedding NOUN (I)] regardless ADV (O) of ADP (O) the DET (O) [target NOUN (B) language NOUN (I)] (second ADJ (O) row NOUN) , (O) the DET (O) model NOUN (O) produces VERB (O) more ADJ (O) English PROPN (O) accented VERB (O) ES PROPN (O) and CCONJ (O) CN PROPN (O) [speech NOUN (B)] , which DET (O) leads VERB (O) to ADP (O) lower ADJ (O) naturalness NOUN (O) but CCONJ (O) higher ADJ (O) similarity NOUN (O) [MOS PROPN (B) scores NOUN (I)] . 
Also ADV (O) see VERB (O) Figure NOUN (O) 2 NUM (O) and CCONJ (O) the DET (O) demo NOUN (O) for ADP (O) accent NOUN (O) transfer NOUN (O) [audio NOUN (B)] examples NOUN . (O) 
We PRON (O) see VERB (O) that DET (O) cloning VERB (O) the DET (O) [CN PROPN (B) voice NOUN (I)] to PART (O) other ADJ (O) languages NOUN (O) (bottom NOUN (O) row NOUN) (O) has AUX (O) the DET (O) lowest NOUN (O) similarity NOUN (O) [MOS PROPN (B)] , although SCONJ (O) the DET (O) scores NOUN (O) are AUX (O) still ADV (O) much ADJ (O) higher ADJ (O) than SCONJ (O) different-[speaker NOUN (B) similarity NOUN (I) MOS PROPN (I)] in ADP (O) the DET (O) off ADP - diagonals NOUN (O) of ADP (O) Table NOUN (O) 1 NUM (O) indicating VERB (O) that SCONJ (O) there PRON (O) is AUX (O) some DET (O) degree NOUN (O) of ADP (O) transfer NOUN . (O) 
This DET (O) is AUX (O) a NOUN (O) consequence NOUN (O) of ADP (O) the DET (O) [low ADJ (B) speaker NOUN (I)] coverage NOUN (O) of ADP (O) CN PROPN (O) compared VERB (O) to ADP (O) EN PROPN (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] , as SCONJ (O) well INTJ (O) as SCONJ (O) the DET (O) large ADJ (O) distance NOUN (O) between ADP (O) CN PROPN (O) and CCONJ (O) other ADJ (O) languages NOUN . (O) 
Finally ADV , (O) Table NOUN (O) 5 NUM (O) demonstrates VERB (O) the DET (O) importance NOUN (O) of ADP (O) training NOUN (O) using VERB (O) a NOUN (O) [variational NOUN (B) residual ADJ (I) encoder NOUN (I)] to PART (O) stabilize VERB (O) the DET (O) model NOUN (O) output NOUN . (O) 
Naturalness PROPN (O) [MOS PROPN (B)] decreases VERB (O) by ADP (O) 0.4 NUM (O) points VERB (O) for ADP (O) EN NOUN - to ADP - CN NOUN (O) cloning VERB (O) without ADP (O) the DET (O) [residual ADJ (B) encoder NOUN (I)] (bottom NOUN (O) row NOUN) . (O) 
In ADP (O) informal ADJ (O) comparisons NOUN (O) of ADP (O) the DET (O) outputs VERB (O) of ADP (O) the DET (O) two NUM (O) models NOUN (O) we PRON (O) find VERB (O) that SCONJ (O) the DET (O) model NOUN (O) without ADP (O) the DET (O) [residual ADJ (B) encoder NOUN (I)] tends VERB (O) to ADP (O) skip NOUN (O) rare ADJ (O) words NOUN (O) or CCONJ (O) inserts VERB (O) unnatural NOUN (O) pauses VERB (O) in ADP (O) the DET (O) output NOUN (O) [speech NOUN (B)] . 
This DET (O) indicates VERB (O) the DET (O) VAE PROPN (O) prior ADJ (O) learns VERB (O) a NOUN (O) mode NOUN (O) which DET (O) helps VERB (O) stabilize VERB (O) attention NOUN . (O) 

 Some DET (O) raters NOUN (O) gave VERB (O) low NOUN (O) fidelity PROPN (O) [audio NOUN (B)] lower ADJ (O) scores NOUN , (O) treating NOUN (O) " blurriness NOUN (O) " as SCONJ (O) a NOUN (O) property NOUN (O) of ADP (O) the DET (O) speaker NOUN . (O) 
Others NOUN (O) gave VERB (O) higher ADJ (O) scores NOUN (O) because SCONJ (O) they PRON (O) recognized VERB (O) such ADJ (O) [audio NOUN (B)] as SCONJ (O) synthetic NOUN (O) and CCONJ (O) had AUX (O) lower ADJ (O) expectations NOUN . (O) 
http://google.github.io/tacotron/publications/multilingual ADJ (O) 
Using VERB (O) character NOUN (O) or CCONJ (O) [byte NOUN (B) inputs VERB (I)] led VERB (O) to ADP (O) similar ADJ (O) results NOUN . (O) 
We PRON (O) did AUX (O) n’t PROPN (O) run NOUN (O) listening NOUN (O) tests VERB (O) because SCONJ (O) it PRON (O) was AUX (O) clear ADJ (O) that DET (O) synthesizing NOUN (O) EN PROPN (O) text NOUN (O) using VERB (O) the DET (O) [CN PROPN (B) speaker NOUN (I) embedding VERB (I)] did AUX (O) n’t PROPN (O) affect VERB (O) the DET (O) model NOUN (O) output NOUN . (O) 

 Conclusions NOUN (O) 

 We PRON (O) describe NOUN (O) extensions NOUN (O) to ADP (O) the DET (O) [Tacotron PROPN (B) 2 NUM (I) neural PROPN (I) TTS PROPN (I) model NOUN (I)] which DET (O) allow VERB (O) training NOUN (O) of ADP (O) a NOUN (O) [multilingual ADJ (B) model NOUN (I)] trained VERB (O) only ADV (O) on ADP (O) [monolingual ADJ (B) speakers NOUN (I)] , which DET (O) is AUX (O) able ADJ (O) to ADP (O) synthesize VERB (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] in ADP (O) three NUM (O) languages NOUN , (O) and CCONJ (O) transfer NOUN (O) [training NOUN (B) voices NOUN (I)] across ADP (O) languages NOUN . (O) 
Furthermore ADV , (O) the DET (O) model NOUN (O) learns VERB (O) to ADP (O) speak VERB (O) foreign ADJ (O) languages NOUN (O) with ADP (O) moderate ADJ (O) control NOUN (O) of ADP (O) accent NOUN , (O) and CCONJ , (O) as SCONJ (O) demonstrated VERB (O) on ADP (O) the DET (O) companion NOUN (O) webpage NOUN , (O) has AUX (O) rudimentary NOUN (O) support NOUN (O) for ADP (O) code NOUN (O) switching NOUN . (O) 
In ADP (O) future NOUN (O) work NOUN (O) we PRON (O) plan NOUN (O) to ADP (O) investigate VERB (O) methods NOUN (O) for ADP (O) scaling VERB (O) up NOUN (O) to ADP (O) leverage NOUN (O) large ADJ (O) amounts VERB (O) of ADP (O) low NOUN (O) quality NOUN (O) [training NOUN (B) data NOUN (I)] , and CCONJ (O) support NOUN (O) many ADJ (O) [more ADJ (B) speakers NOUN (I)] and CCONJ (O) languages NOUN . (O) 
