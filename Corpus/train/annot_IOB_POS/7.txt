Transfer NOUN (O) Learning NOUN (O) from ADP (O) [Speaker PROPN (B) Verification NOUN (I)] to PART (O) [Multispeaker PROPN (B) Text NOUN - To ADP - Speech PROPN (I) Synthesis PROPN (I)] 


 Abstract PROPN (O) 

 We PRON (O) describe NOUN (O) a NOUN (O) [neural NOUN (B) network NOUN - based VERB (I) system NOUN (I)] for ADP (O) [text NOUN - to ADP - speech NOUN (B) (TTS PROPN) (I) synthesis NOUN (I)] that DET (O) is AUX (O) able ADJ (O) to ADP (O) generate NOUN (O) [speech NOUN (B) audio NOUN (I)] in ADP (O) the DET (O) voice NOUN (O) of ADP (O) [different ADJ (B) speakers NOUN (I)] , including VERB (O) those DET (O) unseen ADJ (O) during ADP (O) training NOUN . (O) 
Our DET (O) system NOUN (O) consists VERB (O) of ADP (O) three NUM (O) independently ADV (O) trained VERB (O) components NOUN (O) : a DET (O) [speaker NOUN (B) encoder NOUN (I) network NOUN (I)] , trained VERB (O) on ADP (O) a NOUN (O) [speaker NOUN (B) verification NOUN (I)] task NOUN (O) using VERB (O) an DET (O) [independent ADJ (B) dataset NOUN (I)] of ADP (O) noisy PROPN (O) [speech NOUN (B)] without ADP (O) transcripts NOUN (O) from ADP (O) thousands NOUN (O) of ADP (O) speakers NOUN , (O) to ADP (O) generate NOUN (O) a NOUN (O) fixed VERB - dimensional ADJ (O) embedding NOUN (O) [vector NOUN (B)] from ADP (O) only ADV (O) seconds NOUN (O) of ADP (O) reference NOUN (O) [speech NOUN (B)] from ADP (O) a NOUN (O) [target NOUN (B) speaker NOUN (I)] ; a DET (O) [sequence NOUN - to ADP - sequence NOUN (B) synthesis NOUN (I) network NOUN (I)] based VERB (O) on ADP (O) [Tacotron PROPN (B) 2 NUM (I)] that DET (O) generates VERB (O) a NOUN (O) [mel X (B) spectrogram PROPN (I)] from ADP (O) text NOUN , (O) conditioned VERB (O) on ADP (O) the DET (O) [speaker NOUN (B) embedding NOUN (I)] ; an DET (O) auto NOUN - regressive ADJ (O) [WaveNet PROPN - based VERB (B) vocoder NOUN (I) network NOUN (I)] that DET (O) converts NOUN (O) the DET (O) [mel X (B) spectrogram PROPN (I)] into ADP (O) time NOUN (O) domain NOUN (O) [waveform PROPN (B) samples NOUN (I)] . 
We PRON (O) demonstrate NOUN (O) that SCONJ (O) the DET (O) proposed VERB (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) transfer NOUN (O) the DET (O) knowledge NOUN (O) of ADP (O) [speaker NOUN (B) variability NOUN (I)] learned VERB (O) by ADP (O) the DET (O) discriminatively ADV - trained VERB (O) [speaker NOUN (B) encoder NOUN (I)] to PART (O) the DET (O) [multispeaker NOUN (B) TTS PROPN (I) task NOUN (I)] , and CCONJ (O) is AUX (O) able ADJ (O) to ADP (O) synthesize VERB (O) natural ADJ (O) [speech NOUN (B)] from ADP (O) speakers NOUN (O) unseen ADJ (O) during ADP (O) training NOUN . (O) 
We PRON (O) quantify VERB (O) the DET (O) importance NOUN (O) of ADP (O) training NOUN (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] on ADP (O) a NOUN (O) large ADJ (O) and CCONJ (O) [diverse NOUN (B) speaker NOUN (I)] set VERB (O) in ADP (O) order NOUN (O) to ADP (O) obtain VERB (O) the DET (O) best ADJ (O) generalization NOUN (O) performance NOUN . (O) 
Finally ADV , (O) we PRON (O) show NOUN (O) that SCONJ (O) randomly ADV (O) sampled VERB (O) [speaker NOUN (B) embeddings NOUN (I)] can VERB (O) be AUX (O) used VERB (O) to ADP (O) [synthesize VERB (B) speech NOUN (I)] in ADP (O) the DET (O) voice NOUN (O) of ADP (O) [novel NOUN (B) speakers NOUN (I)] dissimilar ADJ (O) from ADP (O) those DET (O) used VERB (O) in ADP (O) training NOUN , (O) indicating VERB (O) that SCONJ (O) the DET (O) model NOUN (O) has AUX (O) learned VERB (O) a NOUN (O) high ADJ (O) [quality NOUN (B) speaker NOUN (I)] representation NOUN . (O) 

 Introduction NOUN (O) 

 The DET (O) goal NOUN (O) of ADP (O) this DET (O) work NOUN (O) is AUX (O) to ADP (O) build NOUN (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] which DET (O) can VERB (O) generate NOUN (O) natural ADJ (O) [speech NOUN (B)] for ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) speakers NOUN (O) in ADP (O) a NOUN (O) data NOUN (O) efficient ADJ (O) manner NOUN . (O) 
We PRON (O) specifically ADV (O) address NOUN (O) a NOUN (O) zero NUM - shot NOUN (O) learning NOUN (O) setting NOUN , (O) where ADV (O) a NOUN (O) few ADJ (O) seconds NOUN (O) of ADP (O) untranscribed ADJ (O) reference NOUN (O) [audio NOUN (B)] from ADP (O) a NOUN (O) [target NOUN (B) speaker NOUN (I)] is AUX (O) used VERB (O) to ADP (O) synthesize VERB (O) new ADJ (O) [speech NOUN (B)] in ADP (O) that SCONJ (O) [speaker NOUN ’s PROPN (B) voice NOUN (I)] , without ADP (O) updating VERB (O) any DET (O) model NOUN (O) parameters NOUN . (O) 
Such ADJ (O) systems NOUN (O) have AUX (O) accessibility NOUN (O) applications NOUN , (O) such ADJ (O) as SCONJ (O) restoring VERB (O) the DET (O) ability NOUN (O) to ADP (O) communicate NOUN (O) naturally ADV (O) to ADP (O) users NOUN (O) who PRON (O) have AUX (O) lost VERB (O) their DET (O) voice NOUN (O) and CCONJ (O) are AUX (O) therefore ADV (O) unable ADJ (O) to ADP (O) provide VERB (O) many ADJ (O) new ADJ (O) training NOUN (O) examples NOUN . (O) 
They PRON (O) could VERB (O) also ADV (O) enable NOUN (O) new ADJ (O) applications NOUN , (O) such ADJ (O) as SCONJ (O) transferring VERB (O) a NOUN (O) voice NOUN (O) across ADP (O) languages NOUN (O) for ADP (O) more ADJ (O) natural ADJ (O) [speech NOUN - to ADP - speech NOUN (B) translation NOUN (I)] , or CCONJ (O) generating NOUN (O) realistic ADJ (O) [speech NOUN (B)] from ADP (O) text NOUN (O) in ADP (O) low NOUN (O) resource NOUN (O) settings NOUN . (O) 
However ADV , (O) it PRON (O) is AUX (O) also ADV (O) important ADJ (O) to ADP (O) note NOUN (O) the DET (O) potential NOUN (O) for ADP (O) misuse NOUN (O) of ADP (O) this DET (O) technology NOUN , (O) for ADP (O) example NOUN (O) impersonating VERB (O) someone PRON ’s PUNCT (O) voice NOUN (O) without ADP (O) their DET (O) consent NOUN . (O) 
In ADP (O) order NOUN (O) to ADP (O) address NOUN (O) safety NOUN (O) concerns NOUN (O) consistent ADJ (O) with ADP (O) principles VERB (O) such ADJ (O) as SCONJ , (O) we PRON (O) verify VERB (O) that SCONJ (O) voices NOUN (O) generated VERB (O) by ADP (O) the DET (O) proposed VERB (O) model NOUN (O) can VERB (O) easily ADV (O) be AUX (O) distinguished ADJ (O) from ADP (O) [real NOUN (B) voices NOUN (I)] . 
Synthesizing PROPN (O) natural ADJ (O) [speech NOUN (B)] requires VERB (O) training NOUN (O) on ADP (O) a NOUN (O) large ADJ (O) number NOUN (O) of ADP (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)]-transcript PROPN pairs NOUN , (O) and CCONJ (O) supporting VERB (O) [many ADJ (B) speakers NOUN (I)] usually ADV (O) uses VERB (O) tens PROPN (O) of ADP (O) minutes NOUN (O) of ADP (O) [training NOUN (B) data NOUN (I)] per ADP (O) speaker NOUN . (O) 
Recording NOUN (O) a NOUN (O) large ADJ (O) amount NOUN (O) of ADP (O) high ADJ (O) [quality NOUN (B) data NOUN (I)] for ADP (O) [many ADJ (B) speakers NOUN (I)] is AUX (O) impractical ADJ . (O) 
Our DET (O) approach NOUN (O) is AUX (O) to ADP (O) [decouple NOUN (B) speaker NOUN (I)] modeling VERB (O) from ADP (O) [speech NOUN (B) synthesis NOUN (I)] by ADP (O) independently ADV (O) training NOUN (O) a NOUN (O) speaker NOUN - discriminative ADJ (O) embedding NOUN (O) network NOUN (O) that SCONJ (O) captures NOUN (O) the DET (O) space NOUN (O) of ADP (O) [speaker NOUN (B) characteristics NOUN (I)] and CCONJ (O) training NOUN (O) a NOUN (O) high ADJ (O) quality NOUN (O) [TTS PROPN (B) model NOUN (I)] on ADP (O) a NOUN (O) [smaller ADJ (B) dataset NOUN (I)] conditioned VERB (O) on ADP (O) the DET (O) representation NOUN (O) learned VERB (O) by ADP (O) the DET (O) first ADJ (O) network NOUN . (O) 
Decoupling NOUN (O) the DET (O) networks NOUN (O) enables VERB (O) them PRON (O) to ADP (O) be AUX (O) trained VERB (O) on ADP (O) [independent ADJ (B) data NOUN (I)] , which DET (O) reduces VERB (O) the DET (O) need NOUN (O) to ADP (O) obtain VERB (O) high ADJ (O) quality NOUN (O) [multispeaker NOUN (B) training NOUN (I) data NOUN (I)] . 
We PRON (O) train NOUN (O) the DET (O) speaker NOUN (O) embedding NOUN (O) network NOUN (O) on ADP (O) a NOUN (O) [speaker NOUN (B) verification NOUN (I)] task NOUN (O) to ADP (O) determine NOUN (O) if SCONJ (O) two NUM (O) different ADJ (O) utterances VERB (O) were AUX (O) spoken VERB (O) by ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] . 
In ADP (O) contrast NOUN (O) to ADP (O) the DET (O) subsequent ADJ (O) [TTS PROPN (B) model NOUN (I)] , this DET (O) network NOUN (O) is AUX (O) trained VERB (O) on ADP (O) [untranscribed ADJ (B) speech NOUN (I)] containing VERB (O) reverberation NOUN (O) and CCONJ (O) background NOUN (O) noise NOUN (O) from ADP (O) a NOUN (O) large ADJ (O) number NOUN (O) of ADP (O) speakers NOUN . (O) 
We PRON (O) demonstrate NOUN (O) that SCONJ (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] and CCONJ (O) synthesis NOUN (O) networks NOUN (O) can VERB (O) be AUX (O) trained VERB (O) on ADP (O) unbalanced ADJ (O) and CCONJ (O) disjoint NOUN (O) sets VERB (O) of ADP (O) speakers NOUN (O) and CCONJ (O) still ADV (O) generalize VERB (O) well INTJ . (O) 
We PRON (O) train NOUN (O) the DET (O) synthesis NOUN (O) network NOUN (O) on ADV . (O) 
2000 NUM (O) speakers NOUN (O) and CCONJ (O) show NOUN (O) that SCONJ (O) training NOUN (O) the DET (O) [encoder NOUN (B)] on ADP (O) a NOUN (O) much ADJ (O) larger ADJ (O) set NOUN (O) of ADP (O) 18000 NUM (O) speakers NOUN (O) improves VERB (O) adaptation NOUN (O) quality NOUN , (O) and CCONJ (O) further NOUN (O) enables VERB (O) synthesis NOUN (O) of ADP (O) completely ADV (O) [novel NOUN (B) speakers NOUN (I)] by ADP (O) sampling NOUN (O) from ADP (O) the DET (O) embedding NOUN (O) prior ADV . (O) 
There PRON (O) has AUX (O) been AUX (O) significant ADJ (O) interest NOUN (O) in ADP (O) [end NOUN - to ADP - end NOUN (B) training NOUN (I)] of ADP (O) [TTS PROPN (B) models NOUN (I)] , which DET (O) are AUX (O) trained VERB (O) directly ADV (O) from ADP (O) text-[audio PUNCT (B) pairs NOUN (I)] , without ADP (O) depending VERB (O) on ADP (O) hand NOUN (O) crafted VERB (O) intermediate ADJ (O) representations NOUN . (O) 
[Tacotron PROPN (B) 2 NUM (I)] used VERB (O) [WaveNet PROPN (B)] as SCONJ (O) a NOUN (O) [vocoder NOUN (B)] to PART (O) invert ADJ (O) [spectrograms NOUN (B)] generated VERB (O) by ADP (O) an DET (O) [encoder NOUN - decoder NOUN (B) architecture NOUN (I)] with ADP (O) attention NOUN , (O) obtaining VERB (O) naturalness NOUN (O) approaching VERB (O) that SCONJ (O) of ADP (O) human NOUN (O) [speech NOUN (B)] by ADP (O) combining VERB (O) Tacotron’sprosody NOUN (O) with ADP (O) [WaveNet PROPN (B)] ’s PART [audio NOUN (B) quality NOUN (I)] . 
It PRON (O) only ADV (O) supported VERB (O) a NOUN (O) [single ADJ (B) speaker NOUN (I)] . 
Gibiansky PROPN (O) et NOUN (O) al PROPN . (O) ntroduced VERB (O) a NOUN (O) multispeaker NOUN (O) variation NOUN (O) of ADP (O) [Tacotron PROPN (B)] which DET (O) learned VERB (O) [low ADJ - dimensional ADJ (B) speaker NOUN (I)] embedding VERB (O) for ADP (O) each DET (O) [training NOUN (B) speaker NOUN (I)] . 
[Deep ADJ (B) Voice PROPN (I)] 3proposed NUM (O) a NOUN (O) fully ADV (O) [convolutional NOUN (B) encoder NOUN - decoder NOUN (I) architecture NOUN (I)] which DET (O) scaled VERB (O) up NOUN (O) to ADP (O) support NOUN (O) over ADP (O) 2,400 NUM (O) speakers NOUN (O) from ADP (O) [LibriSpeech PROPN (B)] . 
These DET (O) systems NOUN (O) learn VERB (O) a NOUN (O) fixed VERB (O) set NOUN (O) of ADP (O) [speaker NOUN (B) embeddings NOUN (I)] and CCONJ (O) therefore ADV (O) only ADV (O) support NOUN (O) synthesis NOUN (O) of ADP (O) voices NOUN (O) seen VERB (O) during ADP (O) training NOUN . (O) 
In ADP (O) contrast NOUN , (O) VoiceLoop PROPN (O) proposed VERB (O) a NOUN (O) novel NOUN (O) architecture NOUN (O) based VERB (O) on ADP (O) a NOUN (O) fixed VERB (O) size NOUN (O) memory NOUN (O) buffer NOUN (O) which DET (O) can VERB (O) generate NOUN (O) [speech NOUN (B)] from ADP (O) voices NOUN (O) unseen ADJ (O) during ADP (O) training NOUN . (O) 
Obtaining VERB (O) good ADJ (O) results VERB (O) required VERB (O) tens PROPN (O) of ADP (O) minutes NOUN (O) of ADP (O) enrollment NOUN (O) [speech NOUN (B)] and CCONJ (O) transcripts NOUN (O) for ADP (O) a NOUN (O) [new PROPN (B) speaker NOUN (I)] . 
Recent ADJ (O) extensions NOUN (O) have AUX (O) enabled VERB (O) few-[shot PROPN (B) speaker NOUN (I)] adaptation NOUN (O) where ADV (O) only ADV (O) a NOUN (O) few ADJ (O) seconds NOUN (O) of ADP (O) [speech NOUN (B)] per ADP (O) speaker NOUN (O) (without ADP (O) transcripts NOUN) (O) can VERB (O) be AUX (O) used VERB (O) to ADP (O) generate NOUN (O) new ADJ (O) [speech NOUN (B)] in ADP (O) that SCONJ (O) speaker NOUN ’s PUNCT (O) voice NOUN . (O) 
extends VERB (O) [Deep ADJ (B) Voice PROPN (I)] 3 NUM , (O) comparing VERB (O) a NOUN (O) [speaker NOUN (B) adaptation NOUN (I)] method NOUN (O) similar ADJ (O) to ADP (O) where ADV (O) the DET (O) model NOUN (O) parameters NOUN (O) (including VERB (O) [speaker NOUN (B) embedding NOUN (I)]) are AUX (O) fine ADV - tuned VERB (O) on ADP (O) a NOUN (O) small ADJ (O) amount NOUN (O) of ADP (O) [adaptation NOUN (B) data NOUN (I)] to PART (O) a NOUN (O) [speaker NOUN (B) encoding NOUN (I)] method NOUN (O) which DET (O) uses VERB (O) a NOUN (O) [neural NOUN (B) network NOUN (I)] to PART (O) predict VERB (O) speaker NOUN (O) embedding NOUN (O) directly ADV (O) from ADP (O) a NOUN (O) [spectrogram NOUN (B)] . 
The DET (O) latter ADJ (O) approach NOUN (O) is AUX (O) significantly ADV (O) [more ADJ (B) data NOUN (I)] efficient ADJ , (O) obtaining VERB (O) higher ADJ (O) naturalness NOUN (O) using VERB (O) small ADJ (O) amounts VERB (O) of ADP (O) [adaptation NOUN (B) data NOUN (I)] , in ADP (O) as SCONJ (O) few ADJ (O) as SCONJ (O) one NUM (O) or CCONJ (O) two NUM (O) utterances VERB . (O) 
It PRON (O) is AUX (O) also ADV (O) significantly ADV (O) more ADJ (O) computationally ADV (O) efficient ADJ (O) since SCONJ (O) it PRON (O) does AUX (O) not PART (O) require VERB (O) hundreds NOUN (O) of ADP (O) backpropagation NOUN (O) iterations NOUN . (O) 
Nachmani PROPN (O) et NOUN (O) al PROPN . (O)     similarly ADV (O) extended ADJ (O) VoiceLoop PROPN (O) to ADP (O) utilize VERB (O) a NOUN (O) [target NOUN (B) speaker NOUN (I)] encoding VERB (O) network NOUN (O) to ADP (O) predict VERB (O) a NOUN (O) [speaker NOUN (B) embedding NOUN (I)] . 
This DET (O) network NOUN (O) is AUX (O) trained VERB (O) jointly ADV (O) with ADP (O) the DET (O) synthesis NOUN (O) network NOUN (O) using VERB (O) a NOUN (O) contrastive ADJ (O) triplet NOUN (O) loss NOUN (O) to ADP (O) ensure VERB (O) that SCONJ (O) embeddings NOUN (O) predicted VERB (O) from ADP (O) utterances VERB (O) by ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] are AUX (O) closer ADV (O) than SCONJ (O) embeddings NOUN (O) computed VERB (O) from ADP (O) [different ADJ (B) speakers NOUN (I)] . 
In ADP (O) addition NOUN , (O) a NOUN (O) cycle NOUN - consistency NOUN (O) loss NOUN (O) is AUX (O) used VERB (O) to ADP (O) ensure VERB (O) that DET (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] encodes VERB (O) to ADP (O) a NOUN (O) similar ADJ (O) embedding NOUN (O) as SCONJ (O) the DET (O) adaptation NOUN (O) utterance NOUN . (O) 
A PROPN (O) similar ADJ (O) [spectrogram NOUN (B) encoder NOUN (I) network NOUN (I)] , trained VERB (O) without ADP (O) a NOUN (O) triplet NOUN (O) loss NOUN , (O) was AUX (O) shown VERB (O) to ADP (O) work NOUN (O) for ADP (O) transferring VERB (O) [target NOUN (B) prosody NOUN (I)] to PART (O) [synthesized VERB (B) speech NOUN (I)] . 
In ADP (O) this DET (O) paper NOUN (O) we PRON (O) demonstrate NOUN (O) that SCONJ (O) training NOUN (O) a NOUN (O) similar ADJ (O) [encoder NOUN (B)] to PART (O) discriminate NOUN (O) between ADP (O) speakers NOUN (O) leads VERB (O) to ADP (O) reliable ADJ (O) transfer NOUN (O) of ADP (O) [speaker NOUN (B) characteristics NOUN (I)] . 
Our DET (O) work NOUN (O) is AUX (O) most ADJ (O) similar ADJ (O) to ADP (O) the DET (O) [speaker NOUN (B) encoding NOUN (I)] models NOUN (O) in ADP , (O) except SCONJ (O) that SCONJ (O) we PRON (O) utilize VERB (O) a NOUN (O) network NOUN (O) independently ADV - trained VERB (O) for ADP (O) a NOUN (O) [speaker NOUN (B) verification NOUN (I)] task NOUN (O) on ADP (O) a NOUN (O) [large ADJ (B) dataset NOUN (I)] of ADP (O) [untranscribed ADJ (B) audio NOUN (I)] from ADP (O) tens PROPN (O) of ADP (O) thousands NOUN (O) of ADP (O) speakers NOUN , (O) using VERB (O) a NOUN (O) state NOUN - of ADP - the DET - art NOUN (O) generalized VERB (O) [end NOUN - to ADP - end NOUN (B) loss NOUN (I)] . 
incorporated ADJ (O) a NOUN (O) [similar ADJ (B) speaker NOUN (I)]-discriminative NOUN representation NOUN (O) into ADP (O) their DET (O) model NOUN , (O) however ADV (O) all DET (O) components NOUN (O) were AUX (O) trained VERB (O) jointly ADV . (O) 
In ADP (O) contrast NOUN , (O) we PRON (O) explore VERB (O) transfer NOUN (O) learning NOUN (O) from ADP (O) a NOUN (O) pre VERB - trained ADJ (O) [speaker NOUN (B) verification NOUN (I)] model NOUN . (O) 
Doddipatla PROPN (O) et NOUN (O) al PROPN . (O) used VERB (O) a NOUN (O) similar ADJ (O) transfer NOUN (O) learning NOUN (O) configuration NOUN (O) where ADV (O) a NOUN (O) [speaker NOUN (B) embedding NOUN (I)] computed VERB (O) from ADP (O) a NOUN (O) pre VERB - trained ADJ (O) [speaker NOUN (B) classifier NOUN (I)] was AUX (O) used VERB (O) to ADP (O) condition NOUN (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] . 
In ADP (O) this DET (O) paper NOUN (O) we PRON (O) utilize VERB (O) an DET (O) [end NOUN - to ADP - end NOUN (B) synthesis NOUN (I) network NOUN (I)] which DET (O) does AUX (O) not PART (O) rely VERB (O) on ADP (O) intermediate ADJ (O) [linguistic NOUN (B) features VERB (I)] , and CCONJ (O) a NOUN (O) substantially ADV (O) [different ADJ (B) speaker NOUN (I) embedding VERB (I) network NOUN (I)] which DET (O) is AUX (O) not PART (O) limited ADJ (O) to ADP (O) a NOUN (O) closed ADJ (O) set NOUN (O) of ADP (O) speakers NOUN . (O) 
Furthermore ADV , (O) we PRON (O) analyze VERB (O) how ADV (O) quality NOUN (O) varies VERB (O) with ADP (O) the DET (O) number NOUN (O) of ADP (O) speakers NOUN (O) in ADP (O) the DET (O) training NOUN (O) set VERB , (O) and CCONJ (O) find VERB (O) that SCONJ (O) zero NUM - shot NOUN (O) transfer NOUN (O) requires VERB (O) training NOUN (O) on ADP (O) thousands NOUN (O) of ADP (O) speakers NOUN , (O) many ADJ (O) more ADJ (O) than SCONJ (O) were AUX (O) used VERB (O) in ADP . (O) 

 [Multispeaker PROPN (B) speech NOUN (I) synthesis NOUN (I) model NOUN (I)] 

 Our DET (O) system NOUN (O) is AUX (O) composed VERB (O) of ADP (O) three NUM (O) independently ADV (O) trained VERB (O) [neural NOUN (B) networks NOUN (I)] , illustrated VERB (O) in ADP (O) Figure NOUN (O) 1 NUM (O) : (1 X) (O) a NOUN (O) [recurrent NOUN (B) speaker NOUN (I) encoder NOUN (I)] , based VERB (O) on ADV , (O) which DET (O) computes VERB (O) a NOUN (O) fixed VERB (O) dimensional ADJ (O) [vector NOUN (B)] from ADP (O) a NOUN (O) [speech NOUN (B) signal NOUN (I)] , (2 X) (O) a NOUN (O) [sequence NOUN - to ADP - sequence NOUN (B) synthesizer NOUN (I)] , based VERB (O) on ADV , (O) which DET (O) predicts VERB (O) a NOUN (O) [mel X (B) spectrogram PROPN (I)] from ADP (O) a NOUN (O) [sequence NOUN (B) of ADP (I) grapheme PROPN (I)] or CCONJ (O) [phoneme NOUN (B)] inputs VERB , (O) conditioned VERB (O) on ADP (O) the DET (O) speaker NOUN (O) embedding NOUN (O) [vector NOUN (B)] , and CCONJ (O) (3 X) (O) an DET (O) [autoregressive ADJ (B) WaveNet PROPN (I) vocoder NOUN (I)] , which DET (O) converts NOUN (O) the DET (O) [spectrogram NOUN (B)] into ADP (O) time NOUN (O) domain NOUN (O) [waveforms NOUN (B)] . 
                                                
 Figure PROPN (O) : Model NOUN (O) overview NOUN . (O) Each DET (O) of ADP (O) the DET (O) three NUM (O) components NOUN (O) are AUX (O) trained VERB (O) independently ADV . (O) 

 [Speaker PROPN (B) encoder NOUN (I)] 

 The DET (O) [speaker NOUN (B) encoder NOUN (I)] is AUX (O) used VERB (O) to ADP (O) condition NOUN (O) the DET (O) synthesis NOUN (O) network NOUN (O) on ADP (O) a NOUN (O) reference NOUN (O) [speech NOUN (B) signal NOUN (I)] from ADP (O) the DET (O) desired VERB (O) [target NOUN (B) speaker NOUN (I)] . 
Critical PROPN (O) to ADP (O) good ADJ (O) generalization NOUN (O) is AUX (O) the DET (O) use NOUN (O) of ADP (O) a NOUN (O) representation NOUN (O) which DET (O) captures NOUN (O) the DET (O) characteristics NOUN (O) of ADP (O) [different ADJ (B) speakers NOUN (I)] , and CCONJ (O) the DET (O) ability NOUN (O) to ADP (O) identify VERB (O) these DET (O) characteristics NOUN (O) using VERB (O) only ADV (O) a NOUN (O) short ADJ (O) adaptation NOUN (O) signal NOUN , (O) independent ADJ (O) of ADP (O) its DET (O) [phonetic NOUN (B) content NOUN (I)] and CCONJ (O) background NOUN (O) noise NOUN . (O) 
These DET (O) requirements NOUN (O) are AUX (O) satisfied ADJ (O) using VERB (O) a NOUN (O) speaker NOUN - discriminative ADJ (O) model NOUN (O) trained VERB (O) on ADP (O) a NOUN (O) text-[independent PUNCT (B) speaker NOUN (I)] verification NOUN (O) task NOUN . (O) 
We PRON (O) follow VERB , (O) which DET (O) proposed VERB (O) a NOUN (O) highly ADV (O) scalable ADJ (O) and CCONJ (O) accurate ADJ (O) [neural NOUN (B) network NOUN (I) framework NOUN (I)] for ADP (O) [speaker NOUN (B) verification NOUN (I)] . 
The DET (O) network NOUN (O) maps NOUN (O) a NOUN (O) sequence NOUN (O) of ADP (O) [log PROPN - mel PROPN (B) spectrogram PROPN (I) frames VERB (I)] computed VERB (O) from ADP (O) a NOUN (O) [speech NOUN (B)] utterance NOUN (O) of ADP (O) arbitrary ADJ (O) length NOUN , (O) to ADP (O) a NOUN (O) fixed VERB - dimensional ADJ (O) embedding NOUN (O) [vector NOUN (B)] , known VERB (O) as SCONJ (O) d-[vector PROPN (B)] . 
The DET (O) network NOUN (O) is AUX (O) trained VERB (O) to ADP (O) optimize NOUN (O) a NOUN (O) generalized VERB (O) [end NOUN - to ADP - end NOUN (B) speaker NOUN (I) verification NOUN (I)] loss NOUN , (O) so CCONJ (O) that SCONJ (O) embeddings NOUN (O) of ADP (O) utterances VERB (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] have AUX (O) high ADJ (O) cosine NOUN (O) similarity NOUN , (O) while SCONJ (O) those DET (O) of ADP (O) utterances VERB (O) from ADP (O) [different ADJ (B) speakers NOUN (I)] are AUX (O) far ADV (O) apart ADJ (O) in ADP (O) the DET (O) embedding NOUN (O) space NOUN . (O) 
The DET (O) [training NOUN (B) dataset NOUN (I)] consists VERB (O) of ADP (O) [speech NOUN (B) audio NOUN (I)] examples VERB (O) segmented VERB (O) into ADP (O) 1.6 NUM (O) seconds NOUN (O) and CCONJ (O) [associated PROPN (B) speaker NOUN (I)] identity NOUN (O) labels NOUN (O) ; no INTJ (O) transcripts NOUN (O) are AUX (O) used VERB . (O) 
Input NOUN (O) 40-channel NUM (O) [log PROPN - mel PROPN (B) spectrograms VERB (I)] are AUX (O) passed VERB (O) to ADP (O) a NOUN (O) network NOUN (O) consisting VERB (O) of ADP (O) a NOUN (O) stack NOUN (O) of ADP (O) 3 NUM (O) [LSTM PROPN (B) layers NOUN (I)] of ADP (O) 768 NUM (O) cells NOUN , (O) each DET (O) followed VERB (O) by ADP (O) a NOUN (O) projection NOUN (O) to ADP (O) 256 NUM (O) dimensions NOUN . (O) 
The DET (O) final ADJ (O) embedding NOUN (O) is AUX (O) created VERB (O) by ADP (O) L2 PROPN (O) -normalizing NOUN (O) the DET (O) output NOUN (O) of ADP (O) the DET (O) top NOUN (O) layer NOUN (O) at ADP (O) the DET (O) final ADJ (O) frame NOUN . (O) 
During ADP (O) inference NOUN , (O) an DET (O) arbitrary ADJ (O) length NOUN (O) utterance NOUN (O) is AUX (O) broken VERB (O) into ADP (O) 800ms PROPN (O) windows NOUN , (O) overlapped VERB (O) by ADP (O) 50 NUM (O) % . (O) 
The DET (O) network NOUN (O) is AUX (O) run NOUN (O) independently ADV (O) on ADP (O) each DET (O) window NOUN , (O) and CCONJ (O) the DET (O) outputs VERB (O) are AUX (O) averaged VERB (O) and CCONJ (O) normalized ADJ (O) to ADP (O) create VERB (O) the DET (O) final ADJ (O) utterance NOUN (O) embedding NOUN . (O) 
Although SCONJ (O) the DET (O) network NOUN (O) is AUX (O) not PART (O) optimized VERB (O) directly ADV (O) to ADP (O) learn VERB (O) a NOUN (O) representation NOUN (O) which DET (O) captures NOUN (O) [speaker NOUN (B) characteristics NOUN (I)] relevant ADJ (O) to ADP (O) synthesis NOUN , (O) we PRON (O) find VERB (O) that SCONJ (O) training NOUN (O) on ADP (O) a NOUN (O) [speaker NOUN (B) discrimination NOUN (I)] task NOUN (O) leads VERB (O) to ADP (O) an DET (O) embedding NOUN (O) which DET (O) is AUX (O) directly ADV (O) suitable ADJ (O) for ADP (O) conditioning NOUN (O) the DET (O) synthesis NOUN (O) network NOUN (O) on ADP (O) [speaker NOUN (B) identity NOUN (I)] . 

 Synthesizer PROPN (O) 

 We PRON (O) extend VERB (O) the DET (O) recurrent NOUN (O) [sequence NOUN - to ADP - sequence NOUN (B)] with ADP (O) attention NOUN (O) [Tacotron PROPN (B) 2 NUM (I) architecture NOUN (I)] to PART (O) support NOUN (O) [multiple NOUN (B) speakers NOUN (I)] following VERB (O) a NOUN (O) scheme NOUN (O) similar ADJ (O) to PART . (O) 
An PROPN (O) embedding NOUN (O) [vector NOUN (B)] for ADP (O) the DET (O) [target NOUN (B) speaker NOUN (I)] is AUX (O) concatenated VERB (O) with ADP (O) the DET (O) synthesizer NOUN (O) [encoder NOUN (B) output NOUN (I)] at ADP (O) each DET (O) time NOUN (O) step NOUN . (O) 
In ADP (O) contrast NOUN (O) to PART , (O) we PRON (O) find VERB (O) that SCONJ (O) simply ADV (O) passing NOUN (O) embeddings NOUN (O) to ADP (O) the DET (O) [attention NOUN (B) layer NOUN (I)] , as SCONJ (O) in ADP (O) Figure NOUN (O) 1 NUM , (O) converges NOUN (O) across ADP (O) [different ADJ (B) speakers NOUN (I)] . 
We PRON (O) compare VERB (O) two NUM (O) variants NOUN (O) of ADP (O) this DET (O) model NOUN , (O) one NUM (O) which DET (O) computes VERB (O) the DET (O) embedding NOUN (O) using VERB (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] , and CCONJ (O) a NOUN (O) baseline NOUN (O) which DET (O) optimizes VERB (O) a NOUN (O) fixed VERB (O) embedding NOUN (O) for ADP (O) each DET (O) speaker NOUN (O) in ADP (O) the DET (O) training NOUN (O) set VERB , (O) essentially ADV (O) learning NOUN (O) a NOUN (O) lookup NOUN (O) table NOUN (O) of ADP (O) [speaker NOUN (B) embeddings NOUN (I)] similar ADJ (O) to PART . (O) 
The DET (O) synthesizer NOUN (O) is AUX (O) trained VERB (O) on ADP (O) pairs NOUN (O) of ADP (O) text NOUN (O) transcript NOUN (O) and CCONJ (O) [target NOUN (B) audio NOUN (I)] . 
At ADP (O) the DET (O) input NOUN , (O) we PRON (O) map NOUN (O) the DET (O) text NOUN (O) to ADP (O) a NOUN (O) [sequence NOUN (B) of ADP (I) phonemes PROPN (I)] , which DET (O) leads VERB (O) to ADP (O) faster ADV (O) convergence NOUN (O) and CCONJ (O) improved VERB (O) pronunciation NOUN (O) of ADP (O) rare ADJ (O) words NOUN (O) and CCONJ (O) proper NOUN (O) nouns NOUN . (O) 
The DET (O) network NOUN (O) is AUX (O) trained VERB (O) in ADP (O) a NOUN (O) transfer NOUN (O) learning NOUN (O) configuration NOUN , (O) using VERB (O) a NOUN (O) pretrained VERB (O) [speaker NOUN (B) encoder NOUN (I)] (whose DET (O) parameters VERB (O) are AUX (O) frozen ADJ) (O) to ADP (O) extract NOUN (O) a NOUN (O) speaker NOUN (O) embedding NOUN (O) from ADP (O) the DET (O) [target NOUN (B) audio NOUN (I)] , i.e. X (O) the DET (O) [speaker NOUN (B) reference NOUN (I)] signal NOUN (O) is AUX (O) the DET (O) same ADJ (O) as SCONJ (O) the DET (O) [target NOUN (B) speech NOUN (I)] during ADP (O) training NOUN . (O) 
No NOUN (O) [explicit NOUN (B) speaker NOUN (I)] identifier NOUN (O) labels NOUN (O) are AUX (O) used VERB (O) during ADP (O) training NOUN . (O) 
[Target NOUN (B) spectrogram NOUN (I) features VERB (I)] are AUX (O) computed VERB (O) from ADP (O) 50ms NOUN (O) windows PROPN (O) computed VERB (O) with ADP (O) a NOUN (O) 12.5ms PROPN (O) step NOUN , (O) passed VERB (O) through ADP (O) an DET (O) 80-channel NUM (O) [mel ADJ - scale NOUN (B) filterbank NOUN (I)] followed VERB (O) by ADP (O) log NOUN (O) dynamic PROPN (O) range NOUN (O) compression NOUN . (O) 
We PRON (O) extend VERB (O) by ADP (O) augmenting VERB (O) the DET (O) L2 NOUN (O) loss NOUN (O) on ADP (O) the DET (O) predicted VERB (O) [spectrogram NOUN (B)] with ADP (O) an DET (O) additional ADJ (O) L1 PROPN (O) loss NOUN . (O) 
In ADP (O) practice NOUN , (O) we PRON (O) found VERB (O) this DET (O) combined VERB (O) loss NOUN (O) to ADP (O) be AUX (O) more ADJ (O) robust ADJ (O) on ADP (O) noisy NOUN (O) [training NOUN (B) data NOUN (I)] . 
In ADP (O) contrast NOUN (O) to PART , (O) we PRON (O) do AUX (O) n’t PROPN (O) introduce VERB (O) additional ADJ (O) loss NOUN (O) terms NOUN (O) based VERB (O) on ADP (O) the DET (O) [speaker NOUN (B) embedding NOUN (I)] . 

 See VERB (O) https://google.github.io/tacotron/publications/speaker_adaptation NOUN (O) for ADP (O) samples NOUN . (O) 

 Figure NOUN (O) : Example NOUN (O) synthesis NOUN (O) of ADP (O) a NOUN (O) sentence NOUN (O) in ADP (O) [different ADJ (B) voices NOUN (I)] using VERB (O) the DET (O) proposed VERB (O) system NOUN . (O) [Mel PROPN (B) spectrograms VERB (I)] are AUX (O) visualized VERB (O) for ADP (O) reference NOUN (O) utterances VERB (O) used VERB (O) to ADP (O) generate NOUN (O) [speaker NOUN (B) embeddings NOUN (I)] (left NOUN) , (O) and CCONJ (O) the DET (O) corresponding VERB (O) synthesizer NOUN (O) outputs NOUN (O) (right INTJ) . (O) 
The DET (O) [text NOUN - to ADP - spectrogram NOUN (B) alignment NOUN (I)] is AUX (O) shown VERB (O) in ADP (O) red NOUN . (O) 
Three NUM (O) speakers NOUN (O) held VERB (O) out NOUN (O) of ADP (O) the DET (O) train NOUN (O) sets VERB (O) are AUX (O) used VERB (O) : one NUM (O) male NOUN (O) (top NOUN) (O) and CCONJ (O) two NUM (O) female NOUN (O) (center NOUN (O) and CCONJ (O) bottom NOUN) . (O) 

 [Neural PROPN (B) vocoder NOUN (I)] 

 We PRON (O) use NOUN (O) the DET (O) sample NOUN - by ADP - sample NOUN (O) [autoregressive ADJ (B) WaveNet PROPN (I)] as SCONJ (O) a NOUN (O) [vocoder NOUN (B)] to PART (O) invert ADJ (O) synthesized VERB (O) [mel X (B) spectrograms VERB (I)] emitted VERB (O) by ADP (O) the DET (O) synthesis NOUN (O) network NOUN (O) into ADP (O) time NOUN - domain NOUN (O) [waveforms NOUN (B)] . 
The DET (O) architecture NOUN (O) is AUX (O) the DET (O) same ADJ (O) as SCONJ (O) that SCONJ (O) described VERB (O) in ADP , (O) composed VERB (O) of ADP (O) 30 NUM (O) dilated VERB (O) convolution NOUN (O) layers NOUN . (O) 
The DET (O) network NOUN (O) is AUX (O) not PART (O) directly ADV (O) conditioned VERB (O) on ADP (O) the DET (O) output NOUN (O) of ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
The DET (O) [mel X (B) spectrogram PROPN (I)] predicted VERB (O) by ADP (O) the DET (O) [synthesizer NOUN (B) network NOUN (I)] captures NOUN (O) all DET (O) of ADP (O) the DET (O) relevant ADJ (O) detail NOUN (O) needed VERB (O) for ADP (O) high ADJ (O) quality NOUN (O) synthesis NOUN (O) of ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) voices NOUN , (O) allowing VERB (O) a NOUN (O) [multispeaker NOUN (B) vocoder NOUN (I)] to PART (O) be AUX (O) constructed VERB (O) by ADP (O) simply ADV (O) training NOUN (O) on ADP (O) data NOUN (O) from ADP (O) [many ADJ (B) speakers NOUN (I)] . 

 Inference NOUN (O) and CCONJ (O) zero-[shot PROPN (B) speaker NOUN (I)] adaptation NOUN (O) 

 During ADP (O) inference NOUN (O) the DET (O) model NOUN (O) is AUX (O) conditioned VERB (O) using VERB (O) arbitrary ADJ (O) [untranscribed ADJ (B) speech NOUN (I) audio NOUN (I)] , which DET (O) does AUX (O) not PART (O) need NOUN (O) to ADP (O) match NOUN (O) the DET (O) text NOUN (O) to ADP (O) be AUX (O) synthesized VERB . (O) 
Since SCONJ (O) the DET (O) speaker NOUN (O) characteristics NOUN (O) to ADP (O) use NOUN (O) for ADP (O) synthesis NOUN (O) are AUX (O) inferred VERB (O) from ADP (O) [audio NOUN (B)] , it PRON (O) can VERB (O) be AUX (O) conditioned VERB (O) on ADP (O) [audio NOUN (B)] from ADP (O) speakers NOUN (O) that SCONJ (O) are AUX (O) outside ADV (O) the DET (O) training NOUN (O) set VERB . (O) 
In ADP (O) practice NOUN (O) we PRON (O) find VERB (O) that DET (O) using VERB (O) a NOUN (O) single ADJ (O) [audio NOUN (B) clip NOUN (I)] of ADP (O) a NOUN (O) few ADJ (O) seconds NOUN (O) duration NOUN (O) is AUX (O) sufficient ADJ (O) to ADP (O) synthesize VERB (O) new ADJ (O) [speech NOUN (B)] with ADP (O) the DET (O) corresponding VERB (O) [speaker NOUN (B) characteristics NOUN (I)] , representing VERB (O) zero NUM - shot NOUN (O) adaptation NOUN (O) to ADP (O) [novel NOUN (B) speakers NOUN (I)] . 
In ADP (O) Section NOUN (O) 3 NUM (O) we PRON (O) evaluate VERB (O) how ADV (O) well INTJ (O) this DET (O) process NOUN (O) generalizes VERB (O) to ADP (O) previously ADV (O) [unseen NOUN (B) speakers NOUN (I)] . 
An PROPN (O) example NOUN (O) of ADP (O) the DET (O) inference NOUN (O) process NOUN (O) is AUX (O) visualized VERB (O) in ADP (O) Figure NOUN (O) 2 NUM , (O) which DET (O) shows VERB (O) [spectrograms NOUN (B)] synthesized VERB (O) using VERB (O) several ADJ (O) different ADJ (O) 5 NUM (O) [second NOUN (B) speaker NOUN (I)] reference NOUN (O) utterances VERB . (O) 
Compared VERB (O) to ADP (O) those DET (O) of ADP (O) the DET (O) female NOUN (O) (center NOUN (O) and CCONJ (O) bottom NOUN) (O) speakers NOUN , (O) the DET (O) synthesized VERB (O) male NOUN (O) (top NOUN) (O) [speaker NOUN (B) spectrogram NOUN (I)] has AUX (O) noticeably ADV (O) lower ADJ (O) [fundamental ADJ (B) frequency NOUN (I)] , visible ADJ (O) in ADP (O) the DET (O) denser NOUN (O) harmonic PROPN (O) spacing NOUN (O) (horizontal NOUN (O) stripes PROPN) (O) in ADP (O) low NOUN (O) frequencies NOUN , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) formants NOUN , (O) visible ADJ (O) in ADP (O) the DET (O) mid NOUN - frequency ADJ (O) peaks VERB (O) present NOUN (O) during ADP (O) vowel NOUN (O) sounds VERB (O) such ADJ (O) as SCONJ (O) the DET (O) ‘ PUNCT (O) i PRON ’ PUNCT (O) at ADP (O) 0.3 NUM (O) seconds NOUN (O) – PUNCT (O) the DET (O) top NOUN (O) male NOUN (O) F2 PROPN (O) is AUX (O) in ADP (O) [mel X (B)] channel NOUN (O) 35 NUM , (O) whereas SCONJ (O) the DET (O) F2 PROPN (O) of ADP (O) the DET (O) [middle NOUN (B) speaker NOUN (I)] appears VERB (O) closer ADV (O) to ADP (O) channel NOUN (O) 40 NUM . (O) 
Similar PROPN (O) differences NOUN (O) are AUX (O) also ADV (O) visible ADJ (O) in ADP (O) sibilant NOUN (O) sounds VERB , (O) e.g. ADV (O) the DET (O) ‘s NOUN ’ PUNCT (O) at ADP (O) 0.4 NUM (O) seconds NOUN (O) contains VERB (O) more ADJ (O) energy NOUN (O) in ADP (O) lower ADJ (O) frequencies NOUN (O) in ADP (O) the DET (O) [male NOUN (B) voice NOUN (I)] than SCONJ (O) in ADP (O) the DET (O) [female NOUN (B) voices NOUN (I)] . 
Finally ADV , (O) the DET (O) characteristic NOUN (O) speaking VERB (O) rate NOUN (O) is AUX (O) also ADV (O) captured VERB (O) to ADP (O) some DET (O) extent NOUN (O) by ADP (O) the DET (O) speaker NOUN (O) embedding NOUN , (O) as SCONJ (O) can VERB (O) be AUX (O) seen VERB (O) by ADP (O) the DET (O) longer ADJ (O) signal NOUN (O) duration NOUN (O) in ADP (O) the DET (O) bottom NOUN (O) row NOUN (O) compared VERB (O) to ADP (O) the DET (O) top NOUN (O) two NUM . (O) 
Similar PROPN (O) observations NOUN (O) can VERB (O) be AUX (O) made VERB (O) about ADP (O) the DET (O) corresponding VERB (O) reference NOUN (O) utterance NOUN (O) [spectrograms NOUN (B)] in ADP (O) the DET (O) right ADV (O) column NOUN . (O) 

 Table NOUN (O) : [Speech NOUN (B) naturalness NOUN (I) Mean VERB (I) Opinion NOUN (I) Score PROPN (I)] ([MOS PROPN (B)]) with ADP (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN . (O) 


 Experiments NOUN (O) 

 We PRON (O) used VERB (O) two NUM (O) [public NOUN (B) datasets VERB (I)] for ADP (O) training NOUN (O) the DET (O) [speech NOUN (B) synthesis NOUN (I)] and CCONJ (O) [vocoder NOUN (B) networks NOUN (I)] . 
VCTK NOUN (O) contains VERB (O) 44 NUM (O) hours NOUN (O) of ADP (O) clean ADJ (O) [speech NOUN (B)] from ADP (O) 109 NUM (O) speakers NOUN , (O) the DET (O) majority NOUN (O) of ADP (O) which DET (O) have AUX (O) British PROPN (O) accents NOUN . (O) 
We PRON (O) downsampled VERB (O) the DET (O) [audio NOUN (B)] to PART (O) 24 NUM (O) kHz PROPN , (O) trimmed VERB (O) leading VERB (O) and CCONJ (O) trailing VERB (O) silence NOUN (O) (reducing VERB (O) the DET (O) median PROPN (O) duration NOUN (O) from ADP (O) 3.3 NUM (O) seconds NOUN (O) to ADP (O) 1.8 NUM (O) seconds NOUN) , (O) and CCONJ (O) split VERB (O) into ADP (O) three NUM (O) subsets NOUN (O) : train NOUN , (O) validation NOUN (O) (containing VERB (O) the DET (O) [same ADJ (B) speakers NOUN (I)] as SCONJ (O) the DET (O) train NOUN (O) set NOUN) (O) and CCONJ (O) test NOUN (O) (containing VERB (O) 11 NUM (O) speakers NOUN (O) held VERB (O) out NOUN (O) from ADP (O) the DET (O) train NOUN (O) and CCONJ (O) validation NOUN (O) sets NOUN) . (O) 
[LibriSpeech PROPN (B)] consists VERB (O) of ADP (O) the DET (O) union NOUN (O) of ADP (O) the DET (O) two NUM (O) “ PUNCT (O) clean ADJ (O) ” PUNCT (O) training NOUN (O) sets VERB , (O) comprising VERB (O) 436 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B)] from ADP (O) 1,172 NUM (O) speakers NOUN , (O) sampled VERB (O) at ADP (O) 16 NUM (O) kHz PROPN . (O) 
The DET (O) majority NOUN (O) of ADP (O) [speech NOUN (B)] is AUX (O) US PROPN (O) English PROPN , (O) however ADV (O) since SCONJ (O) it PRON (O) is AUX (O) sourced VERB (O) from ADP (O) [audio NOUN (B)] books NOUN , (O) the DET (O) tone NOUN (O) and CCONJ (O) style NOUN (O) of ADP (O) [speech NOUN (B)] can VERB (O) differ NOUN (O) significantly ADV (O) between ADP (O) utterances VERB (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] . 
We PRON (O) resegmented VERB (O) the DET (O) data NOUN (O) into ADP (O) shorter ADJ (O) utterances VERB (O) by ADP (O) force NOUN (O) aligning VERB (O) the DET (O) [audio NOUN (B)] to PART (O) the DET (O) transcript NOUN (O) using VERB (O) an DET (O) [ASR PROPN (B) model NOUN (I)] and CCONJ (O) breaking NOUN (O) segments NOUN (O) on ADP (O) silence NOUN , (O) reducing VERB (O) the DET (O) median PROPN (O) duration NOUN (O) from ADP (O) 14 NUM (O) to ADP (O) 5 NUM (O) seconds NOUN . (O) 
As SCONJ (O) in ADP (O) the DET (O) [original NOUN (B) dataset NOUN (I)] , there PRON (O) is AUX (O) no DET (O) punctuation NOUN (O) in ADP (O) transcripts NOUN . (O) 
The DET (O) [speaker NOUN (B) sets NOUN (I)] are AUX (O) completely ADV (O) disjoint NOUN (O) among ADP (O) the DET (O) train NOUN , (O) validation NOUN , (O) and CCONJ (O) test NOUN (O) sets NOUN . (O) 
Many ADJ (O) recordings VERB (O) in ADP (O) the DET (O) [LibriSpeech PROPN (B) clean ADJ (I) corpus PROPN (I)] contain VERB (O) noticeable ADJ (O) environmental ADJ (O) and CCONJ (O) stationary NOUN (O) background NOUN (O) noise NOUN . (O) 
We PRON (O) preprocessed ADJ (O) the DET (O) [target NOUN (B) spectrogram NOUN (I)] using VERB (O) a NOUN (O) simple ADJ (O) [spectral NOUN (B)] subtraction NOUN (O) denoising VERB (O) procedure NOUN , (O) where ADV (O) the DET (O) background NOUN (O) noise NOUN (O) [spectrum NOUN (B)] of ADP (O) an DET (O) utterance NOUN (O) was AUX (O) estimated VERB (O) as SCONJ (O) the DET (O) 10th NOUN (O) percentile NOUN (O) of ADP (O) the DET (O) energy NOUN (O) in ADP (O) each DET (O) frequency NOUN (O) band NOUN (O) across ADP (O) the DET (O) full ADJ (O) signal NOUN . (O) 
This DET (O) process NOUN (O) was AUX (O) only ADV (O) used VERB (O) on ADP (O) the DET (O) synthesis NOUN (O) target NOUN (O) ; the DET (O) original ADJ (O) noisy PROPN (O) [speech NOUN (B)] was AUX (O) passed VERB (O) to ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
We PRON (O) trained VERB (O) separate ADJ (O) synthesis NOUN (O) and CCONJ (O) [vocoder NOUN (B) networks NOUN (I)] for ADP (O) each DET (O) of ADP (O) these DET (O) two NUM (O) corpora PROPN . (O) 
Throughout PROPN (O) this DET (O) section NOUN , (O) we PRON (O) used VERB (O) synthesis NOUN (O) networks NOUN (O) trained VERB (O) on ADP (O) [phoneme NOUN (B)] inputs VERB , (O) in ADP (O) order NOUN (O) to ADP (O) control NOUN (O) for ADP (O) pronunciation NOUN (O) in ADP (O) subjective ADJ (O) evaluations NOUN . (O) 
For ADP (O) the DET (O) [VCTK NOUN (B) dataset NOUN (I)] , whose DET (O) [audio NOUN (B)] is AUX (O) quite ADV (O) clean ADJ , (O) we PRON (O) found VERB (O) that SCONJ (O) the DET (O) [vocoder NOUN (B)] trained VERB (O) on ADP (O) ground NOUN (O) truth NOUN (O) [mel X (B) spectrograms VERB (I)] worked VERB (O) well INTJ . (O) 
However ADV (O) for ADP (O) [LibriSpeech PROPN (B)] , which DET (O) is AUX (O) noisier NOUN , (O) we PRON (O) found VERB (O) it PRON (O) necessary ADJ (O) to ADP (O) train NOUN (O) the DET (O) [vocoder NOUN (B)] on ADP (O) [spectrograms NOUN (B)] predicted VERB (O) by ADP (O) the DET (O) [synthesizer NOUN (B) network NOUN (I)] . 
No NOUN (O) denoising VERB (O) was AUX (O) performed VERB (O) on ADP (O) the DET (O) [target NOUN (B) waveform PROPN (I)] for ADP (O) [vocoder NOUN (B) training NOUN (I)] . 
The DET (O) [speaker NOUN (B) encoder NOUN (I)] was AUX (O) trained VERB (O) on ADP (O) a NOUN (O) [proprietary ADJ (B) voice NOUN (I) search NOUN (I) corpus PROPN (I)] containing VERB (O) 36 NUM (O) M PROPN (O) utterances VERB (O) with ADP (O) median PROPN (O) duration NOUN (O) of ADP (O) 3.9 NUM (O) seconds NOUN (O) from ADP (O) 18000 NUM (O) [English PROPN (B) speakers NOUN (I)] in ADP (O) the DET (O) United PROPN (O) States PROPN . (O) 
This DET (O) dataset NOUN (O) is AUX (O) not PART (O) transcribed VERB , (O) but CCONJ (O) contains VERB (O) anonymized VERB (O) [speaker NOUN (B) identities NOUN (I)] . 
It PRON (O) is AUX (O) never ADV (O) used VERB (O) to ADP (O) train NOUN (O) synthesis NOUN (O) networks NOUN . (O) 
We PRON (O) primarily ADV (O) rely VERB (O) on ADP (O) crowdsourced VERB (O) [Mean PROPN (B) Opinion NOUN (I) Score PROPN (I) (MOS PROPN) (I) evaluations NOUN (I)] based VERB (O) on ADP (O) subjective ADJ (O) listening VERB (O) tests NOUN . (O) 
All DET (O) our DET (O) [MOS PROPN (B) evaluations NOUN (I)] are AUX (O) aligned VERB (O) to ADP (O) the DET (O) Absolute PROPN (O) Category NOUN (O) Rating NOUN (O) scale NOUN , (O) with ADP (O) rating NOUN (O) scores NOUN (O) from ADP (O) 1 NUM (O) to ADP (O) 5 NUM (O) in ADP (O) 0.5 NUM (O) point NOUN (O) increments NOUN . (O) 
We PRON (O) use NOUN (O) this DET (O) framework NOUN (O) to ADP (O) evaluate VERB (O) [synthesized VERB (B) speech NOUN (I)] along ADP (O) two NUM (O) dimensions NOUN (O) : its DET (O) naturalness NOUN (O) and CCONJ (O) similarity NOUN (O) to ADP (O) real NOUN (O) [speech NOUN (B)] from ADP (O) the DET (O) [target NOUN (B) speaker NOUN (I)] . 

 [Speech NOUN (B) naturalness NOUN (I)] 

 We PRON (O) compared VERB (O) the DET (O) naturalness NOUN (O) of ADP (O) [synthesized VERB (B) speech NOUN (I)] using VERB (O) synthesizers NOUN (O) and CCONJ (O) [vocoders NOUN (B)] trained VERB (O) on ADP (O) VCTK PROPN (O) and CCONJ (O) [LibriSpeech PROPN (B)] . 
We PRON (O) constructed VERB (O) an DET (O) evaluation NOUN (O) set NOUN (O) of ADP (O) 100 NUM (O) phrases NOUN (O) which DET (O) do AUX (O) not PART (O) appear VERB (O) in ADP (O) any DET (O) training NOUN (O) sets VERB , (O) and CCONJ (O) evaluated VERB (O) two NUM (O) sets VERB (O) of ADP (O) speakers NOUN (O) for ADP (O) each DET (O) model NOUN (O) : one NUM (O) composed VERB (O) of ADP (O) speakers NOUN (O) included VERB (O) in ADP (O) the DET (O) train NOUN (O) set NOUN (O) (Seen VERB) , (O) and CCONJ (O) another DET (O) composed VERB (O) of ADP (O) those DET (O) that SCONJ (O) were AUX (O) held VERB (O) out NOUN (O) (Unseen PROPN) . (O) 
We PRON (O) used VERB (O) 11 NUM (O) seen VERB (O) and CCONJ (O) [unseen NOUN (B) speakers NOUN (I)] for ADP (O) VCTK PROPN (O) and CCONJ (O) 10 NUM (O) seen VERB (O) and CCONJ (O) [unseen NOUN (B) speakers NOUN (I)] for ADP (O) [LibriSpeech PROPN (B)] (Appendix PROPN (O) D PROPN) . (O) 
For ADP (O) each DET (O) speaker NOUN , (O) we PRON (O) randomly ADV (O) chose VERB (O) one NUM (O) utterance NOUN (O) with ADP (O) duration NOUN (O) of ADP (O) about ADP (O) 5 NUM (O) seconds NOUN (O) to ADP (O) use NOUN (O) to ADP (O) compute NOUN (O) the DET (O) [speaker NOUN (B) embedding NOUN (I)] (see VERB (O) Appendix PROPN (O) C PROPN) . (O) 
Each DET (O) phrase NOUN (O) was AUX (O) synthesized VERB (O) for ADP (O) each DET (O) speaker NOUN , (O) for ADP (O) a NOUN (O) total NOUN (O) of ADP (O) about ADP (O) 1,000 NUM (O) synthesized VERB (O) utterances VERB (O) per ADP (O) evaluation NOUN . (O) 
Each DET (O) sample NOUN (O) was AUX (O) rated VERB (O) by ADP (O) a NOUN (O) single ADJ (O) rater NOUN , (O) and CCONJ (O) each DET (O) evaluation NOUN (O) was AUX (O) conducted VERB (O) independently ADV (O) : the DET (O) outputs VERB (O) of ADP (O) different ADJ (O) models NOUN (O) were AUX (O) not PART (O) compared VERB (O) directly ADV . (O) 
Results NOUN (O) are AUX (O) shown VERB (O) in ADP (O) Table NOUN (O) 1 NUM , (O) comparing VERB (O) the DET (O) proposed VERB (O) model NOUN (O) to ADP (O) baseline NOUN (O) multispeaker NOUN (O) models NOUN (O) that SCONJ (O) utilize VERB (O) a NOUN (O) lookup NOUN (O) table NOUN (O) of ADP (O) [speaker NOUN (B) embeddings NOUN (I)] similar ADJ (O) to PART , (O) but CCONJ (O) otherwise ADV (O) have AUX (O) identical NOUN (O) architectures VERB (O) to ADP (O) the DET (O) proposed VERB (O) [synthesizer NOUN (B) network NOUN (I)] . 
The DET (O) proposed VERB (O) model NOUN (O) achieved VERB (O) about ADP (O) 4.0 NUM (O) [MOS PROPN (B)] in ADP (O) all DET (O) datasets VERB , (O) with ADP (O) the DET (O) VCTK PROPN (O) model NOUN (O) obtaining VERB (O) a NOUN (O) [MOS PROPN (B)] about ADP (O) 0.2 NUM (O) points VERB (O) higher ADJ (O) than SCONJ (O) the DET (O) [LibriSpeech PROPN (B) model NOUN (I)] when ADV (O) evaluated VERB (O) on ADP (O) seen VERB (O) speakers NOUN . (O) 
This DET (O) is AUX (O) the DET (O) consequence NOUN (O) of ADP (O) two NUM (O) drawbacks VERB (O) of ADP (O) the DET (O) [LibriSpeech PROPN (B) dataset NOUN (I)] : (i NOUN) (O) the DET (O) lack NOUN (O) of ADP (O) punctuation NOUN (O) in ADP (O) transcripts NOUN , (O) which DET (O) makes VERB (O) it PRON (O) difficult ADJ (O) for ADP (O) the DET (O) model NOUN (O) to ADP (O) learn VERB (O) to ADP (O) pause NOUN (O) naturally ADV , (O) and CCONJ (O) (ii PROPN) (O) the DET (O) higher ADJ (O) level NOUN (O) of ADP (O) background NOUN (O) noise NOUN (O) compared VERB (O) to ADP (O) VCTK NOUN , (O) some DET (O) of ADP (O) which DET (O) the DET (O) synthesizer NOUN (O) has AUX (O) learned VERB (O) to ADP (O) reproduce VERB , (O) despite SCONJ (O) denoising VERB (O) the DET (O) training NOUN (O) targets VERB (O) as SCONJ (O) described VERB (O) above ADV . (O) 
Most ADJ (O) importantly ADV , (O) the DET (O) [audio NOUN (B)] generated VERB (O) by ADP (O) our DET (O) model NOUN (O) for ADP (O) [unseen NOUN (B) speakers NOUN (I)] is AUX (O) deemed VERB (O) to ADP (O) be AUX (O) at ADP (O) least ADJ (O) as SCONJ (O) natural ADJ (O) as SCONJ (O) that SCONJ (O) generated VERB (O) for ADP (O) seen VERB (O) speakers NOUN . (O) 
Surprisingly ADV , (O) the DET (O) [MOS PROPN (B)] on ADP (O) [unseen NOUN (B) speakers NOUN (I)] is AUX (O) higher ADJ (O) than SCONJ (O) that SCONJ (O) of ADP (O) seen VERB (O) speakers NOUN , (O) by ADP (O) as SCONJ (O) much ADJ (O) as SCONJ (O) 0.2 NUM (O) points VERB (O) on ADP (O) [LibriSpeech PROPN (B)] . 
This DET (O) is AUX (O) a NOUN (O) consequence NOUN (O) of ADP (O) the DET (O) randomly ADV (O) selected VERB (O) reference NOUN (O) utterance NOUN (O) for ADP (O) each DET (O) speaker NOUN , (O) which DET (O) sometimes ADV (O) contains VERB (O) uneven ADJ (O) and CCONJ (O) non ADJ - neutral ADJ (O) [prosody NOUN (B)] . 
In ADP (O) informal ADJ (O) listening NOUN (O) tests VERB (O) we PRON (O) found VERB (O) that SCONJ (O) the DET (O) [prosody NOUN (B)] of ADP (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] sometimes ADV (O) mimics NOUN (O) that SCONJ (O) of ADP (O) the DET (O) reference NOUN , (O) similar ADJ (O) to PART . (O) 
This DET (O) effect NOUN (O) is AUX (O) larger ADJ (O) on ADP (O) [LibriSpeech PROPN (B)] , which DET (O) contains VERB (O) more ADJ (O) varied ADJ (O) [prosody NOUN (B)] . 
This DET (O) suggests VERB (O) that SCONJ (O) additional ADJ (O) care NOUN (O) must VERB (O) be AUX (O) taken VERB (O) to ADP (O) [disentangle NOUN (B) speaker NOUN (I)] identity NOUN (O) from ADP (O) [prosody NOUN (B)] within ADP (O) the DET (O) synthesis NOUN (O) network NOUN , (O) perhaps ADV (O) by ADP (O) integrating VERB (O) a NOUN (O) [prosody NOUN (B) encoder NOUN (I)] as SCONJ (O) in ADP , (O) or CCONJ (O) by ADP (O) training NOUN (O) on ADP (O) randomly ADV (O) paired VERB (O) reference NOUN (O) and CCONJ (O) target NOUN (O) utterances VERB (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] . 

 Table NOUN (O) : [Speaker PROPN (B) similarity NOUN (I) Mean VERB (I) Opinion NOUN (I) Score PROPN (I)] ([MOS PROPN (B)]) with ADP (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN . (O) 



 [Speaker PROPN (B) similarity NOUN (I)] 

 To ADP (O) evaluate VERB (O) how ADV (O) well INTJ (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] matches VERB (O) that SCONJ (O) from ADP (O) the DET (O) [target NOUN (B) speaker NOUN (I)] , we PRON (O) paired VERB (O) each DET (O) synthesized VERB (O) utterance NOUN (O) with ADP (O) a NOUN (O) randomly ADV (O) selected VERB (O) ground NOUN (O) truth NOUN (O) utterance NOUN (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] . 
Each DET (O) pair NOUN (O) is AUX (O) rated VERB (O) by ADP (O) one NUM (O) rater NOUN (O) with ADP (O) the DET (O) following VERB (O) instructions NOUN (O) : “ PUNCT (O) You PRON (O) should VERB (O) not PART (O) judge NOUN (O) the DET (O) content NOUN , (O) grammar NOUN , (O) or CCONJ (O) [audio NOUN (B) quality NOUN (I)] of ADP (O) the DET (O) sentences NOUN (O) ; instead ADV , (O) just ADV (O) focus NOUN (O) on ADP (O) the DET (O) similarity NOUN (O) of ADP (O) the DET (O) speakers NOUN (O) to ADP (O) one NUM (O) another DET . (O) ” PUNCT (O) 
Results NOUN (O) are AUX (O) shown VERB (O) in ADP (O) Table NOUN . (O) 
The DET (O) scores NOUN (O) for ADP (O) the DET (O) VCTK PROPN (O) model NOUN (O) tend NOUN (O) to ADP (O) be AUX (O) higher ADJ (O) than SCONJ (O) those DET (O) for ADP (O) [LibriSpeech PROPN (B)] , reflecting VERB (O) the DET (O) cleaner NOUN (O) nature NOUN (O) of ADP (O) the DET (O) dataset NOUN . (O) 
This DET (O) is AUX (O) also ADV (O) evident PROPN (O) in ADP (O) the DET (O) higher ADJ (O) ground NOUN (O) truth NOUN (O) baselines NOUN (O) on ADP (O) VCTK NOUN . (O) 
For ADP (O) [seen VERB (B) speakers NOUN (I)] on ADP (O) VCTK NOUN , (O) the DET (O) proposed VERB (O) model NOUN (O) performs VERB (O) about ADP (O) as SCONJ (O) well INTJ (O) as SCONJ (O) the DET (O) baseline NOUN (O) which DET (O) uses VERB (O) an DET (O) embedding NOUN (O) lookup NOUN (O) table NOUN (O) for ADP (O) [speaker NOUN (B) conditioning NOUN (I)] . 
However ADV , (O) on ADP (O) [LibriSpeech PROPN (B)] , the DET (O) proposed VERB (O) model NOUN (O) obtained VERB (O) a NOUN (O) lower ADJ (O) similarity NOUN (O) [MOS PROPN (B)] than SCONJ (O) the DET (O) baseline PROPN , (O) which DET (O) is AUX (O) likely ADV (O) due ADJ (O) to ADP (O) the DET (O) wider ADJ (O) degree NOUN (O) of ADP (O) within-[speaker PROPN (B) variation NOUN (I)] (Appendix PROPN (O) B) , (O) and CCONJ (O) background NOUN (O) noise NOUN (O) level NOUN (O) in ADP (O) the DET (O) dataset NOUN . (O) 
On ADP (O) [unseen NOUN (B) speakers NOUN (I)] , the DET (O) proposed VERB (O) model NOUN (O) obtains NOUN (O) lower ADJ (O) similarity NOUN (O) between ADP (O) ground NOUN (O) truth NOUN (O) and CCONJ (O) [synthesized VERB (B) speech NOUN (I)] . 
On ADP (O) VCTK NOUN , (O) the DET (O) similarity NOUN (O) score NOUN (O) of ADP (O) 3.28 NUM (O) is AUX (O) between ADP (O) “ PUNCT (O) moderately ADV (O) similar ADJ (O) ” PUNCT (O) and CCONJ (O) “ PUNCT (O) very ADV (O) similar ADJ (O) ” PUNCT (O) on ADP (O) the DET (O) evaluation NOUN (O) scale NOUN . (O) 
Informally ADV , (O) it PRON (O) is AUX (O) clear ADJ (O) that SCONJ (O) the DET (O) proposed VERB (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) transfer NOUN (O) the DET (O) broad ADJ (O) strokes VERB (O) of ADP (O) the DET (O) [speaker NOUN (B) characteristics NOUN (I)] for ADP (O) [unseen NOUN (B) speakers NOUN (I)] , clearly ADV (O) reflecting VERB (O) the DET (O) correct ADJ (O) gender NOUN , (O) [pitch NOUN (B)] , and CCONJ (O) formant NOUN (O) ranges VERB (O) (as SCONJ (O) also ADV (O) visualized VERB (O) in ADP (O) Figure NOUN (O) 2 NUM) . (O) 
But CCONJ (O) the DET (O) significantly ADV (O) reduced VERB (O) similarity NOUN (O) scores NOUN (O) on ADP (O) [unseen NOUN (B) speakers NOUN (I)] suggests VERB (O) that SCONJ (O) some DET (O) nuances NOUN , (O) e.g. ADV (O) related ADJ (O) to ADP (O) characteristic NOUN (O) [prosody NOUN (B)] , are AUX (O) lost VERB . (O) 
The DET (O) [speaker NOUN (B) encoder NOUN (I)] is AUX (O) trained VERB (O) only ADV (O) on ADP (O) North NOUN (O) American PROPN (O) [accented ADJ (B) speech NOUN (I)] . 
As SCONJ (O) a NOUN (O) result VERB , (O) accent NOUN (O) mismatch NOUN (O) constrains VERB (O) our DET (O) performance NOUN (O) on ADP (O) [speaker NOUN (B) similarity NOUN (I)] on ADP (O) VCTK PROPN (O) since SCONJ (O) the DET (O) rater NOUN (O) instructions NOUN (O) did AUX (O) not PART (O) specify VERB (O) how ADV (O) to ADP (O) judge NOUN (O) accents NOUN , (O) so CCONJ (O) raters NOUN (O) may VERB (O) consider VERB (O) a NOUN (O) pair NOUN (O) to ADP (O) be AUX (O) from ADP (O) [different ADJ (B) speakers NOUN (I)] if SCONJ (O) the DET (O) accents VERB (O) do AUX (O) not PART (O) match NOUN . (O) 
Indeed ADV , (O) examination NOUN (O) of ADP (O) rater NOUN (O) comments NOUN (O) shows VERB (O) that SCONJ (O) our DET (O) model NOUN (O) sometimes ADV (O) produced VERB (O) a NOUN (O) different ADJ (O) accent NOUN (O) than SCONJ (O) the DET (O) ground NOUN (O) truth NOUN , (O) which DET (O) led VERB (O) to ADP (O) lower ADJ (O) scores NOUN . (O) 
However ADV , (O) a NOUN (O) few ADJ (O) raters NOUN (O) commented VERB (O) that SCONJ (O) the DET (O) tone NOUN (O) and CCONJ (O) inflection NOUN (O) of ADP (O) the DET (O) voices NOUN (O) sounded VERB (O) very ADV (O) similar ADJ (O) despite SCONJ (O) differences NOUN (O) in ADP (O) accent NOUN . (O) 
As SCONJ (O) an DET (O) initial NOUN (O) evaluation NOUN (O) of ADP (O) the DET (O) ability NOUN (O) to ADP (O) generalize VERB (O) to ADP (O) out NOUN (O) of ADP (O) [domain NOUN (B) speakers NOUN (I)] , we PRON (O) used VERB (O) synthesizers NOUN (O) trained VERB (O) on ADP (O) VCTK PROPN (O) and CCONJ (O) [LibriSpeech PROPN (B)] to PART (O) synthesize VERB (O) speakers NOUN (O) from ADP (O) the DET (O) [other ADJ (B) dataset NOUN (I)] . 
We PRON (O) only ADV (O) varied ADJ (O) the DET (O) train NOUN (O) set NOUN (O) of ADP (O) the DET (O) synthesizer NOUN (O) and CCONJ (O) [vocoder NOUN (B) networks NOUN (I)] ; both DET (O) models NOUN (O) used VERB (O) an DET (O) [identical ADJ (B) speaker NOUN (I) encoder NOUN (I)] . 
As SCONJ (O) shown VERB (O) in ADP (O) Table NOUN (O) 3 NUM , (O) the DET (O) models NOUN (O) were AUX (O) able ADJ (O) to ADP (O) generate NOUN (O) [speech NOUN (B)] with ADP (O) the DET (O) same ADJ (O) degree NOUN (O) of ADP (O) naturalness NOUN (O) as SCONJ (O) on ADP (O) unseen ADJ , (O) but CCONJ (O) in ADP - domain NOUN , (O) speakers NOUN (O) shown VERB (O) in ADP (O) Table NOUN (O) 1 NUM . (O) 
However ADV , (O) the DET (O) [LibriSpeech PROPN (B) model NOUN (I)] synthesized VERB (O) [VCTK NOUN (B) speakers NOUN (I)] with ADP (O) significantly ADV (O) [higher ADJ (B) speaker NOUN (I)] similarity NOUN (O) than SCONJ (O) the DET (O) VCTK PROPN (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) synthesize VERB (O) [LibriSpeech PROPN (B) speakers NOUN (I)] . 
The DET (O) better ADJ (O) generalization NOUN (O) of ADP (O) the DET (O) [LibriSpeech PROPN (B) model NOUN (I)] suggests VERB (O) that SCONJ (O) training NOUN (O) the DET (O) synthesizer NOUN (O) on ADP (O) only ADV (O) 100 NUM (O) speakers NOUN (O) is AUX (O) insufficient NOUN (O) to ADP (O) enable NOUN (O) high ADJ (O) [quality NOUN (B) speaker NOUN (I)] transfer NOUN . (O) 

 Table NOUN (O) : Cross NOUN (O) [- (B) dataset NOUN (I)] evaluation NOUN (O) on ADP (O) naturalness NOUN (O) and CCONJ (O) [speaker NOUN (B) similarity NOUN (I)] for ADP (O) [unseen NOUN (B) speakers NOUN (I)] . 



 [Speaker PROPN (B) verification NOUN (I)] 

 As SCONJ (O) an DET (O) objective NOUN (O) metric ADJ (O) of ADP (O) the DET (O) degree NOUN (O) of ADP (O) [speaker NOUN (B) similarity NOUN (I)] between ADP (O) synthesized VERB (O) and CCONJ (O) ground NOUN (O) truth NOUN (O) [audio NOUN (B)] for ADP (O) [unseen NOUN (B) speakers NOUN (I)] , we PRON (O) evaluated VERB (O) the DET (O) ability NOUN (O) of ADP (O) a NOUN (O) [limited ADJ (B) speaker NOUN (I)] verification NOUN (O) system NOUN (O) to ADP (O) distinguish NOUN (O) synthetic NOUN (O) from ADP (O) real NOUN (O) [speech NOUN (B)] . 
We PRON (O) trained VERB (O) a NOUN (O) new ADJ (O) eval NOUN - only ADV (O) [speaker NOUN (B) encoder NOUN (I)] with ADP (O) the DET (O) same ADJ (O) network NOUN (O) topology NOUN (O) as SCONJ (O) Section NOUN , (O) but CCONJ (O) using VERB (O) a NOUN (O) different ADJ (O) training NOUN (O) set NOUN (O) of ADP (O) 28 NUM (O) M PROPN (O) utterances VERB (O) from ADP (O) 113000 NUM (O) speakers NOUN . (O) 
Using VERB (O) a NOUN (O) different ADJ (O) model NOUN (O) for ADP (O) evaluation NOUN (O) ensured VERB (O) that SCONJ (O) metrics NOUN (O) were AUX (O) not PART (O) only ADV (O) valid ADJ (O) on ADP (O) a NOUN (O) [specific ADJ (B) speaker NOUN (I)] embedding VERB (O) space NOUN . (O) 
We PRON (O) enroll VERB (O) the DET (O) voices NOUN (O) of ADP (O) 21 NUM (O) [real NOUN (B) speakers NOUN (I)] : 11 NUM (O) speakers NOUN (O) from ADP (O) VCTK NOUN , (O) and CCONJ (O) 10 NUM (O) from ADP (O) [LibriSpeech PROPN (B)] , and CCONJ (O) score NOUN (O) synthesized VERB (O) [waveforms NOUN (B)] against ADP (O) the DET (O) set NOUN (O) of ADP (O) enrolled VERB (O) speakers NOUN . (O) 
All DET (O) enrollment NOUN (O) and CCONJ (O) [verification NOUN (B) speakers NOUN (I)] are AUX (O) unseen ADJ (O) during ADP (O) synthesizer NOUN (O) training NOUN . (O) 
[Speaker PROPN (B) verification NOUN (I)] equal ADJ (O) error NOUN (O) rates NOUN (O) (SV PROPN - EERs PROPN) (O) are AUX (O) estimated VERB (O) by ADP (O) pairing VERB (O) each DET (O) test NOUN (O) utterance NOUN (O) with ADP (O) each DET (O) [enrollment NOUN (B) speaker NOUN (I)] . 
We PRON (O) synthesized VERB (O) 100 NUM (O) test NOUN (O) utterances VERB (O) for ADP (O) each DET (O) speaker NOUN , (O) so CCONJ (O) 21,000 NUM (O) or CCONJ (O) 23,100 NUM (O) trials NOUN (O) were AUX (O) performed VERB (O) for ADP (O) each DET (O) evaluation NOUN . (O) 
As SCONJ (O) shown VERB (O) in ADP (O) Table NOUN , (O) as SCONJ (O) long ADJ (O) as SCONJ (O) the DET (O) synthesizer NOUN (O) was AUX (O) trained VERB (O) on ADP (O) a NOUN (O) sufficiently ADV (O) large ADJ (O) set NOUN (O) of ADP (O) speakers NOUN , (O) i.e. X (O) on ADP (O) [LibriSpeech PROPN (B)] , the DET (O) [synthesized VERB (B) speech NOUN (I)] is AUX (O) typically ADV (O) most ADJ (O) similar ADJ (O) to ADP (O) the DET (O) ground NOUN (O) [truth NOUN (B) voices NOUN (I)] . 
The DET (O) [LibriSpeech PROPN (B) synthesizer NOUN (I)] obtains VERB (O) similar ADJ (O) EERs PROPN (O) of ADP (O) 5 NUM - 6 NUM (O) % using VERB (O) [reference NOUN (B) speakers NOUN (I)] from ADP (O) both DET (O) datasets VERB , (O) whereas SCONJ (O) the DET (O) one NUM (O) trained VERB (O) on ADP (O) VCTK PROPN (O) performs VERB (O) much ADJ (O) worse ADJ , (O) especially ADV (O) on ADP (O) out SCONJ - of ADP - domain NOUN (O) [LibriSpeech PROPN (B) speakers NOUN (I)] . 
These DET (O) results VERB (O) are AUX (O) consistent ADJ (O) with ADP (O) the DET (O) subjective ADJ (O) evaluation NOUN (O) in ADP (O) Table NOUN . (O) 
To NOUN (O) measure NOUN (O) the DET (O) difficulty NOUN (O) of ADP (O) discriminating VERB (O) between ADP (O) real NOUN (O) and CCONJ (O) [synthetic NOUN (B) speech NOUN (I)] for ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] , we PRON (O) performed VERB (O) an DET (O) additional ADJ (O) evaluation NOUN (O) with ADP (O) an DET (O) expanded VERB (O) set NOUN (O) of ADP (O) enrolled VERB (O) speakers NOUN (O) including VERB (O) 10 NUM (O) synthetic NOUN (O) versions NOUN (O) of ADP (O) the DET (O) 10 NUM (O) real NOUN (O) [LibriSpeech PROPN (B) speakers NOUN (I)] . 
On ADP (O) this DET (O) 20 NUM (O) [voice NOUN (B) discrimination NOUN (I)] task NOUN (O) we PRON (O) obtain VERB (O) an DET (O) EER NOUN (O) of ADP (O) 2.86 NUM (O) % , (O) demonstrating VERB (O) that SCONJ , (O) while SCONJ (O) the DET (O) [synthetic NOUN (B) speech NOUN (I)] tends VERB (O) to ADP (O) be AUX (O) close NOUN (O) to ADP (O) the DET (O) [target NOUN (B) speaker NOUN (I)] (cosine NOUN (O) similarity NOUN (O) > 0.6 NUM , (O) and CCONJ (O) as SCONJ (O) in ADP (O) Table NOUN (O) 4 NUM) , (O) it PRON (O) is AUX (O) nearly ADV (O) always ADV (O) even ADV (O) closer ADV (O) to ADP (O) other ADJ (O) synthetic NOUN (O) utterances VERB (O) for ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] (similarity NOUN (O) > 0.7 NUM) . (O) 
From ADP (O) this DET (O) we PRON (O) can VERB (O) conclude VERB (O) that DET (O) the DET (O) proposed VERB (O) model NOUN (O) can VERB (O) generate NOUN (O) [speech NOUN (B)] that DET (O) resembles VERB (O) the DET (O) [target NOUN (B) speaker NOUN (I)] , but CCONJ (O) not PART (O) well INTJ (O) enough ADJ (O) to ADP (O) be AUX (O) confusable ADJ (O) with ADP (O) a NOUN (O) [real NOUN (B) speaker NOUN (I)] . 

 Speaker NOUN (O) embedding NOUN (O) space NOUN (O) 

 Visualizing VERB (O) the DET (O) speaker NOUN (O) embedding NOUN (O) space NOUN (O) further NOUN (O) contextualizes VERB (O) the DET (O) quantitive NOUN (O) results NOUN (O) described VERB (O) in ADP (O) Section NOUN (O) and CCONJ . (O) 
As SCONJ (O) shown VERB (O) in ADP (O) Figure NOUN (O) 3 NUM , (O) [different ADJ (B) speakers NOUN (I)] are AUX (O) well INTJ (O) separated VERB (O) from ADP (O) each DET (O) other ADJ (O) in ADP (O) the DET (O) speaker NOUN (O) embedding NOUN (O) space NOUN . (O) 
The DET (O) PCA PROPN (O) visualization NOUN (O) (left ADV) (O) shows VERB (O) that SCONJ (O) synthesized VERB (O) utterances VERB (O) tend NOUN (O) to ADP (O) lie NOUN (O) very ADV (O) close NOUN (O) to ADP (O) real NOUN (O) [speech NOUN (B)] from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] in ADP (O) the DET (O) embedding NOUN (O) space NOUN . (O) 
However ADV , (O) synthetic NOUN (O) utterances VERB (O) are AUX (O) still ADV (O) easily ADV (O) distinguishable ADJ (O) from ADP (O) the DET (O) real NOUN (O) human NOUN (O) [speech NOUN (B)] as SCONJ (O) demonstrated VERB (O) by ADP (O) the DET (O) t NOUN - SNE PROPN (O) visualization NOUN (O) (right INTJ) (O) where ADV (O) utterances VERB (O) from ADP (O) each DET (O) [synthetic NOUN (B) speaker NOUN (I)] form NOUN (O) a NOUN (O) distinct ADJ (O) cluster NOUN (O) adjacent ADJ (O) to ADP (O) a NOUN (O) cluster NOUN (O) of ADP (O) real NOUN (O) utterances VERB (O) from ADP (O) the DET (O) corresponding VERB (O) speaker NOUN . (O) 
Speakers PROPN (O) appear VERB (O) to ADP (O) be AUX (O) well INTJ (O) separated VERB (O) by ADP (O) gender NOUN (O) in ADP (O) both DET (O) the DET (O) PCA PROPN (O) and CCONJ (O) t NOUN - SNE PROPN (O) visualizations NOUN , (O) with ADP (O) all DET (O) [female NOUN (B) speakers NOUN (I)] appearing VERB (O) on ADP (O) the DET (O) left VERB , (O) and CCONJ (O) all DET (O) [male NOUN (B) speakers NOUN (I)] appearing VERB (O) on ADP (O) the DET (O) right INTJ . (O) 
This DET (O) is AUX (O) an DET (O) indication NOUN (O) that SCONJ (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] has AUX (O) learned VERB (O) a NOUN (O) reasonable ADJ (O) representation NOUN (O) of ADP (O) [speaker NOUN (B) space NOUN (I)] . 

 Figure NOUN (O) : Visualization NOUN (O) of ADP (O) [speaker NOUN (B) embeddings NOUN (I)] extracted VERB (O) from ADP (O) [LibriSpeech PROPN (B)] utterances VERB . (O) 
Each DET (O) color NOUN (O) corresponds VERB (O) to ADP (O) a NOUN (O) [different ADJ (B) speaker NOUN (I)] . 
Real PROPN (O) and CCONJ (O) synthetic NOUN (O) utterances VERB (O) appear VERB (O) nearby ADV (O) when ADV (O) they PRON (O) are AUX (O) from ADP (O) the DET (O) [same ADJ (B) speaker NOUN (I)] , however ADV (O) real NOUN (O) and CCONJ (O) synthetic NOUN (O) utterances VERB (O) consistently ADV (O) form NOUN (O) distinct ADJ (O) clusters NOUN . (O) 

 Table NOUN (O) : Performance NOUN (O) using VERB (O) [speaker NOUN (B) encoders NOUN (I)] (SEs PROPN) (O) trained VERB (O) on ADP (O) [different ADJ (B) datasets VERB (I)] . 
Synthesizers PROPN (O) are AUX (O) all DET (O) trained VERB (O) on ADP (O) [LibriSpeech PROPN (B)] Clean ADJ (O) and CCONJ (O) evaluated VERB (O) on ADP (O) held VERB (O) out NOUN (O) speakers NOUN . (O) 

 Number NOUN (O) of ADP (O) [speaker NOUN (B) encoder NOUN (I) training NOUN (I) speakers NOUN (I)] 

 It PRON (O) is AUX (O) likely ADV (O) that DET (O) the DET (O) ability NOUN (O) of ADP (O) the DET (O) proposed VERB (O) model NOUN (O) to ADP (O) generalize VERB (O) well INTJ (O) across ADP (O) a NOUN (O) wide ADJ (O) variety NOUN (O) of ADP (O) speakers NOUN (O) is AUX (O) based VERB (O) on ADP (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) representation NOUN (O) learned VERB (O) by ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
We PRON (O) therefore ADV (O) explored VERB (O) the DET (O) effect NOUN (O) of ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I) training NOUN (I)] set VERB (O) on ADP (O) synthesis NOUN (O) quality NOUN . (O) 
We PRON (O) made VERB (O) use NOUN (O) of ADP (O) three NUM (O) additional ADJ (O) training NOUN (O) sets VERB (O) : [LibriSpeech PROPN (B)] Other ADJ , (O) which DET (O) contains VERB (O) 461 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B)] from ADP (O) a NOUN (O) set NOUN (O) of ADP (O) 1,166 NUM (O) [speakers NOUN (B) disjoint NOUN (I)] from ADP (O) those DET (O) in ADP (O) the DET (O) clean ADJ (O) subsets NOUN , (O) [VoxCeleb NOUN (B)] , and CCONJ (O) VoxCeleb2 PROPN (O) which DET (O) contain NOUN (O) 139000 NUM (O) utterances VERB (O) from ADP (O) 1,211 NUM (O) speakers NOUN , (O) and CCONJ (O) 1.09 NUM (O) M PROPN (O) utterances VERB (O) from ADP (O) 5,994 NUM (O) speakers NOUN , (O) respectively ADV . (O) 
Table NOUN (O)     compares VERB (O) the DET (O) performance NOUN (O) of ADP (O) the DET (O) proposed VERB (O) model NOUN (O) as SCONJ (O) a NOUN (O) function NOUN (O) of ADP (O) the DET (O) number NOUN (O) of ADP (O) speakers NOUN (O) used VERB (O) to ADP (O) train NOUN (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
This DET (O) measures NOUN (O) the DET (O) importance NOUN (O) of ADP (O) [speaker NOUN (B) diversity NOUN (I)] when ADV (O) training NOUN (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
To PART (O) avoid NOUN (O) overfitting NOUN , (O) the DET (O) [speaker NOUN (B) encoders NOUN (I)] trained VERB (O) on ADP (O) [small ADJ (B) datasets VERB (I)] (top NOUN (O) two NUM (O) rows NOUN) (O) use NOUN (O) a NOUN (O) smaller ADJ (O) [network NOUN (B) architecture NOUN (I)] (256-dim NUM (O) [LSTM PROPN (B) cells NOUN (I)] with ADP (O) 64-dim NUM (O) projections NOUN) (O) and CCONJ (O) output NOUN (O) 64 NUM (O) [dimensional ADJ (B) speaker NOUN (I) embeddings NOUN (I)] . 
We PRON (O) first ADJ (O) evaluate VERB (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] trained VERB (O) on ADP (O) [LibriSpeech PROPN (B)] Clean ADJ (O) and CCONJ (O) Other ADJ (O) sets NOUN , (O) each DET (O) of ADP (O) which DET (O) contain NOUN (O) a NOUN (O) similar ADJ (O) number NOUN (O) of ADP (O) speakers NOUN . (O) 
In ADP (O) Clean ADJ , (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] and CCONJ (O) synthesizer NOUN (O) are AUX (O) trained VERB (O) on ADP (O) the DET (O) [same ADJ (B) data NOUN (I)] , a DET (O) baseline NOUN (O) similar ADJ (O) to ADP (O) the DET (O) non ADJ - fine ADJ (O) tuned VERB (O) [speaker NOUN (B) encoder NOUN (I)] from ADP , (O) except SCONJ (O) that SCONJ (O) it PRON (O) is AUX (O) trained VERB (O) discriminatively ADV (O) as SCONJ (O) in ADP . (O) 
This DET (O) matched VERB (O) condition NOUN (O) gives VERB (O) a NOUN (O) slightly ADV (O) better ADJ (O) naturalness NOUN (O) and CCONJ (O) a NOUN (O) similar ADJ (O) similarity NOUN (O) score NOUN . (O) 
As SCONJ (O) the DET (O) number NOUN (O) of ADP (O) [training NOUN (B) speakers NOUN (I)] increases VERB , (O) both DET (O) naturalness NOUN (O) and CCONJ (O) similarity NOUN (O) improve VERB (O) significantly ADV . (O) 
The DET (O) objective NOUN (O) EER PROPN (O) results VERB (O) also ADV (O) improve VERB (O) alongside ADP (O) the DET (O) subjective ADJ (O) evaluations NOUN . (O) 
These DET (O) results VERB (O) have AUX (O) an DET (O) important ADJ (O) implication NOUN (O) for ADP (O) [multispeaker NOUN (B) TTS PROPN (I) training NOUN (I)] . 
The DET (O) [data NOUN (B) requirement NOUN (I)] for ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] is AUX (O) much ADJ (O) cheaper ADJ (O) than SCONJ (O) full ADJ (O) [TTS PROPN (B) training NOUN (I)] since SCONJ (O) no DET (O) transcripts NOUN (O) are AUX (O) necessary ADJ , (O) and CCONJ (O) the DET (O) [audio NOUN (B) quality NOUN (I)] can VERB (O) be AUX (O) lower ADJ (O) than SCONJ (O) for ADP (O) [TTS PROPN (B) training NOUN (I)] . 
We PRON (O) have AUX (O) shown VERB (O) that SCONJ (O) it PRON (O) is AUX (O) possible ADJ (O) to ADP (O) synthesize VERB (O) very ADV (O) natural ADJ (O) [TTS PROPN (B)] by ADP (O) combining VERB (O) a NOUN (O) [speaker NOUN (B) encoder NOUN (I) network NOUN (I)] trained VERB (O) on ADP (O) large ADJ (O) amounts VERB (O) of ADP (O) [untranscribed ADJ (B) data NOUN (I)] with ADP (O) a NOUN (O) [TTS PROPN (B) network NOUN (I)] trained VERB (O) on ADP (O) a NOUN (O) smaller ADJ (O) set NOUN (O) of ADP (O) high ADJ (O) [quality NOUN (B) data NOUN (I)] . 

 Table NOUN (O) : [Speech NOUN (B)] from ADP (O) [fictitious PROPN (B) speakers NOUN (I)] compared VERB (O) to ADP (O) their DET (O) nearest NOUN (O) neighbors NOUN (O) in ADP (O) the DET (O) train NOUN (O) sets NOUN . (O) 

 [Fictitious PROPN (B) speakers NOUN (I)] 

 Bypassing VERB (O) the DET (O) [speaker NOUN (B) encoder NOUN (I) network NOUN (I)] and CCONJ (O) conditioning NOUN (O) the DET (O) synthesizer NOUN (O) on ADP (O) random ADJ (O) points VERB (O) in ADP (O) the DET (O) speaker NOUN (O) embedding NOUN (O) space NOUN (O) results VERB (O) in ADP (O) [speech NOUN (B)] from ADP (O) [fictitious PROPN (B) speakers NOUN (I)] which DET (O) are AUX (O) not PART (O) present NOUN (O) in ADP (O) the DET (O) train NOUN (O) or CCONJ (O) test NOUN (O) sets VERB (O) of ADP (O) either CCONJ (O) the DET (O) synthesizer NOUN (O) or CCONJ (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] . 
This DET (O) is AUX (O) demonstrated VERB (O) in ADP (O) Table NOUN , (O) which DET (O) compares VERB (O) 10 NUM (O) [such ADJ (B) speakers NOUN (I)] , generated VERB (O) from ADP (O) uniformly ADV (O) sampled VERB (O) points VERB (O) on ADP (O) the DET (O) surface NOUN (O) of ADP (O) the DET (O) unit NOUN (O) hypersphere NOUN , (O) to ADP (O) their DET (O) nearest NOUN (O) neighbors NOUN (O) in ADP (O) the DET (O) training NOUN (O) sets VERB (O) of ADP (O) the DET (O) component NOUN (O) networks NOUN . (O) 
SV PROPN - EERs PROPN (O) are AUX (O) computed VERB (O) using VERB (O) the DET (O) same ADJ (O) setup NOUN (O) as SCONJ (O) Section NOUN (O) after ADP (O) enrolling NOUN (O) voices NOUN (O) of ADP (O) the DET (O) 10 NUM (O) nearest NOUN (O) neighbors NOUN . (O) 
Even ADV (O) though SCONJ (O) these DET (O) speakers NOUN (O) are AUX (O) totally ADV (O) fictitious ADJ , (O) the DET (O) synthesizer NOUN (O) and CCONJ (O) the DET (O) [vocoder NOUN (B)] are AUX (O) able ADJ (O) to ADP (O) generate NOUN (O) [audio NOUN (B)] as SCONJ (O) natural ADJ (O) as SCONJ (O) for ADP (O) seen VERB (O) or CCONJ (O) unseen ADJ (O) [real NOUN (B) speakers NOUN (I)] . 
The DET (O) low NOUN (O) cosine NOUN (O) similarity NOUN (O) to ADP (O) the DET (O) nearest NOUN (O) neighbor NOUN (O) training NOUN (O) utterances VERB (O) and CCONJ (O) very ADV (O) high ADJ (O) EER PROPN (O) indicate VERB (O) that SCONJ (O) they PRON (O) are AUX (O) indeed ADV (O) distinct ADJ (O) from ADP (O) the DET (O) [training NOUN (B) speakers NOUN (I)] . 

 Conclusion NOUN (O) 

 We PRON (O) present NOUN (O) a NOUN (O) [neural NOUN (B) network NOUN - based VERB (I) system NOUN (I)] for ADP (O) [multispeaker NOUN (B) TTS PROPN (I) synthesis NOUN (I)] . 
The DET (O) system NOUN (O) combines VERB (O) an DET (O) independently ADV (O) trained VERB (O) [speaker NOUN (B) encoder NOUN (I) network NOUN (I)] with ADP (O) a NOUN (O) [sequence NOUN - to ADP - sequence NOUN (B) TTS PROPN (I) synthesis NOUN (I)] network NOUN (O) and CCONJ (O) [neural NOUN (B) vocoder NOUN (I)] based VERB (O) on ADP (O) [Tacotron PROPN (B) 2 NUM (I)] . 
By ADP (O) leveraging NOUN (O) the DET (O) knowledge NOUN (O) learned VERB (O) by ADP (O) the DET (O) [discriminative NOUN (B) speaker NOUN (I) encoder NOUN (I)] , the DET (O) synthesizer NOUN (O) is AUX (O) able ADJ (O) to ADP (O) generate NOUN (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] not PART (O) only ADV (O) for ADP (O) speakers NOUN (O) seen VERB (O) during ADP (O) training NOUN , (O) but CCONJ (O) also ADV (O) for ADP (O) speakers NOUN (O) never ADV (O) seen VERB (O) before ADV . (O) 
Through ADP (O) evaluations NOUN (O) based VERB (O) on ADP (O) a NOUN (O) [speaker NOUN (B) verification NOUN (I)] system NOUN (O) as SCONJ (O) well INTJ (O) as SCONJ (O) subjective ADJ (O) listening VERB (O) tests NOUN , (O) we PRON (O) demonstrated VERB (O) that SCONJ (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] is AUX (O) reasonably ADV (O) similar ADJ (O) to ADP (O) real NOUN (O) [speech NOUN (B)] from ADP (O) the DET (O) [target NOUN (B) speakers NOUN (I)] , even ADV (O) on ADP (O) such ADJ (O) [unseen NOUN (B) speakers NOUN (I)] . 
We PRON (O) ran VERB (O) experiments VERB (O) to ADP (O) analyze VERB (O) the DET (O) impact NOUN (O) of ADP (O) the DET (O) amount NOUN (O) of ADP (O) data NOUN (O) used VERB (O) to ADP (O) train NOUN (O) the DET (O) different ADJ (O) components NOUN , (O) and CCONJ (O) found VERB (O) that SCONJ , (O) given VERB (O) [sufficient ADJ (B) speaker NOUN (I)] diversity NOUN (O) in ADP (O) the DET (O) synthesizer NOUN (O) training NOUN (O) set VERB , (O) [speaker NOUN (B) transfer NOUN (I)] quality NOUN (O) could VERB (O) be AUX (O) significantly ADV (O) improved VERB (O) by ADP (O) increasing VERB (O) the DET (O) amount NOUN (O) of ADP (O) [speaker NOUN (B) encoder NOUN (I) training NOUN (I) data NOUN (I)] . 
Transfer NOUN (O) learning NOUN (O) is AUX (O) critical ADJ (O) to ADP (O) achieving VERB (O) these DET (O) results VERB . (O) 
By ADP (O) separating NOUN (O) the DET (O) training NOUN (O) of ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I)] and CCONJ (O) the DET (O) synthesizer PROPN , (O) the DET (O) system NOUN (O) significantly ADV (O) lowers VERB (O) the DET (O) requirements NOUN (O) for ADP (O) [multispeaker NOUN (B) TTS PROPN (I) training NOUN (I) data NOUN (I)] . 
It PRON (O) requires VERB (O) neither CCONJ (O) [speaker NOUN (B) identity NOUN (I)] labels NOUN (O) for ADP (O) the DET (O) synthesizer NOUN (O) [training NOUN (B) data NOUN (I)] , nor CCONJ (O) high ADJ (O) quality NOUN (O) clean ADJ (O) [speech NOUN (B)] or CCONJ (O) transcripts NOUN (O) for ADP (O) the DET (O) [speaker NOUN (B) encoder NOUN (I) training NOUN (I) data NOUN (I)] . 
In ADP (O) addition NOUN , (O) training NOUN (O) the DET (O) components NOUN (O) independently ADV (O) significantly ADV (O) simplifies NOUN (O) the DET (O) training NOUN (O) configuration NOUN (O) of ADP (O) the DET (O) [synthesizer NOUN (B) network NOUN (I)] compared VERB (O) to ADP (O) since SCONJ (O) it PRON (O) does AUX (O) not PART (O) require VERB (O) additional ADJ (O) triplet NOUN (O) or CCONJ (O) contrastive ADJ (O) losses NOUN . (O) 
However ADV , (O) modeling NOUN (O) [speaker NOUN (B) variation NOUN (I)] using VERB (O) a NOUN (O) low ADJ (O) dimensional ADJ (O) [vector NOUN (B)] limits NOUN (O) the DET (O) ability NOUN (O) to ADP (O) leverage NOUN (O) large ADJ (O) amounts VERB (O) of ADP (O) reference NOUN (O) [speech NOUN (B)] . 
Improving VERB (O) [speaker NOUN (B) similarity NOUN (I)] given VERB (O) more ADJ (O) than SCONJ (O) a NOUN (O) few ADJ (O) seconds NOUN (O) of ADP (O) reference NOUN (O) [speech NOUN (B)] requires VERB (O) a NOUN (O) model NOUN (O) adaptation NOUN (O) approach NOUN (O) as SCONJ (O) in ADP , (O) and CCONJ (O) more ADJ (O) recently ADV (O) in ADP . (O) 
Finally ADV , (O) we PRON (O) demonstrate NOUN (O) that SCONJ (O) the DET (O) model NOUN (O) is AUX (O) able ADJ (O) to ADP (O) generate NOUN (O) realistic ADJ (O) [speech NOUN (B)] from ADP (O) [fictitious PROPN (B) speakers NOUN (I)] that DET (O) are AUX (O) dissimilar NOUN (O) from ADP (O) the DET (O) training NOUN (O) set VERB , (O) implying VERB (O) that SCONJ (O) the DET (O) model NOUN (O) has AUX (O) learned VERB (O) to ADP (O) utilize VERB (O) a NOUN (O) realistic ADJ (O) representation NOUN (O) of ADP (O) the DET (O) space NOUN (O) of ADP (O) [speaker NOUN (B) variation NOUN (I)] . 
The DET (O) proposed VERB (O) model NOUN (O) does AUX (O) not PART (O) attain NOUN (O) [human ADJ - level NOUN (B) naturalness NOUN (I)] , despite SCONJ (O) the DET (O) use NOUN (O) of ADP (O) a NOUN (O) [WaveNet PROPN (B) vocoder NOUN (I)] (along ADP (O) with ADP (O) its DET (O) very ADV (O) high ADJ (O) inference NOUN (O) cost NOUN) , (O) in ADP (O) contrast NOUN (O) to ADP (O) the DET (O) [single ADJ (B) speaker NOUN (I)] results VERB (O) from ADP . (O) 
This DET (O) is AUX (O) a NOUN (O) consequence NOUN (O) of ADP (O) the DET (O) additional ADJ (O) difficulty NOUN (O) of ADP (O) generating NOUN (O) [speech NOUN (B)] for ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) speakers NOUN (O) given VERB (O) significantly ADV (O) [less ADJ (B) data NOUN (I)] per ADP (O) speaker NOUN , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) the DET (O) use NOUN (O) of ADP (O) datasets VERB (O) with ADP (O) [lower ADJ (B) data NOUN (I)] quality NOUN . (O) 
An PROPN (O) additional ADJ (O) limitation NOUN (O) lies VERB (O) in ADP (O) the DET (O) model NOUN ’s PUNCT (O) inability NOUN (O) to ADP (O) transfer NOUN (O) accents NOUN . (O) 
Given VERB (O) sufficient ADJ (O) [training NOUN (B) data NOUN (I)] , this DET (O) could VERB (O) be AUX (O) addressed VERB (O) by ADP (O) conditioning NOUN (O) the DET (O) synthesizer NOUN (O) on ADP (O) [independent ADJ (B) speaker NOUN (I)] and CCONJ (O) accent NOUN (O) embeddings NOUN . (O) 
Finally ADV , (O) we PRON (O) note NOUN (O) that SCONJ (O) the DET (O) model NOUN (O) is AUX (O) also ADV (O) not PART (O) able ADJ (O) to ADP (O) completely ADV (O) isolate VERB (O) the DET (O) [speaker NOUN (B) voice NOUN (I)] from ADP (O) the DET (O) [prosody NOUN (B)] of ADP (O) the DET (O) reference NOUN (O) [audio NOUN (B)] , a DET (O) similar ADJ (O) trend NOUN (O) to ADP (O) that SCONJ (O) observed VERB (O) in ADP . (O) 
