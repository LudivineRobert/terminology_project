[Deep ADJ (B) Voice PROPN (I)] : Real ADJ - time NOUN (O) [Neural PROPN (B) Text NOUN - to ADP - Speech NOUN (I)] 

 Abstract PROPN (O) 

 We PRON (O) present NOUN (O) [Deep ADJ (B) Voice PROPN (I)] , a DET (O) production NOUN - quality NOUN (O) [text NOUN - to ADP - speech NOUN (B) system NOUN (I)] constructed VERB (O) entirely ADV (O) from ADP (O) [deep ADJ (B) neural NOUN (I) networks NOUN (I)] . 
[Deep ADJ (B) Voice PROPN (I)] lays VERB (O) the DET (O) groundwork NOUN (O) for ADP (O) truly ADV (O) [end NOUN - to ADP - end NOUN (B) neural NOUN (I) speech NOUN (I) synthesis NOUN (I)] . 
The DET (O) system NOUN (O) comprises VERB (O) five NUM (O) major NOUN (O) building NOUN (O) blocks PROPN (O) : a DET (O) [segmentation NOUN (B) model NOUN (I)] for ADP (O) locating NOUN (O) [phoneme NOUN (B) boundaries NOUN (I)] , a DET (O) [grapheme NOUN - to ADP - phoneme NOUN (B) conversion NOUN (I) model NOUN (I)] , a DET (O) [phoneme NOUN (B) duration NOUN (I) prediction NOUN (I) model NOUN (I)] , a DET (O) [fundamental ADJ (B) frequency NOUN (I) prediction NOUN (I) model NOUN (I)] , and CCONJ (O) an DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] . 
For ADP (O) the DET (O) [segmentation NOUN (B) model NOUN (I)] , we PRON (O) propose NOUN (O) a NOUN (O) novel NOUN (O) way NOUN (O) of ADP (O) performing VERB (O) [phoneme NOUN (B) boundary ADJ (I)] detection NOUN (O) with ADP (O) [deep ADJ (B) neural NOUN (I) networks NOUN (I)] using VERB (O) [connectionist NOUN (B) temporal NOUN (I) classification NOUN (I)] (CTC PROPN) (O) loss NOUN . (O) 
For ADP (O) the DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] , we PRON (O) implement VERB (O) a NOUN (O) variant NOUN (O) of ADP (O) [WaveNet PROPN (B)] that DET (O) requires VERB (O) fewer ADJ (O) parameters NOUN (O) and CCONJ (O) trains NOUN (O) faster ADV (O) than SCONJ (O) the DET (O) original ADJ . (O) 
By ADP (O) using VERB (O) a NOUN (O) [neural NOUN (B) network NOUN (I)] for ADP (O) each DET (O) component NOUN , (O) our DET (O) system NOUN (O) is AUX (O) simpler ADJ (O) and CCONJ (O) more ADJ (O) flexible ADJ (O) than SCONJ (O) traditional ADJ (O) [text NOUN - to ADP - speech NOUN (B) systems NOUN (I)] , where ADV (O) each DET (O) component NOUN (O) requires VERB (O) [laborious ADJ (B) feature NOUN (I) engineering NOUN (I)] and CCONJ (O) extensive ADJ (O) domain NOUN (O) expertise NOUN . (O) 
Finally ADV , (O) we PRON (O) show NOUN (O) that SCONJ (O) inference NOUN (O) with ADP (O) our DET (O) system NOUN (O) can VERB (O) be AUX (O) performed VERB (O) faster ADV (O) than SCONJ (O) real NOUN (O) time NOUN (O) and CCONJ (O) describe VERB (O) optimized VERB (O) [WaveNet PROPN (B) inference NOUN (I)] kernels NOUN (O) on ADP (O) both DET (O) [CPU NOUN (B)] and CCONJ (O) [GPU PROPN (B)] that DET (O) achieve VERB (O) up NOUN (O) to ADP (O) 400x NUM (O) speedups NOUN (O) over ADP (O) existing VERB (O) implementations NOUN . (O) 


 Introduction NOUN (O) 

 Synthesizing NOUN (O) [artificial NOUN (B) human NOUN (I) speech NOUN (I)] from ADP (O) text NOUN , (O) commonly ADV (O) known VERB (O) as SCONJ (O) [text NOUN - to ADP - speech NOUN (B)] ([TTS PROPN (B)]) , is AUX (O) an DET (O) essential ADJ (O) component NOUN (O) in ADP (O) many ADJ (O) applications NOUN (O) such ADJ (O) as SCONJ (O) [speech NOUN - enabled VERB (B) devices NOUN (I)] , navigation NOUN (O) systems NOUN , (O) and CCONJ (O) accessibility NOUN (O) for ADP (O) the DET (O) visually ADV - impaired VERB . (O) 
Fundamentally ADV , (O) it PRON (O) allows VERB (O) human NOUN - technology NOUN (O) interaction NOUN (O) without ADP (O) requiring VERB (O) visual NOUN (O) interfaces NOUN . (O) 
[Modern ADJ (B) TTS PROPN (I) systems NOUN (I)] are AUX (O) based VERB (O) on ADP (O) complex NOUN , (O) multi ADJ - stage NOUN (O) processing NOUN (O) pipelines NOUN , (O) each DET (O) of ADP (O) which DET (O) may VERB (O) rely VERB (O) on ADP (O) hand NOUN - engineered VERB (O) features VERB (O) and CCONJ (O) heuristics NOUN . (O) 
Due PROPN (O) to ADP (O) this DET (O) complexity NOUN , (O) developing VERB (O) new ADJ (O) [TTS PROPN (B) systems NOUN (I)] can VERB (O) be AUX (O) very ADV (O) labor NOUN (O) intensive ADJ (O) and CCONJ (O) difficult ADJ . (O) 
[Deep ADJ (B) Voice PROPN (I)] is AUX (O) inspired VERB (O) by ADP (O) traditional ADJ (O) [text NOUN - to ADP - speech NOUN (B) pipelines NOUN (I)] and CCONJ (O) adopts VERB (O) the DET (O) same ADJ (O) structure NOUN , (O) while SCONJ (O) replacing VERB (O) all DET (O) components NOUN (O) with ADP (O) [neural NOUN (B) networks NOUN (I)] and CCONJ (O) using VERB (O) [simpler ADJ (B) features VERB (I)] : first ADJ (O) we PRON (O) convert NOUN (O) text NOUN (O) to ADP (O) [phoneme NOUN (B)] and CCONJ (O) then ADV (O) use NOUN (O) an DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] to PART (O) convert NOUN (O) [linguistic NOUN (B) features VERB (I)] into ADP (O) [speech NOUN (B)] (Taylor PROPN , (O) 2009 NUM) . (O) 
Unlike PROPN (O) prior ADJ (O) work NOUN (O) (which DET (O) uses VERB (O) hand NOUN - engineered VERB (O) features VERB (O) such ADJ (O) as SCONJ (O) [spectral NOUN (B) envelope NOUN (I)] , [spectral NOUN (B) parameters NOUN (I)] , aperiodic PROPN (O) parameters NOUN , (O) etc X .) , (O) our DET (O) [only ADV (B) features VERB (I)] are AUX (O) [phonemes NOUN (B)] with ADP (O) stress NOUN (O) annotations NOUN , (O) [phoneme NOUN (B) durations NOUN (I)] , and CCONJ (O) [fundamental ADJ (B) frequency NOUN (I)] (F0 PROPN) . (O) 
This DET (O) choice NOUN (O) of ADP (O) features VERB (O) makes VERB (O) our DET (O) system NOUN (O) more ADJ (O) readily ADV (O) applicable ADJ (O) to ADP (O) [new PROPN (B) datasets VERB (I)] , voices NOUN , (O) and CCONJ (O) domains NOUN (O) without ADP (O) any DET (O) [manual NOUN (B) data NOUN (I)] annotation NOUN (O) or CCONJ (O) [additional ADJ (B) feature NOUN (I) engineering NOUN (I)] . 
We PRON (O) demonstrate NOUN (O) this DET (O) claim NOUN (O) by ADP (O) retraining VERB (O) our DET (O) entire ADJ (O) pipeline NOUN (O) without ADP (O) any DET (O) [hyperparameter NOUN (B)] changes VERB (O) on ADP (O) an DET (O) entirely ADV (O) [new PROPN (B) dataset NOUN (I)] that DET (O) contains VERB (O) solely ADV (O) [audio NOUN (B)] and CCONJ (O) unaligned ADJ (O) textual NOUN (O) transcriptions NOUN (O) andgenerating VERB (O) relatively ADV (O) [high ADJ (B) quality NOUN (I) speech NOUN (I)] . 
In ADP (O) a NOUN (O) conventional ADJ (O) [TTS PROPN (B) system NOUN (I)] this DET (O) adaptation NOUN (O) requires VERB (O) days NOUN (O) to ADP (O) weeks NOUN (O) of ADP (O) tuning NOUN , (O) whereas SCONJ (O) [Deep ADJ (B) Voice PROPN (I)] allows VERB (O) you PRON (O) to ADP (O) do AUX (O) it PRON (O) in ADP (O) only ADV (O) a NOUN (O) fewhours VERB (O) of ADP (O) manual NOUN (O) effort NOUN (O) and CCONJ (O) the DET (O) time NOUN (O) it PRON (O) takes VERB (O) models NOUN (O) to ADP (O) train NOUN . (O) 
Realtime NOUN (O) inference NOUN (O) is AUX (O) a NOUN (O) requirement NOUN (O) for ADP (O) a NOUN (O) production NOUN - quality NOUN (O) [TTS PROPN (B) system NOUN (I)] ; without ADP (O) it PRON , (O) the DET (O) system NOUN (O) is AUX (O) unusable ADJ (O) for ADP (O) most ADJ (O) applications NOUN (O) of ADP (O) [TTS PROPN (B)] . 
Prior ADV (O) work NOUN (O) has AUX (O) demonstrated VERB (O) that SCONJ (O) a NOUN (O) [WaveNet PROPN (B)] (van PROPN (O) den NOUN (O) Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) can VERB (O) generate NOUN (O) close NOUN (O) to ADP (O) [human ADJ - level NOUN (B) speech NOUN (I)] . 
However ADV , (O) [WaveNet PROPN (B) inference NOUN (I)] poses VERB (O) adaunting NOUN (O) computational ADJ (O) problem NOUN (O) due ADJ (O) to ADP (O) the DET (O) high ADJ - frequency NOUN , (O) autoregressive ADJ (O) nature NOUN (O) of ADP (O) the DET (O) model NOUN , (O) and CCONJ (O) it PRON (O) has AUX (O) been AUX (O) hit VERB (O) her PRON (O) to ADP (O) unknown ADJ (O) whether SCONJ (O) such ADJ (O) models NOUN (O) can VERB (O) be AUX (O) used VERB (O) in ADP (O) a NOUN (O) production NOUN (O) system NOUN . (O) 
We PRON (O) answer NOUN (O) this DET (O) question NOUN (O) in ADP (O) the DET (O) affirmative ADJ (O) anddemonstrate VERB (O) efficient ADJ , (O) faster ADJ - than SCONJ - realtime NOUN (O) [WaveNet PROPN (B) inference NOUN (I)] kernels NOUN (O) that SCONJ (O) produce NOUN (O) [high ADJ - quality NOUN (B)] 16 NUM (O) kHz PROPN (O) [audio NOUN (B)] andrealize VERB (O) a NOUN (O) 400X NUM (O) speedup NOUN (O) over ADP (O) previous ADJ (O) [WaveNet PROPN (B) inference NOUN (I)] implementations VERB (O) (Paine PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) . (O) 

 Related VERB (O) Work NOUN (O) 

 Previous ADJ (O) work NOUN (O) uses VERB (O) [neural NOUN (B) networks NOUN (I)] as SCONJ (O) substitutes VERB (O) for ADP (O) several ADJ (O) [TTS PROPN (B) system NOUN (I)] components NOUN , (O) including VERB (O) [grapheme NOUN - to ADP - phoneme NOUN (B) conversion NOUN (I) models NOUN (I)] (Rao PROPN (O) et NOUN (O) al PROPN . , (O) 2015 NUM (O) ; Yao PROPN (O) & Zweig PROPN , (O) 2015 NUM) , (O) [phoneme NOUN (B) duration NOUN (I) prediction NOUN (I) models NOUN (I)] (Zen PROPN (O) & Sak PROPN , (O) 2015 NUM) , (O) [fundamental ADJ (B) frequency NOUN (I) prediction NOUN (I) models NOUN (I)] (Pascual PROPN (O) & Bonafonte PROPN , (O) 2016 NUM (O) ; Ronanki PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) , (O) and CCONJ (O) [audio NOUN (B) synthesis NOUN (I) models NOUN (I)] (van PROPN (O) den NOUN (O) Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM (O) ; Mehri PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) . (O) 
Unlike PROPN (O) [Deep ADJ (B) Voice PROPN (I)] , however ADV , (O) none NOUN (O) of ADP (O) these DET (O) systems NOUN (O) solve VERB (O) the DET (O) entire ADJ (O) problem NOUN (O) of ADP (O) [TTS PROPN (B)] and CCONJ (O) many ADJ (O) of ADP (O) them PRON (O) use NOUN (O) specialized PROPN (O) hand NOUN - engineered VERB (O) features VERB (O) developed VERB (O) specifically ADV (O) for ADP (O) their DET (O) domain NOUN . (O) 
Most ADJ (O) recently ADV , (O) there PRON (O) has AUX (O) been AUX (O) a NOUN (O) lot NOUN (O) of ADP (O) work NOUN (O) in ADP (O) parametric NOUN (O) [audio NOUN (B) synthesis NOUN (I)] , notably ADV (O) [WaveNet PROPN (B)] , [SampleRNN PROPN (B)] , and CCONJ (O) Char2Wav PROPN (O) (van PROPN (O) den NOUN (O) Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM (O) ; Mehri PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM (O) ; Sotelo PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) . (O) 
While SCONJ (O) [WaveNet PROPN (B)] can VERB (O) be AUX (O) used VERB (O) for ADP (O) both DET (O) conditional ADJ (O) and CCONJ (O) unconditional ADJ (O) [audio NOUN (B) generation NOUN (I)] , [SampleRNN PROPN (B)] is AUX (O) only ADV (O) used VERB (O) for ADP (O) unconditional ADJ (O) [audio NOUN (B) generation NOUN (I)] . 
Char2Wav PROPN (O) extends VERB (O) [SampleRNN NOUN (B)] with ADP (O) an DET (O) [attention NOUN - based VERB (B) phoneme NOUN (I) duration NOUN (I) model NOUN (I)] and CCONJ (O) the DET (O) equivalent NOUN (O) of ADP (O) an DET (O) F0 NOUN (O) [prediction NOUN (B) model NOUN (I)] , effectively ADV (O) providing VERB (O) local ADJ (O) conditioning NOUN (O) information NOUN (O) to ADP (O) a NOUN (O) [SampleRNN PROPN (B)]-based VERB [vocoder NOUN (B)] . 
[Deep ADJ (B) Voice PROPN (I)] differs VERB (O) from ADP (O) these DET (O) systems NOUN (O) in ADP (O) several ADJ (O) key NOUN (O) aspects NOUN (O) that SCONJ (O) notably ADV (O) increase NOUN (O) the DET (O) scope NOUN (O) of ADP (O) the DET (O) problem NOUN . (O) 
First ADV , (O) [Deep ADJ (B) Voice PROPN (I)] is AUX (O) completely ADV (O) standalone NOUN (O) ; training NOUN (O) a NOUN (O) new ADJ (O) [Deep ADJ (B) Voice PROPN (I) system NOUN (I)] does AUX (O) not PART (O) require VERB (O) a NOUN (O) pre VERB - existing ADJ (O) [TTS PROPN (B) system NOUN (I)] , and CCONJ (O) can VERB (O) be AUX (O) done VERB (O) from ADP (O) scratch NOUN (O) using VERB (O) a NOUN (O) dataset NOUN (O) of ADP (O) short ADJ (O) [audio NOUN (B) clips NOUN (I)] and CCONJ (O) corresponding VERB (O) textual NOUN (O) transcripts NOUN . (O) 
In ADP (O) contrast NOUN , (O) reproducing VERB (O) either CCONJ (O) of ADP (O) the DET (O) aforementioned ADJ (O) systems NOUN (O) requires VERB (O) access NOUN (O) and CCONJ (O) understanding NOUN (O) of ADP (O) a NOUN (O) pre VERB - existing ADJ (O) [TTS PROPN (B) system NOUN (I)] , because SCONJ (O) they PRON (O) use NOUN (O) features VERB (O) from ADP (O) another DET (O) [TTS PROPN (B) system NOUN (I)] either CCONJ (O) at ADP (O) training NOUN (O) or CCONJ (O) inference NOUN (O) time NOUN . (O) 
Second PROPN , (O) [Deep ADJ (B) Voice PROPN (I)] minimizes NOUN (O) the DET (O) use NOUN (O) of ADP (O) hand NOUN - engineered VERB (O) features VERB (O) ; it PRON (O) uses VERB (O) [one NUM - hot ADJ (B) encoded VERB (I) characters NOUN (I)] for ADP (O) [grapheme NOUN (B) to ADP (I) phoneme PROPN (I) conversion NOUN (I)] , [one NUM - hot ADJ (B) encoded VERB (I) phonemes PROPN (I)] and CCONJ (O) stresses VERB , (O) [phoneme NOUN (B) durations NOUN (I)] in ADP (O) milliseconds VERB , (O) and CCONJ (O) normalized ADJ (O) log NOUN (O) [fundamental ADJ (B) frequency NOUN (I)] that DET (O) can VERB (O) be AUX (O) computed VERB (O) from ADP (O) [waveforms NOUN (B)] using VERB (O) any DET (O) F0 NOUN (O) estimation NOUN (O) algorithm PROPN . (O) 
All DET (O) of ADP (O) these DET (O) can VERB (O) easily ADV (O) be AUX (O) obtained VERB (O) from ADP (O) [audio NOUN (B)] and CCONJ (O) transcripts NOUN (O) with ADP (O) minimal ADJ (O) effort NOUN . (O) 
In ADP (O) contrast NOUN , (O) prior ADJ (O) works VERB (O) use NOUN (O) a NOUN (O) much ADJ (O) more ADJ (O) [complex NOUN (B) feature NOUN (I) representation NOUN (I)] , that DET (O) effectively ADV (O) makes VERB (O) reproducing VERB (O) the DET (O) system NOUN (O) impossible ADJ (O) without ADP (O) a NOUN (O) pre VERB - existing ADJ (O) [TTS PROPN (B) system NOUN (I)] . 
[WaveNet PROPN (B)] uses VERB (O) [several ADJ (B) features VERB (I)] from ADP (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] (Zen PROPN (O) et NOUN (O) al PROPN . , (O) 2013 NUM) , (O) that SCONJ (O) include VERB (O) values NOUN (O) such ADJ (O) as SCONJ (O) the DET (O) number NOUN (O) of ADP (O) syllables NOUN (O) in ADP (O) a NOUN (O) word NOUN , (O) position NOUN (O) of ADP (O) syllables NOUN (O) in ADP (O) the DET (O) phrase NOUN , (O) position NOUN (O) of ADP (O) the DET (O) current ADJ (O) frame NOUN (O) in ADP (O) the DET (O) [phoneme NOUN (B)] , and CCONJ (O) [dynamic ADJ (B) features VERB (I)] of ADP (O) the DET (O) [speech NOUN (B) spectrum NOUN (I)] like SCONJ (O) [spectral NOUN (B)] and CCONJ (O) excitation NOUN (O) parameters NOUN , (O) as SCONJ (O) well INTJ (O) as SCONJ (O) their DET (O) time NOUN (O) derivatives NOUN . (O) 
Char2Wav PROPN (O) relies VERB (O) on ADP (O) [vocoder NOUN (B) features VERB (I)] from ADP (O) the DET (O) WORLD NOUN (O) [TTS PROPN (B) system NOUN (I)] (Morise NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) for ADP (O) pre NOUN - training ADJ (O) their DET (O) alignment NOUN (O) module NOUN (O) which DET (O) include VERB (O) F0 NOUN , (O) [spectral NOUN (B) envelope NOUN (I)] , and CCONJ (O) aperiodic PROPN (O) parameters NOUN . (O) 
Finally ADV , (O) we PRON (O) focus NOUN (O) on ADP (O) creating VERB (O) a NOUN (O) production NOUN - ready ADJ (O) system NOUN , (O) which DET (O) requires VERB (O) that SCONJ (O) our DET (O) models NOUN (O) run NOUN (O) in ADP (O) real ADJ - time NOUN (O) for ADP (O) inference NOUN . (O) 
[Deep ADJ (B) Voice PROPN (I)] can VERB (O) synthesize VERB (O) [audio NOUN (B)] in ADP (O) fractions NOUN (O) of ADP (O) a NOUN (O) second ADV , (O) and CCONJ (O) offers VERB (O) a NOUN (O) tunable ADJ (O) trade NOUN - off NOUN (O) between ADP (O) synthesis NOUN (O) speed NOUN (O) and CCONJ (O) [audio NOUN (B) quality NOUN (I)] . 
In ADP (O) contrast NOUN , (O) previous ADJ (O) results VERB (O) with ADP (O) [WaveNet PROPN (B)] require VERB (O) several ADJ (O) minutes NOUN (O) of ADP (O) runtime NOUN (O) to ADP (O) synthesize VERB (O) one NUM (O) second NOUN (O) of ADP (O) [audio NOUN (B)] . 
We PRON (O) are AUX (O) unaware ADJ (O) of ADP (O) similar ADJ (O) benchmarks VERB (O) for ADP (O) [SampleRNN NOUN (B)] , but CCONJ (O) the DET (O) 3-tier NUM (O) architecture NOUN (O) as SCONJ (O) described VERB (O) in ADP (O) the DET (O) original ADJ (O) publication NOUN (O) requires VERB (O) approximately ADV (O) 4 NUM - 5X NOUN (O) as SCONJ (O) much ADJ (O) compute NOUN (O) during ADP (O) inference NOUN (O) as SCONJ (O) our DET (O) largest ADJ (O) [WaveNet PROPN (B) models NOUN (I)] , so CCONJ (O) running VERB (O) the DET (O) model NOUN (O) in ADP (O) real ADJ - time NOUN (O) may VERB (O) prove VERB (O) challenging NOUN . (O) 

 [TTS PROPN (B) System NOUN (I)] Components PROPN (O) 

 As SCONJ (O) shown VERB (O) in ADP (O) Fig PROPN . (O) 1 NUM , (O) the DET (O) [TTS PROPN (B) system NOUN (I)] consists VERB (O) of ADP (O) five NUM (O) major NOUN (O) building NOUN (O) blocks PROPN (O) : 
• X (O) The DET (O) [grapheme NOUN - to ADP - phoneme NOUN (B) model NOUN (I) converts NOUN (I)] from ADP (O) written VERB (O) text NOUN (O) (English PROPN (O) characters NOUN) (O) to ADP (O) phonemes NOUN (O) (encoded VERB (O) using VERB (O) a NOUN (O) phonemic NOUN (O) alphabet PROPN (O) such ADJ (O) as SCONJ (O) ARPABET ADV) . (O) 
• X (O) The DET (O) [segmentation NOUN (B) model NOUN (I)] locates VERB (O) [phoneme NOUN (B) boundaries NOUN (I)] in ADP (O) the DET (O) [voice NOUN (B) dataset NOUN (I)] . Given VERB (O) an DET (O) [audio NOUN (B) file NOUN (I)] and CCONJ (O) a NOUN (O) [phoneme NOUN - by ADP - phoneme NOUN (B) transcription NOUN (I)] of ADP (O) the DET (O) [audio NOUN (B)] , the DET (O) [segmentation NOUN (B) model NOUN (I)] identifies VERB (O) where ADV (O) in ADP (O) the DET (O) [audio NOUN (B)] each DET (O) [phoneme NOUN (B)] begins VERB (O) and CCONJ (O) ends VERB . (O) 
• X (O) The DET (O) [phoneme NOUN (B) duration NOUN (I) model NOUN (I)] predicts VERB (O) the DET (O) temporal NOUN (O) duration NOUN (O) of ADP (O) every DET (O) [phoneme NOUN (B)] in ADP (O) a NOUN (O) [phoneme NOUN (B) sequence NOUN (I)] (an DET (O) utterance NOUN) . (O) 
• X (O) The DET (O) [fundamental ADJ (B) frequency NOUN (I) model NOUN (I)] predicts VERB (O) whether SCONJ (O) a NOUN (O) [phoneme NOUN (B)] is AUX (O) voiced VERB . (O) If SCONJ (O) it PRON (O) is AUX , (O) the DET (O) model NOUN (O) predicts VERB (O) the DET (O) [fundamental ADJ (B) frequency NOUN (I)] (F0 PROPN) (O) throughout ADP (O) the DET (O) [phoneme NOUN (B)] ’s PART duration NOUN . (O) 
• X (O) The DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] combines VERB (O) the DET (O) outputs VERB (O) of ADP (O) the DET (O) [grapheme NOUN - to ADP - phoneme NOUN (B)] , [phoneme NOUN (B) duration NOUN (I)] , and CCONJ (O) [fundamental ADJ (B) frequency NOUN (I) prediction NOUN (I) models NOUN (I)] and CCONJ (O) synthesizes NOUN (O) [audio NOUN (B)] at ADP (O) a NOUN (O) high ADJ (O) sampling NOUN (O) rate NOUN , (O) corresponding VERB (O) to ADP (O) the DET (O) desired VERB (O) text NOUN . (O) 

 During ADP (O) inference NOUN , (O) text NOUN (O) is AUX (O) fed PROPN (O) through ADP (O) the DET (O) [grapheme NOUN - to ADP (B) phoneme NOUN (I) model NOUN (I)] or CCONJ (O) a NOUN (O) [phoneme NOUN (B) dictionary PROPN (I)] to PART (O) generate NOUN (O) [phonemes NOUN (B)] . 
Next ADV , (O) the DET (O) [phonemes NOUN (B)] are AUX (O) provided VERB (O) as SCONJ (O) inputs VERB (O) to ADP (O) the DET (O) [phoneme NOUN (B) duration NOUN (I) model NOUN (I)] and CCONJ (O) F0 NOUN (O) [prediction NOUN (B) model NOUN (I)] to PART (O) assign NOUN (O) durations NOUN (O) to ADP (O) each DET (O) [phoneme NOUN (B)] and CCONJ (O) generate NOUN (O) an DET (O) F0 NOUN (O) contour NOUN . (O) 
Finally ADV , (O) the DET (O) [phonemes NOUN (B)] , [phoneme NOUN (B) durations NOUN (I)] , and CCONJ (O) F0 NOUN (O) are AUX (O) used VERB (O) as SCONJ (O) local ADJ (O) conditioning NOUN (O) [input NOUN (B) features VERB (I)] to PART (O) the DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] , which DET (O) generates VERB (O) the DET (O) final ADJ (O) utterance NOUN . (O) 
Unlike PROPN (O) the DET (O) other ADJ (O) models NOUN , (O) the DET (O) [segmentation NOUN (B) model NOUN (I)] is AUX (O) not PART (O) used VERB (O) during ADP (O) inference NOUN . (O) 
Instead ADV , (O) it PRON (O) is AUX (O) used VERB (O) to ADP (O) annotate NOUN (O) the DET (O) [training NOUN (B) voice NOUN (I) data NOUN (I)] with ADP (O) [phoneme NOUN (B) boundaries NOUN (I)] . 
The DET (O) [phoneme NOUN (B) boundaries NOUN (I)] imply VERB (O) durations NOUN , (O) which DET (O) can VERB (O) be AUX (O) used VERB (O) to ADP (O) train NOUN (O) the DET (O) [phoneme NOUN (B) duration NOUN (I) model NOUN (I)] . 
The DET (O) [audio NOUN (B)] , annotated VERB (O) with ADP (O) [phonemes NOUN (B)] and CCONJ (O) [phoneme NOUN (B) durations NOUN (I)] as SCONJ (O) well INTJ (O) as SCONJ (O) [fundamental ADJ (B) frequency NOUN (I)] , is AUX (O) used VERB (O) to ADP (O) train NOUN (O) the DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] . 
In ADP (O) the DET (O) following VERB (O) sections NOUN , (O) we PRON (O) describe VERB (O) all DET (O) the DET (O) building NOUN (O) blocks PROPN (O) in ADP (O) detail NOUN . (O) 

 [Grapheme PROPN - to ADP - Phoneme PROPN (B) Model NOUN (I)] 

 Our DET (O) [grapheme NOUN - to ADP - phoneme NOUN (B) model NOUN (I)] is AUX (O) based VERB (O) on ADP (O) the DET (O) [encoder NOUN - decoder NOUN (B) architecture NOUN (I)] developed VERB (O) by ADP (O) (Yao PROPN (O) & Zweig PROPN , (O) 2015 NUM) . (O) 
However ADV , (O) we PRON (O) use NOUN (O) a NOUN (O) [multi ADJ - layer ADJ (B) bidirectional ADJ (I) encoder NOUN (I)] with ADP (O) a NOUN (O) [gated NOUN (B) recurrent NOUN (I) unit NOUN (I) (GRU PROPN) (I) nonlinearity NOUN (I)] and CCONJ (O) an DET (O) equally ADV (O) [deep ADJ (B) unidirectional NOUN (I) GRU PROPN (I) decoder NOUN (I)] (Chung PROPN (O) et NOUN (O) al PROPN . , (O) 2014 NUM) . (O) 
The DET (O) initial NOUN (O) state NOUN (O) of ADP (O) every DET (O) [decoder NOUN (B) layer NOUN (I)] is AUX (O) initialized VERB (O) to ADP (O) the DET (O) final ADJ (O) [hidden VERB (B) state NOUN (I)] of ADP (O) the DET (O) corresponding VERB (O) [encoder NOUN (B) forward NOUN (I) layer NOUN (I)] . 
The DET (O) architecture NOUN (O) is AUX (O) trained VERB (O) with ADP (O) teacher NOUN (O) forcing VERB (O) and CCONJ (O) decoding VERB (O) is AUX (O) performed VERB (O) using VERB (O) beam NOUN (O) search VERB . (O) 
We PRON (O) use NOUN (O) 3 NUM (O) bidirectional ADJ (O) layers NOUN (O) with ADP (O) 1024 NUM (O) units NOUN (O) each DET (O) in ADP (O) the DET (O) [encoder NOUN (B)] and CCONJ (O) 3 NUM (O) unidirectional ADJ (O) layers NOUN (O) of ADP (O) the DET (O) same ADJ (O) size NOUN (O) in ADP (O) the DET (O) [decoder NOUN (B)] and CCONJ (O) a NOUN (O) beam NOUN (O) search NOUN (O) with ADP (O) a NOUN (O) width NOUN (O) of ADP (O) 5 NUM (O) candidates NOUN . (O) 
During ADP (O) training NOUN , (O) we PRON (O) use NOUN (O) [dropout NOUN (B)] with ADP (O) probability NOUN (O) 0.95 NUM (O) after ADP (O) each DET (O) [recurrent NOUN (B) layer NOUN (I)] . 
For ADP (O) training NOUN , (O) we PRON (O) use NOUN (O) the DET (O) [Adam PROPN (B) optimization NOUN (I) algorithm PROPN (I)] with ADP (O) β X (O) 1 NUM (O) = 0.9 NUM , (O) β X (O) 2 NUM (O) = 0 PUNCT . (O) 
999 NUM , (O) ε NOUN (O) = 10 NUM (O) −8 PROPN , (O) a NOUN (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 64 NUM , (O) a NOUN (O) [learning NOUN (B) rate NOUN (I)] of ADP (O) 10 NUM (O) −3 PROPN , (O) and CCONJ (O) an DET (O) annealing VERB (O) rate NOUN (O) of ADP (O) 0.85 NUM (O) applied VERB (O) every DET (O) 1000 NUM (O) iterations NOUN (O) ([Kingma PROPN (B)] & Ba PROPN , (O) 2014 NUM) . (O) 

 [Segmentation NOUN (B) Model NOUN (I)] 

 Our DET (O) [segmentation NOUN (B) model NOUN (I)] is AUX (O) trained VERB (O) to ADP (O) output NOUN (O) the DET (O) alignment NOUN (O) between ADP (O) a NOUN (O) given VERB (O) utterance NOUN (O) and CCONJ (O) a NOUN (O) sequence NOUN (O) of ADP (O) [target NOUN (B) phonemes NOUN (I)] . 
This DET (O) task NOUN (O) is AUX (O) similar ADJ (O) to ADP (O) the DET (O) problem NOUN (O) of ADP (O) aligning VERB (O) [speech NOUN (B)] to PART (O) written VERB (O) output NOUN (O) in ADP (O) [speech NOUN (B) recognition NOUN (I)] . 
In ADP (O) that SCONJ (O) domain NOUN , (O) the DET (O) [connectionist NOUN (B) temporal NOUN (I) classification NOUN (I)] (CTC PROPN) (O) [loss NOUN (B) function NOUN (I)] has AUX (O) been AUX (O) shown VERB (O) to ADP (O) focus NOUN (O) on ADP (O) character NOUN (O) alignments VERB (O) to ADP (O) learn VERB (O) a NOUN (O) mapping NOUN (O) between ADP (O) sound NOUN (O) and CCONJ (O) text NOUN (O) (Graves NOUN (O) et NOUN (O) al PROPN . , (O) 2006 NUM) . (O) 
We PRON (O) adapt NOUN (O) the DET (O) convolutional ADJ (O) [recurrent NOUN (B) neural NOUN (I) network NOUN (I) architecture NOUN (I)] from ADP (O) a NOUN (O) state NOUN - of ADP - the DET - art NOUN (O) [speech NOUN (B) recognition NOUN (I) system NOUN (I)] (Amodei PROPN (O) et NOUN (O) al PROPN . , (O) 2015 NUM) (O) for ADP (O) [phoneme NOUN (B) boundary ADJ (I)] detection NOUN . (O) 
A PROPN (O) network NOUN (O) trained VERB (O) with ADP (O) CTC PROPN (O) to ADP (O) generate NOUN (O) [sequences NOUN (B) of ADP (I) phonemes PROPN (I)] will VERB (O) produce NOUN (O) brief NOUN (O) peaks VERB (O) for ADP (O) every DET (O) output NOUN (O) [phoneme NOUN (B)] . 
Although SCONJ (O) this DET (O) is AUX (O) sufficient ADJ (O) to ADP (O) roughly ADV (O) align NOUN (O) the DET (O) [phonemes NOUN (B)] to PART (O) the DET (O) [audio NOUN (B)] , it PRON (O) is AUX (O) insufficient NOUN (O) to ADP (O) detect VERB (O) precise ADJ (O)     [phoneme NOUN (B) boundaries NOUN (I)] . 
To PART (O) overcome NOUN (O) this DET , (O) we PRON (O) train NOUN (O) to ADP (O) predict VERB (O) [sequences NOUN (B) of ADP (I) phoneme PROPN (I)] pairs NOUN (O) rather ADV (O) than SCONJ (O) single ADJ (O) [phonemes NOUN (B)] . 
The DET (O) network NOUN (O) will VERB (O) then ADV (O) tend NOUN (O) to ADP (O) output NOUN (O) [phoneme NOUN (B) pairs NOUN (I)] at ADP (O) timesteps PROPN (O) close NOUN (O) to ADP (O) the DET (O) boundary ADJ (O) between ADP (O) two NUM (O) [phonemes NOUN (B)] in ADP (O) a NOUN (O) pair NOUN . (O) 
To NOUN (O) illustrate VERB (O) our DET (O) label NOUN (O) encoding NOUN , (O) consider VERB (O) the DET (O) string NOUN (O) “ PUNCT (O) Hello INTJ (O) ! ” PUNCT . (O) 
To NOUN (O) convert NOUN (O) this DET (O) to ADP (O) a NOUN (O) [sequence NOUN (B) of ADP (I) phoneme PROPN (I)] pair NOUN (O) labels NOUN , (O) convert NOUN (O) the DET (O) utterance NOUN (O) to ADP (O) phonemes NOUN (O) (using VERB (O) a NOUN (O) [pronunciation NOUN (B) dictionary NOUN (I)] such ADJ (O) as SCONJ (O) [CMUDict NOUN (B)] or CCONJ (O) a NOUN (O) [grapheme NOUN - to ADP - phoneme NOUN (B) model NOUN (I)]) and CCONJ (O) pad NOUN (O) the DET (O) [phoneme NOUN (B) sequence NOUN (I)] on ADP (O) either CCONJ (O) end NOUN (O) with ADP (O) the DET (O) silence NOUN (O) [phoneme NOUN (B)] to PART (O) get AUX (O) “ PUNCT (O) sil NOUN (O) HH PROPN (O) EH PROPN (O) L NOUN (O) OW PROPN (O) sil NOUN (O) ” PUNCT . (O) 
Finally ADV , (O) construct VERB (O) consecutive ADJ (O) [phoneme NOUN (B) pairs NOUN (I)] and CCONJ (O) get AUX (O) “ PUNCT (O) (sil NOUN , (O) HH PROPN) , (O) (HH PROPN , (O) EH PROPN) , (O) (EH INTJ , (O) L NOUN) , (O) (L NOUN , (O) OW PROPN) , (O) (OW PROPN , (O) sil NOUN) (O) ” PUNCT . (O) 
Input NOUN (O) [audio NOUN (B)] is AUX (O) featurized VERB (O) by ADP (O) computing NOUN (O) 20 NUM (O) [Mel PROPN (B)]-frequency NOUN [cepstral ADJ (B) coefficients NOUN (I)] (MFCCs NOUN) (O) with ADP (O) a NOUN (O) ten NUM (O) millisecond NOUN (O) stride VERB . (O) 
On ADP (O) top NOUN (O) of ADP (O) the DET (O) input NOUN (O) layer NOUN , (O) there PRON (O) are AUX (O) two NUM (O) convolution NOUN (O) layers NOUN (O) (2D VERB (O) convolutions NOUN (O) in ADP (O) time NOUN (O) and CCONJ (O) frequency NOUN) , (O) three NUM (O) bidirectional ADJ (O) recurrent NOUN (O) [GRU PROPN (B) layers NOUN (I)] , and CCONJ (O) finally ADV (O) a NOUN (O) [softmax PROPN (B) output NOUN (I) layer NOUN (I)] . 
The DET (O) convolution NOUN (O) layers NOUN (O) use NOUN (O) kernels NOUN (O) with ADP (O) unit NOUN (O) stride NOUN , (O) height NOUN (O) nine NUM (O) (in ADP (O) frequency NOUN (O) bins PROPN) , (O) and CCONJ (O) width NOUN (O) five NUM (O) (in ADP (O) time NOUN) (O) and CCONJ (O) the DET (O) [recurrent NOUN (B) layers NOUN (I)] use VERB (O) 512 NUM (O) [GRU PROPN (B) cells NOUN (I)] (for ADP (O) each DET (O) direction NOUN) . (O) 
[Dropout NOUN (B)] with ADP (O) a NOUN (O) probability NOUN (O) of ADP (O) 0.95 NUM (O) is AUX (O) applied VERB (O) after ADP (O) the DET (O) last ADJ (O) convolution NOUN (O) and CCONJ (O) [recurrent NOUN (B) layers NOUN (I)] . 
To PART (O) compute NOUN (O) the DET (O) [phoneme NOUN (B) pair NOUN (I) error NOUN (I) rate NOUN (I)] ([PPER PROPN (B)]) , we PRON (O) decode NOUN (O) using VERB (O) beam NOUN (O) search VERB . (O) 
To NOUN (O) decode NOUN (O) [phoneme NOUN (B) boundaries NOUN (I)] , we PRON (O) perform VERB (O) a NOUN (O) beam NOUN (O) search NOUN (O) with ADP (O) width NOUN (O) 50 NUM (O) with ADP (O) the DET (O) constraint NOUN (O) that DET (O) neighboring NOUN (O) [phoneme NOUN (B) pairs NOUN (I)] overlap VERB (O) by ADP (O) at ADP (O) least ADJ (O) one NUM (O) [phoneme NOUN (B)] and CCONJ (O) keep VERB (O) track NOUN (O) of ADP (O) the DET (O) positions NOUN (O) in ADP (O) the DET (O) utterance NOUN (O) of ADP (O) each DET (O) [phoneme NOUN (B) pair NOUN (I)] . 
For ADP (O) training NOUN , (O) we PRON (O) use NOUN (O) the DET (O) [Adam PROPN (B) optimization NOUN (I) algorithm PROPN (I)] with ADP (O) β X (O) 1 NUM (O) = 0.9 NUM , (O) β X (O) 2 NUM (O) = 0 PUNCT . (O) 
999 NUM , (O) ε NOUN (O) = 10 NUM (O) −8 PROPN , (O) a NOUN (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 128 NUM , (O) a NOUN (O) [learning NOUN (B) rate NOUN (I)] of ADP (O) 10 NUM (O) −4 NUM , (O) and CCONJ (O) an DET (O) annealing VERB (O) rate NOUN (O) of ADP (O) 0.95 NUM (O) applied VERB (O) every DET (O) 500 NUM (O) iterations NOUN (O) ([Kingma PROPN (B)] & Ba PROPN , (O) 2014 NUM) . (O) 

 [Phoneme PROPN (B) Duration NOUN (I) and CCONJ (I) Fundamental PROPN (I) Frequency PROPN (I) Model NOUN (I)] 

 We PRON (O) use NOUN (O) a NOUN (O) single ADJ (O) architecture NOUN (O) to ADP (O) jointly ADV (O) predict VERB (O) [phoneme NOUN (B) duration NOUN (I)] and CCONJ (O) [time NOUN - dependent ADJ (B) fundamental ADJ (I) frequency NOUN (I)] . 
The DET (O) input NOUN (O) to ADP (O) the DET (O) model NOUN (O) is AUX (O) a NOUN (O) [sequence NOUN (B) of ADP (I) phonemes PROPN (I)] with ADP (O) stresses VERB , (O) with ADP (O) each DET (O) [phoneme NOUN (B)] and CCONJ (O) stress NOUN (O) being NOUN (O) encoded VERB (O) as SCONJ (O) a NOUN (O) [one NUM - hot ADJ (B) vector NOUN (I)] . 
The DET (O) architecture NOUN (O) comprises VERB (O) two NUM (O) fully ADV (O) connected VERB (O) layers NOUN (O) with ADP (O) 256 NUM (O) units NOUN (O) each DET (O) followed VERB (O) by ADP (O) two NUM (O) unidirectional ADJ (O) [recurrent NOUN (B) layers NOUN (I)] with ADP (O) 128 NUM (O) [GRU PROPN (B) cells NOUN (I)] each DET (O) and CCONJ (O) finally ADV (O) a NOUN (O) fullyconnected ADJ (O) [output NOUN (B) layer NOUN (I)] . 
[Dropout NOUN (B)] with ADP (O) a NOUN (O) probability NOUN (O) of ADP (O) 0.8 NUM (O) is AUX (O) applied VERB (O) after ADP (O) the DET (O) initial NOUN (O) fully ADV - connected VERB (O) layers NOUN (O) and CCONJ (O) the DET (O) last ADJ (O) [recurrent NOUN (B) layer NOUN (I)] . 
The DET (O) final ADJ (O) layer NOUN (O) produces VERB (O) three NUM (O) estimations NOUN (O) for ADP (O) every DET (O) input NOUN (O) [phoneme NOUN (B)] : the DET (O) [phoneme NOUN (B) duration NOUN (I)] , the DET (O) probability NOUN (O) that SCONJ (O) the DET (O) [phoneme NOUN (B)] is AUX (O) voiced VERB (O) (i.e. X (O) has AUX (O) a NOUN (O) [fundamental ADJ (B) frequency NOUN (I)]) , and CCONJ (O) 20 NUM (O) [time NOUN - dependent ADJ (B) F0 NOUN (I) values NOUN (I)] , which DET (O) are AUX (O) sampled VERB (O) uniformly ADV (O) over ADP (O) the DET (O) predicted VERB (O) duration NOUN . (O) 
The DET (O) model NOUN (O) is AUX (O) optimized VERB (O) by ADP (O) minimizing NOUN (O) a NOUN (O) joint NOUN (O) loss NOUN (O) that SCONJ (O) combines VERB (O) [phoneme NOUN (B) duration NOUN (I) error NOUN (I)] , [fundamental ADJ (B) frequency NOUN (I) error NOUN (I)] , the DET (O) negative ADJ (O) [log NOUN (B) likelihood NOUN (I)] of ADP (O) the DET (O) probability NOUN (O) that SCONJ (O) the DET (O) [phoneme NOUN (B)] is AUX (O) voiced VERB , (O) and CCONJ (O) a NOUN (O) penalty NOUN (O) term NOUN (O) proportional ADJ (O) to ADP (O) the DET (O) absolute PROPN (O) change NOUN (O) of ADP (O) F0 NOUN (O) with ADP (O) respect NOUN (O) to ADP (O) time NOUN (O) to ADP (O) impose VERB (O) smoothness ADJ . (O) 
The DET (O) specific ADJ (O) functional ADJ (O) form NOUN (O) of ADP (O) the DET (O) [loss NOUN (B) function NOUN (I)] is AUX (O) described VERB (O) in ADP (O) Appendix PROPN (O) B. PROPN (O) 
For ADP (O) training NOUN , (O) we PRON (O) use NOUN (O) the DET (O) [Adam PROPN (B) optimization NOUN (I) algorithm PROPN (I)] with ADP (O) β X (O) 1 NUM (O) = 0.9 NUM , (O) β X (O) 2 NUM (O) = 0.999 NUM , (O) ε NOUN (O) = 10 NUM (O) −8 PROPN , (O) a NOUN (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 128 NUM , (O) a NOUN (O) [learning NOUN (B) rate NOUN (I)] of ADP (O) 3 NUM (O) × PROPN (O) 10 NUM (O) −4 NUM , (O) and CCONJ (O) an DET (O) annealing VERB (O) rate NOUN (O) of ADP (O) 0.9886 PROPN (O) applied VERB (O) every DET (O) 400 NUM (O) iterations NOUN (O) ([Kingma PROPN (B)] & Ba PROPN , (O) 2014 NUM) . (O) 

 [Audio NOUN (B) Synthesis PROPN (I) Model NOUN (I)] 

 Our DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] is AUX (O) a NOUN (O) variant NOUN (O) of ADP (O) [WaveNet PROPN (B)] . 
[WaveNet PROPN (B)] consists VERB (O) of ADP (O) a NOUN (O) conditioning NOUN (O) network NOUN , (O) which DET (O) upsamples NOUN (O) [linguistic NOUN (B) features VERB (I)] to PART (O) the DET (O) desired VERB (O) frequency NOUN , (O) and CCONJ (O) an DET (O) autoregressive ADJ (O) network NOUN , (O) which DET (O) generates VERB (O) a NOUN (O) probability NOUN (O) distribution NOUN (O) P(y PROPN) (O) over ADP (O) discretized ADJ (O) [audio NOUN (B) samples NOUN (I)] y NOUN (O) ∈ NOUN (O) { 0 NUM , (O) 1 NUM , ... PUNCT , (O) 255 NUM (O) } . (O) 
We PRON (O) vary VERB (O) the DET (O) number NOUN (O) of ADP (O) layers NOUN (O) ` , (O) the DET (O) number NOUN (O) of ADP (O) residual ADJ (O) channels NOUN (O) r NOUN (O) (dimension NOUN (O) of ADP (O) the DET (O) [hidden VERB (B) state NOUN (I)] of ADP (O) every DET (O) layer NOUN) , (O) and CCONJ (O) the DET (O) number NOUN (O) of ADP (O) skip NOUN (O) channels NOUN (O) s NOUN (O) (the DET (O) dimension NOUN (O) to ADP (O) which DET (O) layer NOUN (O) outputs NOUN (O) are AUX (O) projected VERB (O) prior ADJ (O) to ADP (O) the DET (O) [output NOUN (B) layer NOUN (I)]) . 
[WaveNet PROPN (B)] consists VERB (O) of ADP (O) an DET (O) upsampling NOUN (O) and CCONJ (O) conditioning NOUN (O) network NOUN , (O) followed VERB (O) by ADP (O) ` 2×1 NUM (O) convolution NOUN (O) layers NOUN (O) with ADP (O) r NOUN (O) residual ADJ (O) output NOUN (O) channels NOUN (O) and CCONJ (O) gated VERB (O) [tanh NOUN (B)] nonlinearities NOUN . (O) 
We PRON (O) break NOUN (O) the DET (O) convolution NOUN (O) into ADP (O) two NUM (O) matrix NOUN (O) multiplies NOUN (O) per ADP (O) timestep NOUN (O) with ADP (O) W NOUN (O) prev NOUN (O) and CCONJ (O) W NOUN (O) cur PROPN . (O) 
These DET (O) layers NOUN (O) are AUX (O) connected VERB (O) with ADP (O) [residual ADJ (B) connections NOUN (I)] . 
The DET (O) hidden VERB (O) state NOUN (O) of ADP (O) every DET (O) layer NOUN (O) is AUX (O) concatenated VERB (O) to ADP (O) an DET (O) ` r NOUN (O) [vector NOUN (B)] and CCONJ (O) projected VERB (O) to ADP (O) s NOUN (O) skip NOUN (O) channels NOUN (O) with ADP (O) W NOUN (O) skip NOUN , (O) followed VERB (O) by ADP (O) two NUM (O) layers NOUN (O) of ADP (O) 1 NUM (O) × PROPN (O) 1 NUM (O) convolutions NOUN (O) (with ADP (O) weights NOUN (O) W NOUN (O) [relu NOUN (B)] and CCONJ (O) W NOUN (O) out ADV) (O) with ADP (O) [relu NOUN (B)] nonlinearities NOUN . (O) 
[WaveNet PROPN (B)] uses VERB (O) transposed VERB (O) convolutions NOUN (O) for ADP (O) upsampling NOUN (O) and CCONJ (O) conditioning NOUN . (O) 
We PRON (O) find VERB (O) that SCONJ (O) our DET (O) models NOUN (O) perform VERB (O) better ADJ , (O) train NOUN (O) faster ADV , (O) and CCONJ (O) require VERB (O) fewer ADJ (O) parameters NOUN (O) if SCONJ (O) we PRON (O) instead ADV (O) first ADJ (O) encode NOUN (O) the DET (O) inputs VERB (O) with ADP (O) a NOUN (O) stack NOUN (O) of ADP (O) bidirectional ADJ (O) quasi-[RNN NOUN (B) (QRNN PROPN) (I) layers NOUN (I)] (Bradbury NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) and CCONJ (O) then ADV (O) perform VERB (O) upsampling NOUN (O) by ADP (O) repetition NOUN (O) to ADP (O) the DET (O) desired VERB (O) frequency NOUN . (O) 
Our DET (O) [highest ADJ - quality NOUN (B) final ADJ (I) model NOUN (I)] uses VERB (O) ` = 40 NUM (O) layers NOUN , (O) r NOUN (O) = 64 NUM (O) residual ADJ (O) channels NOUN , (O) and CCONJ (O) s NOUN (O) = 256 NUM (O) skip NOUN (O) channels NOUN . (O) 
For ADP (O) training NOUN , (O) we PRON (O) use NOUN (O) the DET (O) [Adam PROPN (B) optimization NOUN (I) algorithm PROPN (I)] with ADP (O) β X (O) 1 NUM (O) = 0.9 NUM , (O) β X (O) 2 NUM (O) = 0.999 NUM , (O) ε NOUN (O) = 10 NUM (O) −8 PROPN , (O) a NOUN (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 8 NUM , (O) a NOUN (O) [learning NOUN (B) rate NOUN (I)] of ADP (O) 10 NUM (O) −3 PROPN , (O) and CCONJ (O) an DET (O) annealing VERB (O) rate NOUN (O) of ADP (O) 0.9886 PROPN (O) applied VERB (O) every DET (O) 1,000 NUM (O) iterations NOUN (O) ([Kingma PROPN (B)] & Ba PROPN , (O) 2014 NUM) . (O) 
Please INTJ (O) refer NOUN (O) to ADP (O) Appendix PROPN (O) A NOUN (O) for ADP (O) full ADJ (O) details NOUN (O) of ADP (O) our DET (O) [WaveNet PROPN (B) architecture NOUN (I)] and CCONJ (O) the DET (O) [QRNN PROPN (B) layers NOUN (I)] we PRON (O) use NOUN . (O) 

 Results NOUN (O) 

 We PRON (O) train NOUN (O) our DET (O) models NOUN (O) on ADP (O) an DET (O) internal ADJ (O) English PROPN (O) [speech NOUN (B) database NOUN (I)] containing VERB (O) approximately ADV (O) 20 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B) data NOUN (I)] segmented VERB (O) into ADP (O) 13,079 NUM (O) utterances VERB . (O) 
In ADP (O) addition NOUN , (O) we PRON (O) present NOUN (O) [audio NOUN (B) synthesis NOUN (I) results VERB (I)] for ADP (O) our DET (O) models NOUN (O) trained VERB (O) on ADP (O) a NOUN (O) subset NOUN (O) of ADP (O) the DET (O) Blizzard PROPN (O) 2013 NUM (O) data NOUN (O) (Prahallad PROPN (O) et NOUN (O) al PROPN . , (O) 2013 NUM) . (O) 
Both DET (O) datasets VERB (O) are AUX (O) spoken VERB (O) by ADP (O) a NOUN (O) professional ADJ (O) [female NOUN (B) speaker NOUN (I)] . 
All DET (O) of ADP (O) our DET (O) models NOUN (O) are AUX (O) implemented VERB (O) using VERB (O) the DET (O) TensorFlow PROPN (O) framework NOUN (O) (Abadi PROPN (O) et NOUN (O) al PROPN . , (O) 2015 NUM) . (O) 

 Segmentation NOUN (O) Results NOUN (O) 

 We PRON (O) train NOUN (O) on ADP (O) 8 NUM (O) TitanX NOUN (O) Maxwell PROPN (O) [GPUs NOUN (B)] , splitting NOUN (O) each DET (O) batch NOUN (O) equally ADV (O) among ADP (O) the DET (O) [GPUs NOUN (B)] and CCONJ (O) using VERB (O) a NOUN (O) ring NOUN (O) all DET - reduce NOUN (O) to ADP (O) average NOUN (O) gradients VERB (O) computed VERB (O) on ADP (O) different ADJ (O) [GPUs NOUN (B)] , with ADP (O) each DET (O) iteration NOUN (O) taking NOUN (O) approximately ADV (O) 1300 NUM (O) milliseconds VERB . (O) 
After ADP (O) approximately ADV (O) 14,000 NUM (O) iterations NOUN , (O) the DET (O) model NOUN (O) converges NOUN (O) to ADP (O) a NOUN (O) [phoneme NOUN (B) pair NOUN (I) error NOUN (I) rate NOUN (I)] of ADP (O) 7 NUM (O) % . (O) We PRON (O) also ADV (O) find VERB (O) that SCONJ (O) [phoneme NOUN (B) boundaries NOUN (I)] do AUX (O) not PART (O) have AUX (O) to ADP (O) be AUX (O) precise ADJ , (O) and CCONJ (O) randomly ADV (O) shifting NOUN (O) [phoneme NOUN (B) boundaries NOUN (I)] by ADP (O) 10 NUM - 30 NUM (O) milliseconds VERB (O) makes VERB (O) no DET (O) difference NOUN (O) in ADP (O) the DET (O) [audio NOUN (B) quality NOUN (I)] , and CCONJ (O) so CCONJ (O) suspect NOUN (O) that SCONJ (O) [audio NOUN (B) quality NOUN (I)] is AUX (O) insensitive ADJ (O) to ADP (O) the DET (O) [phoneme NOUN (B) pair NOUN (I) error NOUN (I) rate NOUN (I)] past ADJ (O) a NOUN (O) certain ADJ (O) point NOUN . (O) 

 [Grapheme PROPN - to ADP - Phoneme PROPN (B) Results NOUN (I)] 

 We PRON (O) train NOUN (O) a NOUN (O) [grapheme NOUN - to ADP - phoneme NOUN (B) model NOUN (I)] on ADP (O) data NOUN (O) obtained VERB (O) from ADP (O) [CMUDict NOUN (B)] (Weide PROPN , (O) 2008 NUM) . (O) We PRON (O) strip NOUN (O) out NOUN (O) all DET (O) words NOUN (O) that SCONJ (O) do AUX (O) not PART (O) start VERB (O) with ADP (O) a NOUN (O) letter NOUN , (O) contain NOUN (O) numbers NOUN , (O) or CCONJ (O) have AUX (O) multiple NOUN (O) pronunciations NOUN , (O) which DET (O) leaves VERB (O) 124,978 NUM (O) out NOUN (O) of ADP (O) the DET (O) original ADJ (O) 133,854 NUM (O) [grapheme PROPN - phoneme PROPN (B) sequence NOUN (I) pairs NOUN (I)] . 
We PRON (O) train NOUN (O) on ADP (O) a NOUN (O) single ADJ (O) TitanX NOUN (O) Maxwell PROPN (O) [GPU PROPN (B)] with ADP (O) each DET (O) iteration NOUN (O) taking NOUN (O) approximately ADV (O) 150 NUM (O) milliseconds VERB . (O) 
After ADP (O) approximately ADV (O) 20,000 NUM (O) iterations NOUN , (O) the DET (O) model NOUN (O) converges NOUN (O) to ADP (O) a NOUN (O) [phoneme NOUN (B) error NOUN (I) rate NOUN (I)] of ADP (O) 5.8 NUM (O) % and CCONJ (O) a NOUN (O) [word NOUN (B) error NOUN (I) rate NOUN (I)] of ADP (O) 28.7 NUM (O) % , (O) which DET (O) are AUX (O) on ADP (O) par NOUN (O) with ADP (O) previous ADJ (O) reported VERB (O) results VERB (O) (Yao PROPN (O) & Zweig PROPN , (O) 2015 NUM) . (O) 
Unlike PROPN (O) prior ADJ (O) work NOUN , (O) we PRON (O) do AUX (O) not PART (O) use NOUN (O) a NOUN (O) language NOUN (O) model NOUN (O) during ADP (O) decoding VERB (O) and CCONJ (O) do AUX (O) not PART (O) include VERB (O) words NOUN (O) with ADP (O) multiple NOUN (O) pronunciations NOUN (O) in ADP (O) our DET (O) data NOUN (O) set VERB . (O) 

 [Phoneme PROPN (B) Duration NOUN (I) and CCONJ (I) Fundamental PROPN (I) Frequency PROPN (I) Results NOUN (I)] 

 We PRON (O) train NOUN (O) on ADP (O) a NOUN (O) single ADJ (O) TitanX NOUN (O) Maxwell PROPN (O) [GPU PROPN (B)] with ADP (O) each DET (O) iteration NOUN (O) taking NOUN (O) approximately ADV (O) 120 NUM (O) milliseconds VERB . (O) 
After ADP (O) approximately ADV (O) 20,000 NUM (O) iterations NOUN , (O) the DET (O) model NOUN (O) converges NOUN (O) to ADP (O) a NOUN (O) mean VERB (O) absolute PROPN (O) error NOUN (O) of ADP (O) 38 NUM (O) milliseconds VERB (O) (for ADP (O) [phoneme NOUN (B) duration NOUN (I)]) and CCONJ (O) 29.4 NUM (O) Hz PROPN (O) (for ADP (O) [fundamental ADJ (B) frequency NOUN (I)]) . 

 [Audio NOUN (B) Synthesis PROPN (I) Results NOUN (I)] 

 We PRON (O) divide NOUN (O) the DET (O) utterances VERB (O) in ADP (O) our DET (O) [audio NOUN (B) dataset NOUN (I)] into ADP (O) one NUM (O) second NOUN (O) chunks NOUN (O) with ADP (O) a NOUN (O) quarter NOUN (O) second NOUN (O) of ADP (O) context NOUN (O) for ADP (O) each DET (O) chunk NOUN , (O) padding NOUN (O) each DET (O) utterance NOUN (O) with ADP (O) a NOUN (O) quarter NOUN (O) second NOUN (O) of ADP (O) silence NOUN (O) at ADP (O) the DET (O) beginning NOUN . (O) 
We PRON (O) filter NOUN (O) out NOUN (O) chunks NOUN (O) that SCONJ (O) are AUX (O) predominantly ADV (O) silence NOUN (O) and CCONJ (O) end NOUN (O) up NOUN (O) with ADP (O) 74,348 NUM (O) total NOUN (O) chunks NOUN . (O) 
We PRON (O) trained VERB (O) models NOUN (O) with ADP (O) varying NOUN (O) depth NOUN , (O) including VERB (O) 10 NUM , (O) 20 NUM , (O) 30 NUM , (O) and CCONJ (O) 40 NUM (O) layers NOUN (O) in ADP (O) the DET (O) residual ADJ (O) layer NOUN (O) stack NOUN . (O) 
We PRON (O) find VERB (O) that SCONJ (O) models NOUN (O) below ADP (O) 20 NUM (O) layers NOUN (O) result NOUN (O) in ADP (O) poor ADJ (O) quality NOUN (O) [audio NOUN (B)] . 
The DET (O) 20 NUM , (O) 30 NUM , (O) and CCONJ (O) 40 NUM (O) [layer NOUN (B) models NOUN (I)] all DET (O) produce NOUN (O) high ADJ (O) quality NOUN (O) recognizable ADJ (O) [speech NOUN (B)] , but CCONJ (O) the DET (O) 40 NUM (O) [layer NOUN (B) models NOUN (I)] have AUX (O) less ADJ (O) noise NOUN (O) than SCONJ (O) the DET (O) 20 NUM (O) [layer NOUN (B) models NOUN (I)] , which DET (O) can VERB (O) be AUX (O) detected VERB (O) with ADP (O) high ADJ (O) quality NOUN (O) over ADP - ear NOUN (O) headphones NOUN . (O) 
Previous ADJ (O) work NOUN (O) has AUX (O) emphasized VERB (O) the DET (O) importance NOUN (O) of ADP (O) receptive ADJ (O) field NOUN (O) size NOUN (O) in ADP (O) determining VERB (O) model NOUN (O) quality NOUN . (O) 
Indeed ADV , (O) the DET (O) 20 NUM (O) [layer NOUN (B) models NOUN (I)] have AUX (O) half NOUN (O) the DET (O) receptive ADJ (O) field NOUN (O) as SCONJ (O) the DET (O) 40 NUM (O) [layer NOUN (B) models NOUN (I)] . 
However ADV , (O) when ADV (O) run NOUN (O) at ADP (O) 48 NUM (O) kHz PROPN , (O) models NOUN (O) with ADP (O) 40 NUM (O) layers NOUN (O) have AUX (O) only ADV (O) 83 NUM (O) milliseconds VERB (O) of ADP (O) receptive ADJ (O) field NOUN , (O) but CCONJ (O) still ADV (O) generate NOUN (O) high ADJ (O) quality NOUN (O) [audio NOUN (B)] . 
This DET (O) suggests VERB (O) the DET (O) receptive ADJ (O) field NOUN (O) of ADP (O) the DET (O) 20 NUM (O) [layer NOUN (B) models NOUN (I)] is AUX (O) sufficient ADJ , (O) and CCONJ (O) we PRON (O) conjecture NOUN (O) the DET (O) difference NOUN (O) in ADP (O) [audio NOUN (B) quality NOUN (I)] is AUX (O) due ADJ (O) to ADP (O) some DET (O) other ADJ (O) factor NOUN (O) than SCONJ (O) receptive ADJ (O) field NOUN (O) size NOUN . (O) 
We PRON (O) train NOUN (O) on ADP (O) 8 NUM (O) TitanX NOUN (O) Maxwell PROPN (O) [GPUs NOUN (B)] with ADP (O) one NUM (O) chunk NOUN (O) per ADP (O) [GPU PROPN (B)] , using VERB (O) a NOUN (O) ring NOUN (O) allreduce NOUN (O) to ADP (O) average NOUN (O) gradients VERB (O) computed VERB (O) on ADP (O) different ADJ (O) [GPUs NOUN (B)] . 
Each DET (O) iteration NOUN (O) takes VERB (O) approximately ADV (O) 450 NUM (O) milliseconds VERB . (O) 
Our DET (O) model NOUN (O) converges NOUN (O) after ADP (O) approximately ADV (O) 300,000 NUM (O) iterations NOUN . (O) 
We PRON (O) find VERB (O) that SCONJ (O) a NOUN (O) single ADJ (O) 1.25s NUM (O) chunk NOUN (O) is AUX (O) sufficient ADJ (O) to ADP (O) saturate NOUN (O) the DET (O) compute NOUN (O) on ADP (O) the DET (O) [GPU PROPN (B)] and CCONJ (O) that SCONJ (O) batching NOUN (O) does AUX (O) not PART (O) increase NOUN (O) training NOUN (O) efficiency NOUN . (O) 
As SCONJ (O) is AUX (O) common ADJ (O) with ADP (O) high ADJ - dimensional ADJ (O) generative PROPN (O) models NOUN (O) (Theis PROPN (O) et NOUN (O) al PROPN . , (O) 2015 NUM) , (O) model NOUN (O) loss NOUN (O) is AUX (O) somewhat ADV (O) uncorrelated ADJ (O) with ADP (O) perceptual NOUN (O) quality NOUN (O) of ADP (O) individual NOUN (O) samples NOUN . (O) 
While SCONJ (O) models NOUN (O) with ADP (O) unusually ADV (O) high ADJ (O) loss NOUN (O) sound NOUN (O) distinctly ADV (O) noisy PROPN , (O) models NOUN (O) that SCONJ (O) optimize NOUN (O) below ADP (O) a NOUN (O) certain ADJ (O) threshold NOUN (O) do AUX (O) not PART (O) have AUX (O) a NOUN (O) loss NOUN (O) indicative ADJ (O) of ADP (O) their DET (O) quality NOUN . (O) 
In ADP (O) addition NOUN , (O) changes VERB (O) in ADP (O) [model NOUN (B) architecture NOUN (I)] (such ADJ (O) as SCONJ (O) depth NOUN (O) and CCONJ (O) output NOUN (O) frequency NOUN) (O) can VERB (O) have AUX (O) a NOUN (O) significant ADJ (O) impact NOUN (O) on ADP (O) model NOUN (O) loss NOUN (O) while SCONJ (O) having VERB (O) a NOUN (O) small ADJ (O) effect NOUN (O) on ADP (O) [audio NOUN (B) quality NOUN (I)] . 
To PART (O) estimate NOUN (O) perceptual NOUN (O) quality NOUN (O) of ADP (O) the DET (O) individual NOUN (O) stages NOUN (O) of ADP (O) our DET (O) [TTS PROPN (B) pipeline NOUN (I)] , we PRON (O) crowdsourced VERB (O) [mean NOUN (B) opinion NOUN (I) score NOUN (I)] ([MOS PROPN (B)]) ratings NOUN (O) (ratings NOUN (O) between ADP (O) one NUM (O) and CCONJ (O) five NUM , (O) higher ADJ (O) values NOUN (O) being NOUN (O) better ADV) (O) from ADP (O) Mechanical PROPN (O) Turk PROPN (O) using VERB (O) the DET (O) CrowdMOS PUNCT (O) [toolkit NOUN (B)] and CCONJ (O) methodology NOUN (O) (Ribeiro PROPN (O) et NOUN (O) al PROPN . , (O) 2011 NUM) . (O) 
In ADP (O) order NOUN (O) to ADP (O) separate ADJ (O) the DET (O) effect NOUN (O) of ADP (O) the DET (O) [audio NOUN (B)] preprocessing VERB , (O) the DET (O) [WaveNet PROPN (B) model NOUN (I)] quality NOUN , (O) and CCONJ (O) the DET (O) [phoneme NOUN (B) duration NOUN (I) and CCONJ (I) fundamental ADJ (I) frequency NOUN (I) model NOUN (I)] quality NOUN , (O) we PRON (O) present NOUN (O) [MOS PROPN (B) scores NOUN (I)] for ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) utterance NOUN (O) types NOUN , (O) including VERB (O) synthesis NOUN (O) results VERB (O) where ADV (O) the DET (O) [WaveNet PROPN (B) inputs VERB (I)] (duration NOUN (O) and CCONJ (O) F0 NOUN) (O) are AUX (O) extracted VERB (O) from ADP (O) [ground NOUN (B) truth NOUN (I) audio NOUN (I)] rather ADV (O) than SCONJ (O)     synthesized VERB (O) by ADP (O) other ADJ (O) models NOUN . (O) 
The DET (O) results VERB (O) are AUX (O) presented VERB (O) in ADP (O) Table NOUN (O) 1 NUM . (O) 
We PRON (O) purposefully ADV (O) include VERB (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] in ADP (O) every DET (O) batch NOUN (O) of ADP (O) samples NOUN (O) that SCONJ (O) raters NOUN (O) evaluate VERB (O) to ADP (O) highlight NOUN (O) the DET (O) delta PROPN (O) from ADP (O) human NOUN (O) [speech NOUN (B)] and CCONJ (O) allow VERB (O) raters NOUN (O) to ADP (O) distinguish NOUN (O) finer PROPN (O) grained VERB (O) differences NOUN (O) between ADP (O) models NOUN (O) ; the DET (O) downside NOUN (O) of ADP (O) this DET (O) approach NOUN (O) is AUX (O) that SCONJ (O) the DET (O) resulting VERB (O) [MOS PROPN (B) scores NOUN (I)] will VERB (O) be AUX (O) significantly ADV (O) lower ADJ (O) than SCONJ (O) if SCONJ (O) raters NOUN (O) are AUX (O) presented VERB (O) only ADV (O) with ADP (O) synthesized VERB (O) [audio NOUN (B) samples NOUN (I)] . 
First ADV (O) of ADP (O) all DET , (O) we PRON (O) find VERB (O) a NOUN (O) significant ADJ (O) drop NOUN (O) in ADP (O) [MOS PROPN (B)] when ADV (O) simply ADV (O) downsampling VERB (O) the DET (O) [audio NOUN (B)] stream NOUN (O) from ADP (O) 48 NUM (O) kHz PROPN (O) to ADP (O) 16 NUM (O) kHz PROPN , (O) especially ADV (O) in ADP (O) combination NOUN (O) with ADP (O) μ NOUN - law NOUN (O) companding NOUN (O) and CCONJ (O) quantization NOUN , (O) likely ADV (O) because SCONJ (O) a NOUN (O) 48 NUM (O) kHz PROPN (O) sample NOUN (O) is AUX (O) presented VERB (O) to ADP (O) the DET (O) raters NOUN (O) as SCONJ (O) a NOUN (O) baseline NOUN (O) for ADP (O) a NOUN (O) 5 NUM (O) score NOUN , (O) and CCONJ (O) a NOUN (O) low ADJ (O) quality NOUN (O) noisy PROPN (O) synthesis NOUN (O) result NOUN (O) is AUX (O) presented VERB (O) as SCONJ (O) a NOUN (O) 1 NUM . (O) 
When ADV (O) used VERB (O) with ADP (O) ground NOUN (O) truth NOUN (O) durations NOUN (O) and CCONJ (O) F0 NOUN , (O) our DET (O) models NOUN (O) score NOUN (O) highly ADV , (O) with ADP (O) the DET (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN (O) of ADP (O) our DET (O) models NOUN (O) intersecting NOUN (O) those DET (O) of ADP (O) the DET (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] . 
However ADV , (O) using VERB (O) synthesized VERB (O) frequency NOUN (O) reduces VERB (O) the DET (O) [MOS PROPN (B)] , and CCONJ (O) further NOUN (O) including VERB (O) synthesized VERB (O) durations NOUN (O) reduces VERB (O) it PRON (O) significantly ADV . (O) 
We PRON (O) conclude VERB (O) that DET (O) the DET (O) main ADJ (O) barrier NOUN (O) to ADP (O) progress NOUN (O) towards ADP (O) natural ADJ (O) [TTS PROPN (B)] lies VERB (O) with ADP (O) [duration NOUN (B) and CCONJ (I) fundamental ADJ (I) frequency NOUN (I) prediction NOUN (I)] , and CCONJ (O) our DET (O) systems NOUN (O) have AUX (O) not PART (O) meaningfully ADV (O) progressed VERB (O) past ADJ (O) the DET (O) state NOUN (O) of ADP (O) the DET (O) art NOUN (O) in ADP (O) that SCONJ (O) regard NOUN . (O) 
Finally ADV , (O) our DET (O) best ADJ (O) models NOUN (O) run NOUN (O) slightly ADV (O) slower NOUN (O) than SCONJ (O) real ADJ - time NOUN (O) (see VERB (O) Table NOUN (O) 2 NUM) , (O) so CCONJ (O) we PRON (O) demonstrate NOUN (O) that SCONJ (O) synthesis NOUN (O) quality NOUN (O) can VERB (O) be AUX (O) traded VERB (O) for ADP (O) inference NOUN (O) speed NOUN (O) by ADP (O) adjusting VERB (O) model NOUN (O) size NOUN (O) by ADP (O) obtaining VERB (O) scores NOUN (O) for ADP (O) models NOUN (O) that SCONJ (O) run NOUN (O) 1X PROPN (O) and CCONJ (O) 2X PROPN (O) faster ADV (O) than SCONJ (O) real ADJ - time NOUN . (O) 
We PRON (O) also ADV (O) tested VERB (O) [WaveNet PROPN (B) models NOUN (I)] trained VERB (O) on ADP (O) the DET (O) full ADJ (O) set NOUN (O) of ADP (O) features VERB (O) from ADP (O) the DET (O) original ADJ (O) [WaveNet PROPN (B)] publication NOUN , (O) but CCONJ (O) found VERB (O) no DET (O) perceptual NOUN (O) difference NOUN (O) between ADP (O) those DET (O) models NOUN (O) and CCONJ (O) models NOUN (O) trained VERB (O) on ADP (O) our DET (O) reduced VERB (O) [feature NOUN (B) set NOUN (I)] . 

 Blizzard PROPN (O) Results NOUN (O) 

 To PART (O) demonstrate NOUN (O) the DET (O) flexibility NOUN (O) of ADP (O) our DET (O) system NOUN , (O) we PRON (O) retrained VERB (O) all DET (O) of ADP (O) our DET (O) models NOUN (O) with ADP (O) identical NOUN (O) [hyperparameters NOUN (B)] on ADP (O) the DET (O) Blizzard PROPN (O) 2013 NUM (O) dataset NOUN (O) (Prahallad PROPN (O) et NOUN (O) al PROPN . , (O) 2013 NUM) . (O) 
For ADP (O) our DET (O) experiments NOUN , (O) we PRON (O) used VERB (O) a NOUN (O) 20.5 NUM (O) hour NOUN (O) subset NOUN (O) of ADP (O) the DET (O) dataset NOUN (O) segmented VERB (O) into ADP (O) 9,741 NUM (O) utterances VERB . (O) 
We PRON (O) evaluated VERB (O) the DET (O) model NOUN (O) using VERB (O) the DET (O) procedure NOUN (O) described VERB (O) in ADP (O) Section NOUN (O) 4.4 NUM , (O) which DET (O) encourages VERB (O) raters NOUN (O) to ADP (O) compare VERB (O) synthesized VERB (O) [audio NOUN (B)] directly ADV (O) with ADP (O) the DET (O) 
ground NOUN (O) truth NOUN . (O) 
On ADP (O) the DET (O) held VERB (O) out NOUN (O) set VERB , (O) 16 NUM (O) kHz PROPN (O) companded VERB (O) and CCONJ (O) expanded VERB (O) [audio NOUN (B)] receives VERB (O) a NOUN (O) [MOS PROPN (B) score NOUN (I)] of ADP (O) 4.65±0.13 NUM , (O) while SCONJ (O) our DET (O) synthesized VERB (O) [audio NOUN (B)] received VERB (O) a NOUN (O) [MOS PROPN (B) score NOUN (I)] of ADP (O) 2.67±0.37 NUM . (O) 

 Optimizing VERB (O) Inference NOUN (O) 

 Although SCONJ (O) [WaveNet PROPN (B)] has AUX (O) shown VERB (O) promise NOUN (O) in ADP (O) generating NOUN (O) highquality NOUN (O) [synthesized VERB (B) speech NOUN (I)] , initial ADJ (O) experiments NOUN (O) reported VERB (O) generation NOUN (O) times NOUN (O) of ADP (O) many ADJ (O) minutes NOUN (O) or CCONJ (O) hours NOUN (O) for ADP (O) short ADJ (O) utterances VERB . (O) 
[WaveNet PROPN (B) inference NOUN (I)] poses VERB (O) an DET (O) incredibly ADV (O) challenging NOUN (O) computational ADJ (O) problem NOUN (O) due ADJ (O) to ADP (O) the DET (O) high ADJ - frequency NOUN , (O) autoregressive ADJ (O) nature NOUN (O) of ADP (O) the DET (O) model NOUN , (O) which DET (O) requires VERB (O) orders NOUN (O) of ADP (O) magnitude NOUN (O) more ADJ (O) timesteps PROPN (O) than SCONJ (O) traditional ADJ (O) [recurrent NOUN (B) neural NOUN (I) networks NOUN (I)] . 
When ADV (O) generating NOUN (O) [audio NOUN (B)] , a DET (O) single ADJ (O) sample NOUN (O) must VERB (O) be AUX (O) generated VERB (O) in ADP (O) approximately ADV (O) 60 NUM (O) μs X (O) (for ADP (O) 16 NUM (O) kHz PROPN (O) [audio NOUN (B)]) or CCONJ (O) 20 NUM (O) μs X (O) (for ADP (O) 48 NUM (O) kHz PROPN (O) [audio NOUN (B)]) . 
For ADP (O) our DET (O) 40 NUM (O) [layer NOUN (B) models NOUN (I)] , this DET (O) means VERB (O) that SCONJ (O) a NOUN (O) single ADJ (O) layer NOUN (O) (consisting VERB (O) of ADP (O) several ADJ (O) matrix NOUN (O) multiplies NOUN (O) and CCONJ (O) nonlinearities NOUN) (O) must VERB (O) complete ADJ (O) in ADP (O) approximately ADV (O) 1 NUM . (O) 
5 NUM (O) μs X . (O) 
For ADP (O) comparison NOUN , (O) accessing VERB (O) a NOUN (O) value NOUN (O) that SCONJ (O) resides VERB (O) in ADP (O) main ADJ (O) memory NOUN (O) on ADP (O) a NOUN (O) [CPU NOUN (B)] can VERB (O) take VERB (O) 0.1 NUM (O) μs X . (O) 
In ADP (O) order NOUN (O) to ADP (O) perform VERB (O) inference NOUN (O) at ADP (O) real ADJ - time NOUN , (O) we PRON (O) must VERB (O) take VERB (O) great ADJ (O) care NOUN (O) to ADP (O) never ADV (O) recompute NOUN (O) any DET (O) results VERB , (O) store NOUN (O) the DET (O) entire ADJ (O) model NOUN (O) in ADP (O) the DET (O) processor NOUN (O) cache PROPN (O) (as SCONJ (O) opposed VERB (O) to ADP (O) main ADJ (O) memory NOUN) , (O) and CCONJ (O) optimally ADV (O) utilize VERB (O) the DET (O) available ADJ (O) computational ADJ (O) units NOUN . (O) 
These DET (O) same ADJ (O) techniques NOUN (O) could VERB (O) be AUX (O) used VERB (O) to ADP (O) accelerate VERB (O) image NOUN (O) synthesis NOUN (O) with ADP (O) PixelCNN PUNCT (O) (Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) to ADP (O) fractions NOUN (O) of ADP (O) a NOUN (O) second ADJ (O) per ADP (O) image NOUN . (O) 
Synthesizing PROPN (O) one NUM (O) second NOUN (O) of ADP (O) [audio NOUN (B)] with ADP (O) our DET (O) 40 NUM (O) layer NOUN (O) [WaveNet PROPN (B) model NOUN (I)] takes VERB (O) approximately ADV (O) 55×10 NUM (O) 9 NUM (O) floating VERB (O) point NOUN (O) operations NOUN (O) ([FLOPs PROPN (B)]) . 
The DET (O) activations VERB (O) in ADP (O) any DET (O) given VERB (O) layer NOUN (O) depend VERB (O) on ADP (O) the DET (O) activations VERB (O) in ADP (O) the DET (O) previous ADJ (O) layer NOUN (O) and CCONJ (O) the DET (O) previous ADJ (O) timestep NOUN , (O) so CCONJ (O) inference NOUN (O) must VERB (O) be AUX (O) done VERB (O) one NUM (O) timestep NOUN (O) and CCONJ (O) one NUM (O) layer NOUN (O) at ADP (O) a NOUN (O) time NOUN . (O) 
A PROPN (O) single ADJ (O) layer NOUN (O) requires VERB (O) only ADV (O) 42 NUM (O) × PROPN (O) 10 NUM (O) 3 NUM (O) [FLOPs PROPN (B)] , which DET (O) makes VERB (O) achieving VERB (O) meaningful ADJ (O) parallelism NOUN (O) difficult ADJ . (O) 
In ADP (O) addition NOUN (O) to ADP (O) the DET (O) compute PROPN (O) requirements NOUN , (O) the DET (O) model NOUN (O) has AUX (O) approximately ADV (O) 1.6 NUM (O) × PROPN (O) 10 NUM (O) 6 NUM (O) parameters NOUN , (O) which DET (O) equate NOUN (O) to ADP (O) about ADP (O) 6.4 NUM (O) MB NOUN (O) if SCONJ (O) represented VERB (O) in ADP (O) single ADJ (O) precision NOUN . (O) 
(See VERB (O) Appendix PROPN (O) E NOUN (O) for ADP (O) a NOUN (O) complete ADJ (O) performance NOUN (O) model NOUN .) (O) 
On ADP (O) [CPU NOUN (B)] , a DET (O) single ADJ (O) Haswell PROPN (O) or CCONJ (O) Broadwell PROPN (O) core NOUN (O) has AUX (O) a NOUN (O) peak NOUN (O) single ADJ - precision NOUN (O) throughput NOUN (O) of ADP (O) approximately ADV (O) 77 NUM (O) × PROPN (O) 10 NUM (O) 9 NUM (O) [FLOPs PROPN (B)] and CCONJ (O) an DET (O) L2-to PROPN - L1 PROPN (O) cache PROPN (O) bandwidth NOUN (O) of ADP (O) approximately ADV (O) 140 NUM (O) GB PROPN (O) / s NOUN (O) (1 NUM) . (O) 
The DET (O) model NOUN (O) must VERB (O) be AUX (O) loaded VERB (O) from ADP (O) cache PROPN (O) once ADV (O) per ADP (O) timestep NOUN , (O) which DET (O) requires VERB (O) a NOUN (O) bandwidth NOUN (O) of ADP (O) 100 NUM (O) GB PROPN (O) / s. PROPN (O) 
Even ADV (O) if SCONJ (O) the DET (O) model NOUN (O) were AUX (O) to ADP (O) fit NOUN (O) in ADP (O) L2 NOUN (O) cache PROPN , (O) the DET (O) implementation NOUN (O) would VERB (O) need NOUN (O) to ADP (O) utilize VERB (O) 70 NUM (O) % of ADP (O) the DET (O) maximum NOUN (O) bandwidth NOUN (O) and CCONJ (O) 70 NUM (O) % of ADP (O) the DET (O) peak NOUN (O) [FLOPS PROPN (B)] in ADP (O) order NOUN (O) to ADP (O) do AUX (O) inference NOUN (O) in ADP (O) realtime NOUN (O) on ADP (O) a NOUN (O) single ADJ (O) core NOUN . (O) 
Splitting NOUN (O) the DET (O) calculations NOUN (O) across ADP (O) multiple NOUN (O) cores NOUN (O) reduces VERB (O) the DET (O) difficulty NOUN (O) of ADP (O) the DET (O) problem NOUN , (O) but CCONJ (O) nonetheless ADV (O) it PRON (O) remains VERB (O) challenging NOUN (O) as SCONJ (O) inference NOUN (O) must VERB (O) operate VERB (O) at ADP (O) a NOUN (O) significant ADJ (O) fraction NOUN (O) of ADP (O) maximum NOUN (O) memory NOUN (O) bandwidth NOUN (O) and CCONJ (O) peak NOUN (O) [FLOPs PROPN (B)] and CCONJ (O) while SCONJ (O) keeping NOUN (O) threads NOUN (O) synchronized VERB . (O) 
A NOUN (O) [GPU PROPN (B)] has AUX (O) higher ADJ (O) memory NOUN (O) bandwidth NOUN (O) and CCONJ (O) peak NOUN (O) [FLOPs PROPN (B)] than SCONJ (O) a NOUN (O) [CPU NOUN (B)] but CCONJ (O) provides VERB (O) a NOUN (O) more ADJ (O) specialized PROPN (O) and CCONJ (O) hence ADV (O) restrictive ADJ (O) computational ADJ (O) model NOUN . (O) 
A PROPN (O) naive ADJ (O) implementation NOUN (O) that SCONJ (O) launches VERB (O) a NOUN (O) single ADJ (O) kernel NOUN (O) for ADP (O) every DET (O) layer NOUN (O) or CCONJ (O) timestep NOUN (O) is AUX (O) untenable ADJ , (O) but CCONJ (O) an DET (O) implementation NOUN (O) based VERB (O) on ADP (O) the DET (O) persistent NOUN (O) [RNN PROPN (B) technique NOUN (I)] (Diamos PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) may VERB (O) be AUX (O) able ADJ (O) to ADP (O) take VERB (O) advantage NOUN (O) of ADP (O) the DET (O) throughput NOUN (O) offered VERB (O) by ADP (O) [GPUs NOUN (B)] . 
We PRON (O) implement VERB (O) high ADJ - speed NOUN (O) optimized VERB (O) inference NOUN (O) kernels NOUN (O) for ADP (O) both DET (O) [CPU NOUN (B)] and CCONJ (O) [GPU PROPN (B)] and CCONJ (O) demonstrate NOUN (O) that SCONJ (O) [WaveNet PROPN (B) inference NOUN (I)] at ADP (O) faster ADJ - than SCONJ - real ADJ - time NOUN (O) speeds VERB (O) is AUX (O) achievable ADJ . (O) 
Table NOUN (O) 2 NUM (O) lists VERB (O) the DET (O) [CPU NOUN (B)] and CCONJ (O) [GPU PROPN (B) inference NOUN (I)] speeds VERB (O) for ADP (O) different ADJ (O) models NOUN . (O) 
In ADP (O) both DET (O) cases NOUN , (O) the DET (O) benchmarks VERB (O) include VERB (O) only ADV (O) the DET (O) autoregressive ADJ , (O) high ADJ - frequency NOUN (O) [audio NOUN (B) generation NOUN (I)] and CCONJ (O) do AUX (O) not PART (O) include VERB (O) the DET (O) generation NOUN (O) of ADP (O) linguistic ADJ (O) [conditioning NOUN (B) features VERB (I)] (which DET (O) can VERB (O) be AUX (O) done VERB (O) in ADP (O) parallel NOUN (O) for ADP (O) the DET (O) entire ADJ (O) utterance NOUN) . (O) 
Our DET (O) [CPU NOUN (B) kernels NOUN (I)] run VERB (O) at ADP (O) real ADJ - time NOUN (O) or CCONJ (O) faster ADJ - than SCONJ - real ADJ - time NOUN (O) for ADP (O) a NOUN (O) subset NOUN (O) of ADP (O) models NOUN , (O) while SCONJ (O) the DET (O) [GPU PROPN (B) models NOUN (I)] do AUX (O) not PART (O) yet CCONJ (O) match NOUN (O) this DET (O) performance NOUN . (O) 

 Assuming VERB (O) two NUM (O) 8-wide NUM (O) AVX PROPN (O) FMA PROPN (O) instructions NOUN (O) every DET (O) cycle NOUN (O) and CCONJ (O) an DET (O) L2-to PROPN - L1 PROPN (O) bandwidth NOUN (O) of ADP (O) 64 NUM (O) [bytes NOUN (B)] per ADP (O) cycle NOUN . (O) 


 Table NOUN . (O) [Mean PROPN (B) Opinion NOUN (I) Scores NOUN (I)] ([MOS PROPN (B)]) and CCONJ (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN (O) (CIs X) (O) for ADP (O) utterances VERB . (O) 
This DET (O) [MOS PROPN (B) score NOUN (I)] is AUX (O) a NOUN (O) relative NOUN (O) [MOS PROPN (B) score NOUN (I)] obtained VERB (O) by ADP (O) showing VERB (O) raters NOUN (O) the DET (O) same ADJ (O) utterance NOUN (O) across ADP (O) all DET (O) the DET (O) model NOUN (O) types NOUN (O) (which DET (O) encourages VERB (O) comparative ADJ (O) rating NOUN (O) and CCONJ (O) allows VERB (O) the DET (O) raters NOUN (O) to ADP (O) distinguish NOUN (O) finer PROPN (O) grained VERB (O) differences NOUN) . (O) 
Every DET (O) batch NOUN (O) of ADP (O) samples NOUN (O) also ADV (O) includes VERB (O) the DET (O) ground NOUN (O) truth NOUN (O) 48 NUM (O) kHz PROPN (O) recording NOUN , (O) which DET (O) makes VERB (O) all DET (O) our DET (O) ratings NOUN (O) comparative ADJ (O) to ADP (O) natural ADJ (O) [human NOUN (B) voices NOUN (I)] . 474 NUM (O) ratings NOUN (O) were AUX (O) collected VERB (O) for ADP (O) every DET (O) sample NOUN . (O) 
Unless SCONJ (O) otherwise ADV (O) mentioned VERB , (O) models NOUN (O) used VERB (O) [phoneme NOUN (B) durations NOUN (I)] and CCONJ (O) F0 NOUN (O) extracted VERB (O) from ADP (O) the DET (O) ground NOUN (O) truth NOUN , (O) rather ADV (O) than SCONJ (O) synthesized VERB (O) by ADP (O) the DET (O) duration NOUN (O) prediction NOUN (O) and CCONJ (O) [frequency NOUN (B) prediction NOUN (I) models NOUN (I)] , as SCONJ (O) well INTJ (O) as SCONJ (O) a NOUN (O) 16384 NUM (O) Hz PROPN (O) [audio NOUN (B) sampling NOUN (I) rate NOUN (I)] . 

 Table NOUN . (O) [CPU NOUN (B)] and CCONJ (O) [GPU PROPN (B) inference NOUN (I)] kernel NOUN (O) benchmarks VERB (O) for ADP (O) different ADJ (O) models NOUN (O) in ADP (O) float32 PROPN (O) and CCONJ (O) int16 X . (O) 
At ADP (O) least ADJ (O) one NUM (O) main ADJ (O) and CCONJ (O) one NUM (O) auxiliary ADJ (O) thread NOUN (O) were AUX (O) used VERB (O) for ADP (O) all DET (O) [CPU NOUN (B) kernels NOUN (I)] . These DET (O) kernels NOUN (O) operate VERB (O) on ADP (O) a NOUN (O) single ADJ (O) utterance NOUN (O) with ADP (O) no DET (O) batching NOUN . (O) 
[CPU NOUN (B) results NOUN (I)] are AUX (O) from ADP (O) a NOUN (O) Intel PROPN (O) Xeon PROPN (O) E5 NOUN - 2660 NUM (O) v3 NOUN (O) Haswell PROPN (O) processor NOUN (O) clocked VERB (O) at ADP (O) 2.6 NUM (O) GHz PROPN (O) and CCONJ (O) [GPU PROPN (B) results NOUN (I)] are AUX (O) from ADP (O) a NOUN (O) GeForce PROPN (O) GTX PROPN (O) Titan PROPN (O) X NOUN (O) Maxwell PROPN (O) [GPU PROPN (B)] . 

 [CPU NOUN (B) Implementation NOUN (I)] 

 We PRON (O) achieve VERB (O) real ADJ - time NOUN (O) [CPU NOUN (B) inference NOUN (I)] by ADP (O) avoiding VERB (O) any DET (O) recomputation NOUN , (O) doing VERB (O) cache PROPN - friendly ADJ (O) memory NOUN (O) accesses NOUN , (O) parallelizing VERB (O) work NOUN (O) via ADP (O) multithreading VERB (O) with ADP (O) efficient ADJ (O) synchronization NOUN , (O) minimizing NOUN (O) nonlinearity NOUN (O) [FLOPs PROPN (B)] , avoiding VERB (O) cache PROPN (O) thrashing NOUN (O) and CCONJ (O) thread NOUN (O) contention NOUN (O) via ADP (O) thread NOUN (O) pinning VERB , (O) and CCONJ (O) using VERB (O) custom NOUN (O) hardware NOUN - optimized VERB (O) routines NOUN (O) for ADP (O) matrix NOUN (O) multiplication NOUN (O) and CCONJ (O) convolution NOUN . (O) 
For ADP (O) the DET (O) [CPU NOUN (B) implementation NOUN (I)] , we PRON (O) split VERB (O) the DET (O) computation NOUN (O) into ADP (O) the DET (O) following VERB (O) steps NOUN (O) : 

 Sample NOUN (O) Embedding NOUN (O) : Compute PROPN (O) the DET (O) [WaveNet PROPN (B) input NOUN (I)] causal ADJ (O) convolution NOUN (O) by ADP (O) doing VERB (O) two NUM (O) sample NOUN (O) embeddings NOUN , (O) one NUM (O) for ADP (O) the DET (O) current ADJ (O) timestep NOUN (O) and CCONJ (O) one NUM (O) for ADP (O) the DET (O) previous ADJ (O)     timestep NOUN , (O) and CCONJ (O) summing VERB (O) them PRON (O) with ADP (O) a NOUN (O) bias NOUN . (O) That SCONJ (O) is AUX , (O) 

 Layer NOUN (O) Inference NOUN (O) : For ADP (O) every DET (O) layer NOUN (O) j PROPN (O) from ADP (O) j PROPN (O) = 1 NUM (O) to ADP (O) ` with ADP (O) dilation NOUN (O) width NOUN (O) d NOUN (O) : 
(a NOUN) (O) Compute PROPN (O) the DET (O) left VERB (O) half NOUN (O) of ADP (O) the DET (O) width NOUN - two NUM (O) dilated VERB (O) convolution NOUN (O) via ADP (O) a NOUN (O) [matrix NOUN - vector NOUN (B) multiply NOUN (I)] : 
(b NOUN) (O) Compute PROPN (O) the DET (O) right ADV (O) half NOUN (O) of ADP (O) the DET (O) dilated VERB (O) convolution NOUN (O) : 
(c PROPN) (O) Compute PROPN (O) the DET (O) hidden VERB (O) state NOUN (O) h NOUN (O) (j PROPN) (O) given VERB (O) the DET (O) conditioning NOUN (O) [vector NOUN (B)] L NOUN (O) h NOUN (O) : 
where ADV (O) v NOUN (O) 0 PUNCT (O) : r NOUN (O) denotes VERB (O) the DET (O) first ADJ (O) r NOUN (O) elements NOUN (O) of ADP (O) the DET (O) [vector NOUN (B)] v NOUN (O) and CCONJ (O) v NOUN (O) r:2r NOUN (O) denotes VERB (O) the DET (O) next ADJ (O) r NOUN (O) elements NOUN . (O) Then ADV , (O) compute NOUN (O) the DET (O) input NOUN (O) to ADP (O) the DET (O) next ADJ (O) layer NOUN (O) via ADP (O) a NOUN (O) [matrix NOUN - vector NOUN (B) multiply NOUN (I)] : 
(d NOUN) (O) Compute PROPN (O) the DET (O) contribution NOUN (O) to ADP (O) the DET (O) skip NOUN - channel NOUN (O) matrix NOUN (O) multiply NOUN (O) from ADP (O) this DET (O) layer NOUN , (O) accumulating NOUN (O) over ADP (O) all DET (O) layers NOUN , (O) with ADP (O) q PROPN (O) (0 PUNCT) (O) = B (O) skip NOUN (O) : 

 Output NOUN (O) : Compute PROPN (O) the DET (O) two NUM (O) output NOUN (O) 1 NUM (O) × PROPN (O) 1 NUM (O) convolutions NOUN (O) : 
Finally ADV , (O) sample NOUN (O) y NOUN (O) i+1 PROPN (O) randomly ADV (O) from ADP (O) the DET (O) distribution NOUN (O) p. NOUN (O) 

 We PRON (O) parallelize NOUN (O) these DET (O) across ADP (O) two NUM (O) groups NOUN (O) of ADP (O) threads NOUN (O) as SCONJ (O) depicted VERB (O) in ADP (O) Figure NOUN . (O) 
A PROPN (O) group NOUN (O) of ADP (O) main ADJ (O) threads NOUN (O) computes VERB (O) (j PROPN) (O) x NOUN (O) (0 PUNCT) , (O) a NOUN (O) cur PROPN , (O) h NOUN (O) (j PROPN) , (O) and CCONJ (O) x NOUN (O) (j PROPN) , (O) z NOUN (O) a NOUN , (O) and CCONJ (O) p. NOUN (O) 
A PROPN (O) group NOUN (O) of ADP (O) auxiliary ADJ (O) (j PROPN) (O) (j PROPN) (O) threads NOUN (O) computes VERB (O) a NOUN (O) prev NOUN , (O) q PROPN (O) (j PROPN) , (O) and CCONJ (O) z NOUN (O) s NOUN , (O) with ADP (O) the DET (O) a NOUN (O) prev NOUN (O) being NOUN (O) computed VERB (O) for ADP (O) the DET (O) next ADJ (O) upcoming ADJ (O) timestep NOUN (O) while SCONJ (O) the DET (O) main ADJ (O) threads NOUN (O) compute PROPN (O) z NOUN (O) a NOUN (O) and CCONJ (O) p. NOUN (O) 
Each DET (O) of ADP (O) these DET (O) groups NOUN (O) can VERB (O) consist VERB (O) of ADP (O) a NOUN (O) single ADJ (O) thread NOUN (O) or CCONJ (O) of ADP (O) multiple NOUN (O) threads NOUN (O) ; if SCONJ (O) there PRON (O) are AUX (O) multiple NOUN (O) threads NOUN , (O) each DET (O) thread NOUN (O) computes VERB (O) one NUM (O) block NOUN (O) of ADP (O) each DET (O) [matrix NOUN - vector NOUN (B) multiply NOUN (I)] , binary ADJ (O) operation NOUN , (O) or CCONJ (O) unary ADJ (O) operation NOUN , (O) and CCONJ (O) thread NOUN (O) barriers NOUN (O) are AUX (O) inserted VERB (O) as SCONJ (O) needed VERB . (O) 
Splitting NOUN (O) the DET (O) model NOUN (O) across ADP (O) multiple NOUN (O) threads NOUN (O) both DET (O) splits VERB (O) up NOUN (O) the DET (O) compute NOUN (O) and CCONJ (O) can VERB (O) also ADV (O) be AUX (O) used VERB (O) to ADP (O) ensure VERB (O) that DET (O) the DET (O) model NOUN (O) weights NOUN (O) fit PROPN (O) into ADP (O) the DET (O) processor NOUN (O) L2 NOUN (O) cache PROPN . (O) 
Pinning NOUN (O) threads NOUN (O) to ADP (O) physical ADJ (O) cores NOUN (O) (or CCONJ (O) disabling NOUN (O) hyperthreading VERB) (O) is AUX (O) important ADJ (O) for ADP (O) avoiding VERB (O) thread NOUN (O) contention NOUN (O) and CCONJ (O) cache PROPN (O) thrashing NOUN (O) and CCONJ (O) increases VERB (O) performance NOUN (O) by ADP (O) approximately ADV (O) 30 NUM (O) % . (O) 
Depending VERB (O) on ADP (O) model NOUN (O) size NOUN , (O) the DET (O) nonlinearities NOUN (O) ([tanh X (B)] , [sigmoid NOUN (B)] , and CCONJ (O) [softmax PROPN (B)]) can VERB (O) also ADV (O) take VERB (O) a NOUN (O) significant ADJ (O) fraction NOUN (O) of ADP (O) inference NOUN (O) time NOUN , (O) so CCONJ (O) we PRON (O) replace VERB (O) all DET (O) nonlinearities NOUN (O) with ADP (O) high ADJ - accuracy NOUN (O) approximations NOUN , (O) which DET (O) are AUX (O) detailed ADJ (O) in ADP (O) Appendix PROPN (O) C. PROPN (O) 
The DET (O) maximum NOUN (O) absolute NOUN (O) error NOUN (O) arising VERB (O) from ADP (O) these DET (O) approximations NOUN (O) is AUX (O) 1.5 NUM (O) × PROPN (O) 10 NUM (O) −3 PROPN (O) for ADP (O) [tanh NOUN (B)] , 2.5 NUM (O) × PROPN (O) 10 NUM (O) −3 PROPN (O) for ADP (O) [sigmoid NOUN (B)] , and CCONJ (O) 2.4 NUM (O) × PROPN (O) 10 NUM (O) −5 PROPN (O) for ADP (O) e NOUN (O) x. NOUN (O) 
With ADP (O) approximate NOUN (O) instead ADV (O) of ADP (O) exact NOUN (O) nonlinearities NOUN , (O) performance NOUN (O) increases VERB (O) by ADP (O) roughly ADV (O) 30 NUM (O) % . (O) 
We PRON (O) also ADV (O) implement VERB (O) inference NOUN (O) with ADP (O) weight NOUN (O) matrices NOUN (O) quantized VERB (O) to ADP (O) int16 NOUN (O) and CCONJ (O) find VERB (O) no DET (O) change NOUN (O) in ADP (O) perceptual NOUN (O) quality NOUN (O) when ADV (O) using VERB (O) quantization NOUN . (O) 
For ADP (O) larger ADJ (O) models NOUN , (O) quantization NOUN (O) offers VERB (O) a NOUN (O) significant ADJ (O) speedup NOUN (O) when ADV (O) using VERB (O) fewer ADJ (O) threads NOUN , (O) but CCONJ (O) overhead NOUN (O) of ADP (O) thread NOUN (O) synchronization NOUN (O) prevents VERB (O) it PRON (O) from ADP (O) being AUX (O) useful ADJ (O) with ADP (O) a NOUN (O) larger ADJ (O) number NOUN (O) of ADP (O) threads NOUN . (O) 
Finally ADV , (O) we PRON (O) write VERB (O) custom NOUN (O) AVX PROPN (O) assembly NOUN (O) kernels NOUN (O) for ADP (O) matrix NOUN (O) [vector NOUN (B)] multiplication NOUN (O) using VERB (O) PeachPy PROPN (O) (Dukhan PROPN , (O) 2015 NUM) (O) specialized PROPN (O) to ADP (O) our DET (O) matrix NOUN (O) sizes VERB . (O) 
Inference PROPN (O) using VERB (O) our DET (O) custom NOUN (O) assembly NOUN (O) kernels NOUN (O) is AUX (O) up NOUN (O) to ADP (O) 1.5X PROPN (O) faster ADV (O) than SCONJ (O) Intel PROPN (O) MKL PROPN (O) and CCONJ (O) 3.5X PROPN (O) faster ADV (O) than SCONJ (O) OpenBLAS PROPN (O) when ADV (O) using VERB (O) float32 PROPN . (O) 
Neither CCONJ (O) library NOUN (O) provides VERB (O) the DET (O) equivalent NOUN (O) int16 NOUN (O) operations NOUN . (O) 

 [GPU PROPN (B) Implementation NOUN (I)] 

 Due NOUN (O) to ADP (O) their DET (O) computational ADJ (O) intensity NOUN , (O) many ADJ (O) [neural NOUN (B) models NOUN (I)] are AUX (O) ultimately ADV (O) deployed VERB (O) on ADP (O) [GPUs NOUN (B)] , which DET (O) can VERB (O) have AUX (O) a NOUN (O) much ADJ (O) higher ADJ (O) computational ADJ (O) throughput NOUN (O) than SCONJ (O) CPUs NOUN . (O) 
Since SCONJ (O) our DET (O) model NOUN (O) is AUX (O) memory NOUN (O) bandwidth NOUN (O) and CCONJ (O) [FLOP PROPN (B)] bound VERB , (O) it PRON (O) may VERB (O) seem VERB (O) like INTJ (O) a NOUN (O) natural ADJ (O) choice NOUN (O) to ADP (O) run NOUN (O) inference NOUN (O) on ADP (O) a NOUN (O) [GPU PROPN (B)] , but CCONJ (O) it PRON (O) turns VERB (O) out NOUN (O) that SCONJ (O) comes VERB (O) with ADP (O) a NOUN (O) different ADJ (O) set NOUN (O) of ADP (O) challenges NOUN . (O) 
Usually ADV , (O) code NOUN (O) is AUX (O) run NOUN (O) on ADP (O) the DET (O) [GPU PROPN (B)] in ADP (O) a NOUN (O) sequence NOUN (O) of ADP (O) kernel NOUN (O) invocations NOUN , (O) with ADP (O) every DET (O) matrix NOUN (O) multiply NOUN (O) or CCONJ (O) [vector NOUN (B)] operation NOUN (O) being AUX (O) its DET (O) own ADJ (O) kernel NOUN . (O) 
However ADV , (O) the DET (O) latency NOUN (O) for ADP (O) a NOUN (O) [CUDA PROPN (B) kernel NOUN (I)] launch NOUN (O) (which DET (O) may VERB (O) be AUX (O) up NOUN (O) to ADP (O) 50 NUM (O) μs X) (O) combined VERB (O) with ADP (O) the DET (O) time NOUN (O) needed VERB (O) to ADP (O) load NOUN (O) the DET (O) entire ADJ (O) model NOUN (O) from ADP (O) [GPU PROPN (B)] memory NOUN (O) are AUX (O) prohibitively ADV (O) large ADJ (O) for ADP (O) an DET (O) approach NOUN (O) like INTJ (O) this DET . (O) 
An PROPN (O) inference NOUN (O) kernel NOUN (O) in ADP (O) this DET (O) style NOUN (O) ends VERB (O) up NOUN (O) being AUX (O) approximately ADV (O) 1000X PROPN (O) slower NOUN (O) than SCONJ (O) real ADJ - time NOUN . (O) 
To NOUN (O) get AUX (O) close NOUN (O) to ADP (O) real ADJ - time NOUN (O) on ADP (O) a NOUN (O) [GPU PROPN (B)] , we PRON (O) instead ADV (O) build NOUN (O) a NOUN (O) kernel NOUN (O) using VERB (O) the DET (O) techniques NOUN (O) of ADP (O) persistent NOUN (O) [RNNs PROPN (B)] (Diamos PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) which DET (O) generates VERB (O) all DET (O) samples NOUN (O) in ADP (O) the DET (O) output NOUN (O) [audio NOUN (B)] in ADP (O) a NOUN (O) single ADJ (O) kernel NOUN (O) launch NOUN . (O) 
The DET (O) weights NOUN (O) for ADP (O) the DET (O) model NOUN (O) are AUX (O) loaded VERB (O) to ADP (O) registers NOUN (O) once ADV (O) and CCONJ (O) then ADV (O) used VERB (O) without ADP (O) unloading NOUN (O) them PRON (O) for ADP (O) the DET (O) entire ADJ (O) duration NOUN (O) of ADP (O) inference NOUN . (O) 
Due PROPN (O) to ADP (O) the DET (O) mismatch NOUN (O) between ADP (O) the DET (O) [CUDA PROPN (B)] programming VERB (O) model NOUN (O) and CCONJ (O) such ADJ (O) persistent NOUN (O) kernels NOUN , (O) the DET (O) resulting VERB (O) kernels NOUN (O) are AUX (O) specialized PROPN (O) to ADP (O) particular ADJ (O) model NOUN (O) sizes VERB (O) and CCONJ (O) are AUX (O) incredibly ADV (O) labor NOUN - intensive ADJ (O) to ADP (O) write VERB . (O) 
Although SCONJ (O) our DET (O) [GPU PROPN (B) inference NOUN (I)] speeds VERB (O) are AUX (O) not PART (O) quite ADV (O) real ADJ - time NOUN (O) (Table NOUN (O) 2 NUM) , (O) we PRON (O) believe VERB (O) that SCONJ (O) with ADP (O) these DET (O) techniques NOUN (O) and CCONJ (O) a NOUN (O) better ADJ (O) implementation NOUN (O) we PRON (O) can VERB (O) achieve VERB (O) real ADJ - time NOUN (O) [WaveNet PROPN (B) inference NOUN (I)] on ADP (O) [GPUs NOUN (B)] as SCONJ (O) well INTJ (O) as SCONJ (O) CPUs NOUN . (O) 
Implementation NOUN (O) details NOUN (O) for ADP (O) the DET (O) persistent NOUN (O) [GPU PROPN (B) kernels NOUN (I)] are AUX (O) available ADJ (O) in ADP (O) Appendix PROPN (O) D. PROPN (O) 

 Conclusion NOUN (O) 

 In ADP (O) this DET (O) work NOUN , (O) we PRON (O) demonstrate NOUN (O) that SCONJ (O) current ADJ (O) [Deep ADJ (B) Learning NOUN (I) approaches VERB (I)] are AUX (O) viable ADJ (O) for ADP (O) all DET (O) the DET (O) components NOUN (O) of ADP (O) a NOUN (O) highquality NOUN (O) [text NOUN - to ADP - speech NOUN (B) engine NOUN (I)] by ADP (O) building NOUN (O) a NOUN (O) fully ADV (O) neural NOUN (O) system NOUN . (O) 
We PRON (O) optimize NOUN (O) inference NOUN (O) to ADP (O) faster ADJ - than SCONJ - real ADJ - time NOUN (O) speeds NOUN , (O) showing VERB (O) that SCONJ (O) these DET (O) techniques NOUN (O) can VERB (O) be AUX (O) applied VERB (O) to ADP (O) generate NOUN (O) [audio NOUN (B)] in ADP (O) real ADJ - time NOUN (O) in ADP (O) a NOUN (O) streaming NOUN (O) fashion NOUN . (O) 
Our DET (O) system NOUN (O) is AUX (O) trainable NOUN (O) without ADP (O) any DET (O) human NOUN (O) involvement NOUN , (O) dramatically ADV (O) simplifying VERB (O) the DET (O) process NOUN (O) of ADP (O) creating VERB (O) [TTS PROPN (B) systems NOUN (I)] . 
Our DET (O) work NOUN (O) opens VERB (O) many ADJ (O) new ADJ (O) possible ADJ (O) directions NOUN (O) for ADP (O) exploration NOUN . (O) 
Inference PROPN (O) performance NOUN (O) can VERB (O) be AUX (O) further ADJ (O) improved VERB (O) through ADP (O) careful ADJ (O) optimization NOUN , (O) model NOUN (O) quantization NOUN (O) on ADP (O) [GPU PROPN (B)] , and CCONJ (O) int8 PROPN (O) quantization NOUN (O) on ADP (O) [CPU NOUN (B)] , as SCONJ (O) well INTJ (O) as SCONJ (O) experimenting VERB (O) with ADP (O) other ADJ (O) architectures VERB (O) such ADJ (O) as SCONJ (O) the DET (O) Xeon PROPN (O) Phi PROPN . (O) 
Another DET (O) natural ADJ (O) direction NOUN (O) is AUX (O) removing VERB (O) the DET (O) separation NOUN (O) between ADP (O) stages NOUN (O) and CCONJ (O) merging NOUN (O) the DET (O) segmentation NOUN , (O) duration NOUN (O) prediction NOUN , (O) and CCONJ (O) [fundamental ADJ (B) frequency NOUN (I) prediction NOUN (I) models NOUN (I)] directly ADV (O) into ADP (O) the DET (O) [audio NOUN (B) synthesis NOUN (I) model NOUN (I)] , thereby ADV (O) turning VERB (O) the DET (O) problem NOUN (O) into ADP (O) a NOUN (O) full ADJ (O) [sequence NOUN - to ADP - sequence NOUN (B) model NOUN (I)] , creating VERB (O) a NOUN (O) single ADJ (O) [end NOUN - to ADP - end NOUN (B) trainable NOUN (I) TTS PROPN (I) system NOUN (I)] , and CCONJ (O) allowing VERB (O) us PROPN (O) to ADP (O) train NOUN (O) the DET (O) entire ADJ (O) system NOUN (O) with ADP (O) no DET (O) intermediate ADJ (O) supervision NOUN . (O) 
In ADP (O) lieu NOUN (O) of ADP (O) fusing NOUN (O) the DET (O) models NOUN , (O) improving VERB (O) the DET (O) duration NOUN (O) and CCONJ (O) frequency NOUN (O) models NOUN (O) via ADP (O) larger ADJ (O) [training NOUN (B) datasets VERB (I)] or CCONJ (O) generative PROPN (O) modeling NOUN (O) techniques NOUN (O) may VERB (O) have AUX (O) an DET (O) impact NOUN (O) on ADP (O) [voice NOUN (B) naturalness NOUN (I)] . 

