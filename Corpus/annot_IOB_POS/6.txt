DIRECTLY PROPN (O) MODELING NOUN (O) [SPEECH PROPN (B) WAVEFORMS PROPN (I)] BY PROPN (O) [NEURAL PROPN (B) NETWORKS PROPN (I)] FOR ADP (O) [STATISTICAL PROPN (B) PARAMETRIC PROPN (I) SPEECH PROPN (I) SYNTHESIS PROPN (I)] 


 ABSTRACT PROPN (O) 
This DET (O) paper NOUN (O) proposes VERB (O) a NOUN (O) novel NOUN (O) approach NOUN (O) for ADP (O) directly ADV - modeling VERB (O) [speech NOUN (B)] at ADP (O) the DET (O) [waveform PROPN (B)] level NOUN (O) using VERB (O) a NOUN (O) [neural NOUN (B) network NOUN (I)] . 
This DET (O) approach NOUN (O) uses VERB (O) the DET (O) [neural NOUN (B) network NOUN - based VERB (I) statistical ADJ (I) parametric NOUN (I) speech NOUN (I) synthesis NOUN (I) framework NOUN (I)] with ADP (O) a NOUN (O) specially ADV (O) designed VERB (O) [output NOUN (B) layer NOUN (I)] . 
As SCONJ (O) [acoustic ADJ (B) feature NOUN (I)] extraction NOUN (O) is AUX (O) integrated VERB (O) to ADP (O) [acoustic ADJ (B) model NOUN (I) training NOUN (I)] , it PRON (O) can VERB (O) overcome NOUN (O) the DET (O) limitations VERB (O) of ADP (O) conventional ADJ (O) approaches VERB , (O) such ADJ (O) as SCONJ (O) two NUM - step NOUN (O) ([feature NOUN (B) extraction NOUN (I)] and CCONJ (O) acoustic ADJ (O) modeling NOUN) (O) optimization NOUN , (O) use NOUN (O) of ADP (O) spectra PROPN (O) rather ADV (O) than SCONJ (O) [waveforms NOUN (B)] as SCONJ (O) targets NOUN , (O) use NOUN (O) of ADP (O) overlapping VERB (O) and CCONJ (O) shifting NOUN (O) frames NOUN (O) as SCONJ (O) unit NOUN , (O) and CCONJ (O) fixed VERB (O) [decision NOUN (B) tree NOUN (I)] structure NOUN . (O) Experimental PROPN (O) results VERB (O) show NOUN (O) that SCONJ (O) the DET (O) proposed VERB (O) approach NOUN (O) can VERB (O) directly ADV (O) maximize NOUN (O) the DET (O) likelihood NOUN (O) defined VERB (O) at ADP (O) the DET (O) [waveform PROPN (B)] domain NOUN . (O) 
Index NOUN (O) Terms NOUN (O) — PUNCT (O) [Statistical ADJ (B) parametric NOUN (I) speech NOUN (I) synthesis NOUN (I)] ; [neural NOUN (B) network NOUN (I)] ; [adaptive ADJ (B) cepstral ADJ (I) analysis NOUN (I)] . 

 INTRODUCTION VERB (O) 
While SCONJ (O) training NOUN (O) an DET (O) [acoustic ADJ (B) model NOUN (I)] for ADP (O) [statistical ADJ (B) parametric NOUN (I) speech NOUN (I) synthesis NOUN (I)] (SPSS PROPN) , (O) a NOUN (O) set NOUN (O) of ADP (O) parametric NOUN (O) representation NOUN (O) of ADP (O) [speech NOUN (B)] (e.g. ADV (O) cepstral ADJ , (O) line NOUN (O) [spectrum NOUN (B) pairs NOUN (I)] , [fundamental ADJ (B) frequency NOUN (I)] , and CCONJ (O) aperiodicity NOUN .) (O) at ADP (O) every DET (O) 5 NUM (O) ms NOUN (O) is AUX (O) first ADJ (O) extracted VERB (O) then ADV (O) relationships NOUN (O) between ADP (O) [linguistic NOUN (B) features VERB (I)] associated VERB (O) with ADP (O) the DET (O) [speech NOUN (B) waveform PROPN (I)] and CCONJ (O) the DET (O) extracted VERB (O) parameters NOUN (O) are AUX (O) modeled VERB (O) by ADP (O) an DET (O) [acoustic ADJ (B) model NOUN (I)] (e.g. ADV (O) [hidden VERB (B) Markov PROPN (I) models NOUN (I)] , [neural NOUN (B) networks NOUN (I)]) . 
Typically ADV , (O) a NOUN (O) minimum NOUN (O) mean VERB (O) squared PROPN (O) error NOUN (O) (MMSE PROPN) (O) or CCONJ (O) a NOUN (O) [maximum NOUN (B) likelihood NOUN (I)] (ML PROPN) (O) criterion NOUN (O) is AUX (O) used VERB (O) to ADP (O) estimate NOUN (O) the DET (O) model NOUN (O) parameters NOUN . (O) 
Extracting PROPN (O) a NOUN (O) parametric NOUN (O) representation NOUN (O) of ADP (O) [speech NOUN (B)] can VERB (O) also ADV (O) be AUX (O) viewed VERB (O) as SCONJ (O) ML PROPN (O) estimation NOUN (O) of ADP (O) the DET (O) model NOUN (O) parameters NOUN (O) given VERB (O) the DET (O) [waveform PROPN (B)] . 
Linear PROPN (O) predictive ADJ (O) analysis NOUN (O) assumes VERB (O) that SCONJ (O) the DET (O) generative PROPN (O) model NOUN (O) of ADP (O) [speech NOUN (B) waveform PROPN (I)] is AUX (O) autoregressive ADJ (O) (AR PROPN) (O) then ADV (O) fit PROPN (O) the DET (O) model NOUN (O) to ADP (O) the DET (O) [waveform PROPN (B)] based VERB (O) on ADP (O) the DET (O) ML PROPN (O) criterion NOUN . (O) In ADP (O) this DET (O) sense NOUN , (O) training NOUN (O) of ADP (O) an DET (O) [acoustic ADJ (B) model NOUN (I)] can VERB (O) be AUX (O) viewed VERB (O) as SCONJ (O) a NOUN (O) two NUM - step NOUN (O) optimization NOUN (O) : extract VERB (O) parametric NOUN (O) representation NOUN (O) of ADP (O) [speech NOUN (B)] based VERB (O) on ADP (O) the DET (O) ML PROPN (O) criterion NOUN , (O) then ADV (O) model NOUN (O) trajectories NOUN (O) of ADP (O) the DET (O) extracted VERB (O) parameters NOUN (O) with ADP (O) an DET (O) [acoustic ADJ (B) model NOUN (I)] . Therefore ADV , (O) the DET (O) current ADJ (O) framework NOUN (O) could VERB (O) be AUX (O) sub NOUN - optimal ADJ . (O) 
It PRON (O) is AUX (O) desirable ADJ (O) to ADP (O) combine VERB (O) these DET (O) two NUM (O) steps NOUN (O) in ADP (O) a NOUN (O) single ADJ (O) one NUM (O) and CCONJ (O) jointly ADV (O) optimize NOUN (O) both DET (O) [feature NOUN (B) extraction NOUN (I)] and CCONJ (O) acoustic ADJ (O) modeling NOUN . (O) 
There PRON (O) are AUX (O) a NOUN (O) couple NOUN (O) of ADP (O) attempts VERB (O) to ADP (O) integrate VERB (O) [feature NOUN (B) extraction NOUN (I)] and CCONJ (O)     [acoustic ADJ (B) model NOUN (I) training NOUN (I)] into ADP (O) a NOUN (O) single ADJ (O) framework NOUN , (O) e.g. ADV (O) the DET (O) log NOUN (O) [spectral NOUN (B)] distortion NOUN - version NOUN (O) of ADP (O) minimum NOUN (O) generation NOUN (O) error NOUN (O) training NOUN (O) (MGE PROPN - LSD PROPN) , (O) statistical ADJ (O) [vocoder NOUN (B)] (STAVOCO PROPN) , (O) [waveform NOUN - level NOUN (B) statistical ADJ (I) model NOUN (I)] , and CCONJ (O) [mel PROPN - cepstral ADJ (B) analysis NOUN (I)]-integrated VERB [hidden VERB (B) Markov PROPN (I) models NOUN (I)] ([HMMs NOUN (B)]) . 
However ADV , (O) there PRON (O) are AUX (O) limitations VERB (O) in ADP (O) these DET (O) approaches VERB , (O) such ADJ (O) as SCONJ (O) the DET (O) use NOUN (O) of ADP (O) spectra PROPN (O) rather ADV (O) than SCONJ (O) [waveforms NOUN (B)] , the DET (O) use NOUN (O) of ADP (O) overlapping VERB (O) and CCONJ (O) shifting NOUN (O) frames NOUN (O) as SCONJ (O) unit NOUN , (O) and CCONJ (O) fixing VERB (O) [decision NOUN (B) trees NOUN (I)] , which DET (O) represent VERB (O) the DET (O) mapping NOUN (O) from ADP (O) [linguistic NOUN (B) features VERB (I)] to PART (O) acoustic ADJ (O) ones NOUN . (O) 

 This DET (O) paper NOUN (O) aims VERB (O) to ADP (O) fully ADV (O) integrate VERB (O) [acoustic ADJ (B) feature NOUN (I)] extraction NOUN (O) into ADP (O) [acoustic ADJ (B) model NOUN (I) training NOUN (I)] and CCONJ (O) overcome NOUN (O) the DET (O) limitations VERB (O) of ADP (O) the DET (O) existing VERB (O) frameworks NOUN , (O) using VERB (O) the DET (O) recently ADV (O) proposed VERB (O) [neural NOUN (B) network NOUN - based VERB (I) speech NOUN (I) synthesis NOUN (I) framework NOUN (I)] with ADP (O) a NOUN (O) specially ADV (O) designed VERB (O) [output NOUN (B) layer NOUN (I)] which DET (O) includes VERB (O) inverse NOUN (O) filtering VERB (O) of ADP (O) the DET (O) [speech NOUN (B)] to PART (O) define NOUN (O) the DET (O) likelihood NOUN (O) at ADP (O) the DET (O) [waveform PROPN (B)] level NOUN . (O) 
An PROPN (O) efficient ADJ (O) training NOUN (O) algorithm PROPN (O) based VERB (O) on ADP (O) this DET (O) framework NOUN (O) which DET (O) can VERB (O) run NOUN (O) sequentially ADV (O) in ADP (O) a NOUN (O) sample NOUN - by ADP - sample NOUN (O) manner NOUN (O) is AUX (O) also ADV (O) derived VERB . (O) 
The DET (O) rest NOUN (O) of ADP (O) the DET (O) paper NOUN (O) is AUX (O) organized VERB (O) as SCONJ (O) follows VERB . (O) Section NOUN (O) defines VERB (O) the DET (O) [waveform NOUN - level NOUN (B) probability NOUN (I) density NOUN (I) function NOUN (I)] . 
Section NOUN (O) gives VERB (O) the DET (O) training NOUN (O) algorithm PROPN . (O) Preliminary PROPN (O) experimental NOUN (O) results VERB (O) are AUX (O) presented VERB (O) in ADP (O) Section NOUN . (O) 
Concluding VERB (O) remarks VERB (O) are AUX (O) given VERB (O) in ADP (O) the DET (O) final ADJ (O) section NOUN . (O) 

 [WAVEFORM PROPN - LEVEL PROPN (B) DEFINITION PROPN (I)] OF ADP (O) [PROBABILITY NOUN (B) DENSITY NOUN (I) FUNCTION PROPN (I)] OF ADP (O) [SPEECH PROPN (B)] 
Cepstral PROPN (O) representation NOUN (O) 
A NOUN (O) discrete ADJ - time NOUN (O) [speech NOUN (B) signal NOUN (I)] x X (O) = x(0 X) , (O) x(1 NOUN) , ... PUNCT , (O) x(T PUNCT (O) − PROPN (O) 1)⊤ NUM (O) corresponding VERB (O) to ADP (O) an DET (O) utterance NOUN (O) or CCONJ (O) whole NOUN (O) [speech NOUN (B) database NOUN (I)] is AUX (O) assumed VERB (O) to ADP (O) be AUX (O) a NOUN (O) zero NUM - mean NOUN (O) stationary NOUN (O) [Gaussian PROPN (B) process NOUN (I)] . 
The DET (O) [probability NOUN (B) density NOUN (I) function NOUN (I)] of ADP (O) a NOUN (O) zero NUM - mean NOUN (O) stationary NOUN (O) [Gaussian PROPN (B) process NOUN (I)] can VERB (O) be AUX (O) written VERB (O) as SCONJ (O) 



 and CCONJ (O) H(ejω ADV) (O) is AUX (O) the DET (O) power NOUN (O) [spectrum NOUN (B)] of ADP (O) the DET (O) [Gaussian PROPN (B) process NOUN (I)] . 
This DET (O) paper NOUN (O) assumes VERB (O) that SCONJ (O) the DET (O) corresponding VERB (O) minimum ADJ - phase NOUN (O) system NOUN (O) function NOUN (O) H(ejω ADV) (O) is AUX (O) parameterized VERB (O) by ADP (O) [cepstral ADJ (B) coefficients NOUN (I)] c NOUN (O) as SCONJ (O) 

 lthough NOUN (O) x NOUN (O) should VERB (O) be AUX (O) an DET (O) infinite PROPN (O) sequence NOUN , (O) it PRON (O) is AUX (O) described VERB (O) as SCONJ (O) a NOUN (O) finite NOUN (O) sequence NOUN (O) for ADP (O) notation NOUN (O) simplicity NOUN . (O) 

 By ADP (O) assuming VERB (O) x NOUN (O) is AUX (O) an DET (O) infinite PROPN (O) sequence NOUN , (O) the DET (O) covariance NOUN (O) matrix NOUN (O) Σc PROPN (O) can VERB (O) be AUX (O) decomposed VERB (O) as SCONJ (O) follows VERB (O) : 

 where ADV (O) I (O) is AUX (O) an DET (O) identity NOUN (O) matrix PROPN . (O)                                                           
                                                                                    
 Nonstationarity NOUN (O) modeling NOUN (O) 
To NOUN (O) model NOUN (O) the DET (O) nonstationary ADJ (O) nature NOUN (O) of ADP (O) the DET (O) [speech NOUN (B) signal NOUN (I)] , x SYM (O) is AUX (O) assumed VERB (O) to ADP (O) be AUX (O) segment NOUN - by ADP - segment NOUN (O) piecewise NOUN - stationary PROPN , (O) i.e. X (O) Ac NOUN (O) in ADP (O) Eq PROPN . (O) (9 NUM) (O) is AUX (O) assumed VERB (O) to ADP (O) be AUX (O) 
               
 and CCONJ (O) I (O) is AUX (O) the DET (O) number NOUN (O) of ADP (O) segments NOUN (O) in ADP (O) x NOUN (O) corresponding VERB (O) to ADP (O) an DET (O) utterance NOUN (O) or CCONJ (O) whole NOUN (O) [speech NOUN (B) database NOUN (I)] and CCONJ (O) thus ADV (O) T NOUN (O) = L NOUN (O) × PROPN (O) I. PROPN (O)                                            

 TRAINING NOUN (O) ALGORITHM PROPN (O) 
Derivative PROPN (O) of ADP (O) the DET (O) [log NOUN (B) likelihood NOUN (I)] 
With ADP (O) some DET (O) elaboration NOUN , (O) the DET (O) partial NOUN (O) derivative ADJ (O) of ADP (O) Eq PROPN . (O) w.r.t PROPN . (O) c(i PROPN) (O) can VERB (O) be AUX (O) derived VERB (O) as SCONJ (O) 

 where ADV (O) 

 and CCONJ (O) δ(m X) (O) is AUX (O) the DET (O) unit NOUN (O) impulse PROPN (O) function NOUN . (O) 

 Sequential PROPN (O) algorithm NOUN (O) 
For ADP (O) calculating VERB (O) the DET (O) impulse PROPN (O) response NOUN (O) a(i PROPN) (O) (n PROPN) (O) using VERB (O) a NOUN (O) recursive NOUN (O) formula NOUN , (O) O(M PROPN (O) N NUM) (O) operations NOUN (O) are AUX (O) required VERB (O) at ADP (O) each DET (O) segment NOUN (O) i PRON , (O) even ADV (O) if SCONJ (O) it PRON (O) is AUX (O) truncated VERB (O) with ADP (O) a NOUN (O) sufficiently ADV (O) large ADJ (O) number NOUN (O) of ADP (O) N. NOUN (O) 
Furthermore ADV , (O) for ADP (O) calculating VERB (O) Eq PROPN . , (O) O(N NOUN (O) (M NOUN (O) + L NOUN)) (O) operations NOUN (O) are AUX (O) required VERB (O) for ADP (O) each DET (O) segment NOUN (O) i. NOUN (O) 
To NOUN (O) reduce VERB (O) the DET (O) computational ADJ (O) burden NOUN , (O) the DET (O) following VERB (O) two NUM (O) approximations NOUN (O) are AUX (O) applied VERB (O) ; 
By ADP (O) assuming VERB (O) 

 where ADV (O) 


 As SCONJ (O) an DET (O) approximation NOUN , (O) inverse NOUN (O) filtering VERB (O) in ADP (O) Eq.can PUNCT (O) be AUX (O) efficiently ADV (O) calculated VERB (O) by ADP (O) the DET (O) log NOUN (O) magnitude NOUN (O) approximation NOUN (O) (LMA PROPN) (O) filterwhose NOUN (O) coefficients NOUN (O) are AUX (O) given VERB (O) by ADP (O) 


 Similarderivation PROPN (O) can VERB (O) be AUX (O) found VERB (O) in ADP (O) Eqs PROPN . (O) 
The DET (O) LMA PROPN (O) filter NOUN (O) is AUX (O) a NOUN (O) special ADJ (O) type NOUN (O) of ADP (O) digital PROPN (O) filter NOUN (O) which DET (O) can VERB (O) approximate NOUN (O) the DET (O) system NOUN (O) function NOUN (O) of ADP (O) Eq PROPN . (O) 

 Fig PROPN . (O) Block PROPN (O) diagram PROPN (O) of ADP (O) the DET (O) proposed VERB (O) [waveform PROPN (B)]-based VERB framework NOUN (O) (L NOUN (O) = 1 NUM , (O) M PROPN (O) = 3 NUM) . (O) 
For ADP (O) notation NOUN (O) simplicity NOUN , (O) here ADV (O) [acoustic ADJ (B) model NOUN (I)] is AUX (O) illustrated VERB (O) as SCONJ (O) a NOUN (O) [feed NOUN - forward NOUN (B) neural NOUN (I) network NOUN (I)] rather ADV (O) than SCONJ (O) [LSTM PROPN - RNN PROPN (B)] . 

 With ADP (O) these DET (O) approximations NOUN , (O) a NOUN (O) simple ADJ (O) structure NOUN (O) for ADP (O) training NOUN (O) a NOUN (O) [neural NOUN (B) network NOUN - based VERB (I) acoustic ADJ (I) model NOUN (I)] , which DET (O) represents VERB (O) a NOUN (O) mapping NOUN (O) from ADP (O) [linguistic NOUN (B) features VERB (I)] to PART (O) [speech NOUN (B) signals NOUN (I)] , can VERB (O) be AUX (O) derived VERB . (O) 
It PRON (O) can VERB (O) run NOUN (O) in ADP (O) a NOUN (O) sequential ADJ (O) manner NOUN (O) as SCONJ (O) shown VERB (O) in ADP (O)     Fig PROPN . (O) (a NOUN) . (O) This DET (O) [neural NOUN (B) network NOUN (I)] out ADP (O) puts VERB (O) [cepstral ADJ (B) coefficients NOUN (I)] c NOUN (O) given VERB (O) [linguistic NOUN (B) feature NOUN (I) vector NOUN (I) sequence NOUN (I)] l NOUN (O) = l(0 PROPN) , ... PUNCT , (O) l(I−1 PROPN) , (O) which DET (O) in ADP (O) turn VERB (O) gives VERB (O) a NOUN (O) [probability NOUN (B) density NOUN (I) function NOUN (I)] of ADP (O) [speech NOUN (B) signals NOUN (I)] x X , (O) which DET (O) corresponds VERB (O) to ADP (O) an DET (O) utterance NOUN (O) or CCONJ (O) whole NOUN (O) [speech NOUN (B) database NOUN (I)] , conditioned VERB (O) on ADP (O) l NOUN , (O) p NOUN (O) (x NOUN (O) | l NOUN , (O) M PROPN) (O) as SCONJ (O) 

 where ADV (O) M PROPN (O) denotes VERB (O) a NOUN (O) set NOUN (O) of ADP (O) network NOUN (O) weights NOUN , (O) c(l PROPN) (O) is AUX (O) given VERB (O) by ADP (O) activations VERB (O) at ADP (O) the DET (O) [output NOUN (B) layer NOUN (I)] of ADP (O) the DET (O) network NOUN (O) given VERB (O) input NOUN (O) [linguistic NOUN (B) features VERB (I)] , and CCONJ (O) the DET (O) RHS PROPN (O) is AUX (O) given VERB (O) by ADP (O) Eq PROPN . (O) (14 NUM) . (O) By ADP (O) back NOUN - propagating NOUN (O) the DET (O) derivative ADJ (O) of ADP (O) the DET (O) [log NOUN (B) likelihood NOUN (I) function NOUN (I)] through ADP (O) the DET (O) network NOUN , (O) the DET (O) network NOUN (O) weights NOUN (O) can VERB (O) be AUX (O) updated VERB (O) to ADP (O) maximize NOUN (O) the DET (O) [log NOUN (B) likelihood NOUN (I)] .                                                                 
 It PRON (O) should VERB (O) be AUX (O) noted VERB (O) that SCONJ (O) although SCONJ (O) the DET (O) optimization NOUN (O) problem NOUN (O) at ADP (O) each DET (O) segment NOUN (O) becomes VERB (O) an DET (O) underdetermined ADJ (O) problem NOUN (O) when ADV (O) L NOUN (O) < M PROPN , (O) it PRON (O) is AUX (O) expected VERB (O) that SCONJ (O) the DET (O) finite NOUN (O) number NOUN (O) of ADP (O) weights NOUN (O) in ADP (O) the DET (O) [neural NOUN (B) network NOUN (I)] an DET (O) work NOUN (O) as SCONJ (O) a NOUN (O) regularizer NOUN (O) for ADP (O) the DET (O) optimization NOUN (O) problem NOUN . (O) 
Thus ADV , (O) L NOUN (O) = 1 NUM (O) (t NOUN (O) = i PRON , (O) ct PROPN (O) = c(i NOUN) , (O) lt NOUN (O) = l(i NOUN)) (O) is AUX (O) assumed VERB (O) in ADP (O) the DET (O) figure NOUN (O) and CCONJ (O) the DET (O) following VERB (O) discussion NOUN . (O) As SCONJ (O) a NOUN (O) result VERB , (O) the DET (O) training NOUN (O) algorithm PROPN (O) can VERB (O) run NOUN (O) sequentially ADV (O) in ADP (O) a NOUN (O) sample NOUN - by ADP - sample NOUN (O) manner NOUN , (O) rather ADV (O) than SCONJ (O) conventional ADJ (O) frame NOUN - by ADP - frame NOUN (O) manner NOUN . (O) 
The DET (O) structure NOUN (O) of ADP (O) the DET (O) training NOUN (O) algorithm PROPN (O) is AUX (O) quite ADV (O) similar ADJ (O) to ADP (O) that SCONJ (O) in ADP (O) the DET (O) [adaptive ADJ (B) cepstral ADJ (I) analysis NOUN (I) algorithm PROPN (I)] . The DET (O) difference NOUN (O) is AUX (O) that SCONJ (O) the DET (O) [adaptive ADJ (B) cepstral ADJ (I) analysis NOUN (I) algorithm PROPN (I)] updates VERB (O) [cepstral ADJ (B) coefficients NOUN (I)] of ADP (O) the DET (O) [neural NOUN (B) network NOUN (I)] which DET (O) predicts VERB (O) the DET (O) [cepstral ADJ (B) coefficients NOUN (I)] . 
                                                                                                                           
 It PRON (O) is AUX (O) also ADV (O) noted VERB (O) that SCONJ (O) the DET (O) [log NOUN (B) likelihood NOUN (I)] can VERB (O) be AUX (O) calculated VERB (O) by ADP (O) 

                                                                                                        
 where ADV (O) e NOUN (O) = e(0 NUM) , ... PUNCT , (O) e(T PUNCT (O) − PROPN (O) 1)⊤ NUM (O) and CCONJ (O) the DET (O) third NOUN (O) term NOUN (O) of ADP (O) Eq.corresponds VERB (O) to ADP (O) the DET (O) sum NOUN (O) of ADP (O) squares NOUN (O) of ADP (O) the DET (O) inverse NOUN (O) system NOUN (O) output NOUN . (O)                                                                                                      

 Fig PROPN . (O) [Log PROPN (B) likelihoods NOUN (I)] of ADP (O) trained VERB (O) [LSTM PROPN - RNNs PROPN (B)] over ADP (O) both DET (O) training NOUN (O) and CCONJ (O) development NOUN (O) subsets NOUN (O) (60,000 NUM (O) samples NOUN) . (O) 
Note NOUN (O) that DET (O) the DET (O) initialization NOUN (O) stage NOUN (O) using VERB (O) the DET (O) [MMSE NOUN (B) criterion NOUN (I)] was AUX (O) not PART (O) included VERB . (O) 

 Synthesis NOUN (O) structure NOUN (O) 
The DET (O) synthesis NOUN (O) structure NOUN (O) is AUX (O) given VERB (O) by ADP (O)     Fig PROPN . (O) (b NOUN) . (O) 
The DET (O) [synthesized VERB (B) speech NOUN (I)] (x(t PROPN) (O) in ADP (O)     Fig PROPN . (O) (b NOUN)) (O) can VERB (O) be AUX (O) generated VERB (O) by ADP (O) sampling NOUN (O) x NOUN (O) from ADP (O) the DET (O) [probability NOUN (B) density NOUN (I) function NOUN (I)] p(x ADV (O) | l NOUN , (O) M PROPN) . (O) It PRON (O) can VERB (O) be AUX (O) done VERB (O) by ADP (O) exciting ADJ (O) the DET (O) LMA PROPN (O) filter NOUN (O) using VERB (O) a NOUN (O) zero NUM - mean NOUN (O) white NOUN (O) [Gaussian PROPN (B)] noise NOUN (O) with ADP (O) unity NOUN (O) variance NOUN (O) as SCONJ (O) source NOUN (O) excitation NOUN (O) signal NOUN (O) (e(t X) (O) in ADP (O)     Fig PROPN . (O) (b NOUN)) . (O) 
It PRON (O) is AUX (O) possible ADJ (O) to ADP (O) substitute NOUN (O) e(t X) (O) with ADP (O) the DET (O) excitation NOUN (O) signal NOUN (O) used VERB (O) in ADP (O) standard NOUN (O) 
directly ADV (O) whereas SCONJ (O) the DET (O) training NOUN (O) algorithm PROPN (O) in ADP (O)     Fig PROPN . (O) (a X) (O) updates VERB (O) weights NOUN (O) [statistical ADJ (B) parametric NOUN (I) speech NOUN (I) synthesis NOUN (I) systems NOUN (I)] , such ADJ (O) as SCONJ (O) outputs VERB (O) from ADP (O) pulse NOUN (O) / noise NOUN (O) or CCONJ (O) mixed ADJ (O) excitation NOUN (O) generators NOUN . (O) 

 The DET (O) definition NOUN (O) of ADP (O) the DET (O) [linguistic NOUN (B) feature NOUN (I) vector NOUN (I)] used VERB (O) in ADP (O) this DET (O) paper NOUN (O) can VERB (O) be AUX (O) found VERB (O) in ADP . (O)   

 EXPERIMENTS PROPN (O) 
Experimental PROPN (O) conditions NOUN (O) 
[Speech NOUN (B) data NOUN (I)] in ADP (O) US PROPN (O) English PROPN (O) from ADP (O) a NOUN (O) female NOUN (O) [professional ADJ (B) speaker NOUN (I)] was AUX (O) used VERB (O) for ADP (O) the DET (O) experiments NOUN . (O) 
The DET (O) training NOUN (O) and CCONJ (O) [development NOUN (B) data NOUN (I)] sets VERB (O) consisted VERB (O) of ADP (O) 34,632 NUM (O) and CCONJ (O) 100 NUM (O) utterances VERB , (O) respectively ADV . (O) A NOUN (O) speaker NOUN - dependent ADJ (O) unidirectional ADJ (O) [LSTM PROPN - RNN PROPN (B)] was AUX (O) trained VERB . (O) 

 Fig PROPN . (O) Inverse PROPN (O) system NOUN (O) output NOUN (O) for ADP (O) a NOUN (O) sentence NOUN (O) “ PUNCT (O) Two NUM (O) elect PROPN (O) only ADV (O) two NUM (O) ” PUNCT (O) by ADP (O) cepstra PROPN (O) predicted VERB (O) by ADP (O) [LSTM PROPN - RNNs PROPN (B)] before ADP (O) (a X) (O) and CCONJ (O) after ADP (O) (b NOUN) (O) training NOUN . (O) 

 Fig PROPN . (O) Synthesized VERB (O) [speech NOUN (B)] spectra PROPN (O) for ADP (O) a NOUN (O) sentence NOUN (O) “ PUNCT (O) Two NUM (O) elect PROPN (O) only ADV (O) two NUM (O) ” PUNCT . (O) Note NOUN (O) that DET (O) spectra PROPN (O) were AUX (O) sampled VERB (O) at ADP (O) every DET (O) 5 NUM (O) ms PROPN . (O) 

 From ADP (O) the DET (O) [speech NOUN (B) data NOUN (I)] , its DET (O) associated PROPN (O) transcriptions NOUN , (O) and CCONJ (O) automatically ADV (O) derived VERB (O) [phonetic NOUN (B) alignments NOUN (I)] , sample NOUN - level NOUN (O) [linguistic NOUN (B) features VERB (I)] included VERB (O) 535 NUM (O) linguistic ADJ (O) contexts PROPN , (O) 50 NUM (O) [numerical ADJ (B) features VERB (I)] for ADP (O) coarse ADV - coded VERB (O) position NOUN (O) of ADP (O) the DET (O) current ADJ (O) sample NOUN (O) in ADP (O) the DET (O) current ADJ (O) [phoneme NOUN (B)] , and CCONJ (O) one NUM (O) [numerical ADJ (B) feature NOUN (I)] for ADP (O) duration NOUN (O) of ADP (O) the DET (O) current ADJ (O) [phoneme NOUN (B)] .                                    
 The DET (O) [speech NOUN (B) data NOUN (I)] was AUX (O) downsampled VERB (O) from ADP (O) 48 NUM (O) kHz PROPN (O) to ADP (O) 16 NUM (O) kHz PROPN , (O) 24 NUM (O) [cepstral ADJ (B) coefficients NOUN (I)] were AUX (O) extracted VERB (O) at ADP (O) each DET (O) sample NOUN (O) using VERB (O) the DET (O) [adaptive ADJ (B) cepstral ADJ (I) analysis NOUN (I)] . 
The DET (O) [output NOUN (B) features VERB (I)] of ADP (O) the DET (O) [LSTM PROPN - RNN PROPN (B)] consisted VERB (O) of ADP (O) 24 NUM (O) [cepstral ADJ (B) coefficients NOUN (I)] . 
Both DET (O) the DET (O) input NOUN (O) and CCONJ (O) [output NOUN (B) features VERB (I)] were AUX (O) normalized ADJ (O) ; the DET (O) [input NOUN (B) features VERB (I)] were AUX (O) normalized ADJ (O) to ADP (O) have AUX (O) zero NUM - mean NOUN (O) unit NOUN - variance NOUN , (O) whereas SCONJ (O) the DET (O) [output NOUN (B) features VERB (I)] were AUX (O) normalized ADJ (O) to ADP (O) be AUX (O) within ADP (O) 0.01–0.99 PUNCT (O) based VERB (O) on ADP (O) their DET (O) minimum NOUN (O) and CCONJ (O) maximum NOUN (O) values NOUN (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] . 
The DET (O) architecture NOUN (O) of ADP (O) the DET (O) [LSTM PROPN - RNN PROPN (B)] was AUX (O) 1 NUM (O) forward ADV - directed VERB (O) hidden VERB (O) [LSTM PROPN (B) layer NOUN (I)] with ADP (O) 256 NUM (O) memory NOUN (O) blocks PROPN . (O) 
To NOUN (O) reduce VERB (O) the DET (O) training NOUN (O) time NOUN (O) and CCONJ (O) impact NOUN (O) of ADP (O) having VERB (O) many ADJ (O) silences NOUN , (O) 80 NUM (O) % of ADP (O) silence NOUN (O) regions NOUN (O) were AUX (O) removed VERB . (O) 
After ADP (O) setting NOUN (O) the DET (O) network NOUN (O) weights NOUN (O) randomly ADV , (O) they PRON (O) were AUX (O) first ADJ (O) updated VERB (O) to ADP (O) minimize NOUN (O) the DET (O) mean VERB (O) squared PROPN (O) error NOUN (O) between ADP (O) the DET (O) extracted VERB (O) and CCONJ (O) predicted VERB (O) [cepstral ADJ (B) coefficients NOUN (I)] . 
Then ADV (O) they PRON (O) were AUX (O) used VERB (O) as SCONJ (O) initial PROPN (O) values NOUN (O) to ADP (O) start VERB (O) the DET (O) proposed VERB (O) training NOUN (O) algorithm PROPN (O) ; the DET (O) weights NOUN (O) were AUX (O) further ADJ (O) optimized VERB (O) to ADP (O) maximize NOUN (O) the DET (O) [waveform NOUN - level NOUN (B) log NOUN (I) likelihood NOUN (I)] . 
A NOUN (O) distributed VERB (O) [CPU NOUN (B) implementation NOUN (I)] of ADP (O) mini NOUN - batch ADJ (O) ASGD PROPN (O) based VERB (O) back NOUN (O) propagation NOUN (O) through ADP (O) time NOUN (O) (BPTT PROPN) (O) algorithm PROPN (O) was AUX (O) used VERB . (O)                                                          
                                                                                          
 Experimental PROPN (O) results VERB (O)                                                                                         
 First ADV (O) the DET (O) proposed VERB (O) training NOUN (O) algorithm PROPN (O) was AUX (O) verified VERB (O) with ADP (O) the DET (O) [log NOUN (B) likelihoods NOUN (I)] . 
Figure NOUN (O) plots NOUN (O) the DET (O) [log NOUN (B) likelihoods NOUN (I)] of ADP (O) the DET (O) trained VERB (O) [LSTM PROPN - RNN PROPN (B)] over ADP (O) training NOUN (O) and CCONJ (O) development NOUN (O) subsets NOUN (O) against ADP (O) the DET (O) number NOUN (O) of ADP (O) training NOUN (O) samples NOUN . (O) 
Both DET (O) of ADP (O) them PRON (O) consisted VERB (O) of ADP (O) 60,000 NUM (O) samples NOUN . (O) 
It PRON (O) can VERB (O) be AUX (O) seen VERB (O) from ADP (O) the DET (O) figure NOUN (O) that SCONJ (O) the DET (O) log NOUN (O) likelihoods NOUN (O) w.r.t PROPN . (O) the DET (O) training NOUN (O) and CCONJ (O) development NOUN (O) subsets NOUN (O) improved VERB (O) and CCONJ (O) converged ADJ (O) after ADP (O) training NOUN . (O) The DET (O) log NOUN (O) likelihoods NOUN (O) w.r.t PROPN . (O) the DET (O) development NOUN (O) subset NOUN (O) became VERB (O) better ADJ (O) than SCONJ (O) the DET (O) training NOUN (O) one NUM . (O) 
It PRON (O) may VERB (O) be AUX (O) due ADJ (O) to ADP (O) the DET (O) use NOUN (O) of ADP (O) small ADJ (O) subsets NOUN (O) from ADP (O) both DET (O) training NOUN (O) and CCONJ (O) development NOUN (O) sets NOUN . (O) As SCONJ (O) discussed VERB (O) in ADP , (O) maximizing NOUN (O) the DET (O) likelihood NOUN (O) corresponds VERB (O) to ADP (O) minimizing NOUN (O) prediction NOUN (O) error NOUN . (O) 
Thus ADV , (O) it PRON (O) is AUX (O) expected VERB (O) that SCONJ (O) the DET (O) proposed VERB (O) training NOUN (O) algorithm PROPN (O) reduces VERB (O) the DET (O) energy NOUN (O) of ADP (O) the DET (O) [waveform NOUN - level NOUN (B) prediction NOUN (I) errors NOUN (I)] . 
When ADV (O) the DET (O) [neural NOUN (B) network NOUN (I)] predicts VERB (O) the DET (O) true ADJ (O) [cepstral ADJ (B) coefficients NOUN (I)] , the DET (O) inverse NOUN (O) filter NOUN (O) output NOUN (O) e NOUN (O) becomes VERB (O) a NOUN (O) zero NUM - mean NOUN (O) white NOUN (O) [Gaussian PROPN (B)] noise NOUN (O) with ADP (O) unity NOUN (O) variance NOUN . (O)     Figure NOUN (O) shows VERB (O) inverse NOUN (O) system NOUN (O) outputs NOUN (O) e NOUN (O) from ADP (O) the DET (O) [LSTM PROPN - RNNs PROPN (B)] before ADP (O) and CCONJ (O) after ADP (O) updating VERB (O) the DET (O) weights NOUN (O) using VERB (O) the DET (O) proposed VERB (O) training NOUN (O) algorithm PROPN . (O) 
Note NOUN (O) that DET (O) the DET (O) [LSTM PROPN - RNN PROPN (B)] before ADP (O) updating VERB (O) was AUX (O) trained VERB (O) by ADP (O) the DET (O) [MMSE NOUN (B) criterion NOUN (I)] using VERB (O) the DET (O) sample NOUN - level NOUN (O) cepstra NOUN (O) as SCONJ (O) targets NOUN . (O) It PRON (O) can VERB (O) be AUX (O) seen VERB (O) from ADP (O) the DET (O) figure NOUN (O) that SCONJ (O) the DET (O) energy NOUN (O) of ADP (O) the DET (O) inverse NOUN (O) filter NOUN (O) outputs NOUN (O) are AUX (O) reduced VERB (O) towards ADP (O) unity NOUN (O) variance NOUN . (O) 
Figure NOUN (O) shows VERB (O) the DET (O) predicted VERB (O) spectra PROPN (O) for ADP (O) a NOUN (O) sentence NOUN (O) not PART (O) included VERB (O) in ADP (O) the DET (O) [training NOUN (B) data NOUN (I)] . It PRON (O) can VERB (O) be AUX (O) seen VERB (O) from ADP (O) the DET (O) figure NOUN (O) that SCONJ (O) smoothly ADV (O) varying NOUN (O) [speech NOUN (B)] spectra PROPN (O) were AUX (O) generated VERB . (O) 
It PRON (O) indicates VERB (O) that SCONJ (O) the DET (O) [neural NOUN (B) network NOUN (I)] structure NOUN (O) could VERB (O) work NOUN (O) as SCONJ (O) a NOUN (O) regularizer NOUN (O) and CCONJ (O) the DET (O) proposed VERB (O) framework NOUN (O) could VERB (O) be AUX (O) used VERB (O) for ADP (O) [text NOUN - to ADP - speech NOUN (B) applications NOUN (I)] . 

 CONCLUSIONS NOUN (O) 
A PROPN (O) new ADJ (O) [neural NOUN (B) network NOUN (I)] structure NOUN (O) with ADP (O) a NOUN (O) specially ADV (O) designed VERB (O) [output NOUN (B) layer NOUN (I)] for ADP (O) directly ADV (O) modeling NOUN (O) [speech NOUN (B)] at ADP (O) the DET (O) [waveform PROPN (B)] level NOUN (O) was AUX (O) proposed VERB (O) and CCONJ (O) its DET (O) training NOUN (O) algorithm PROPN (O) which DET (O) can VERB (O) run NOUN (O) sequentially ADV (O) in ADP (O) a NOUN (O) sample NOUN - by ADP - sample NOUN (O) manner NOUN (O) was AUX (O) derived VERB . (O) 
[Acoustic PROPN (B) feature NOUN (I)] extraction NOUN (O) can VERB (O) be AUX (O) fully ADV (O) integrated VERB (O) into ADP (O) training NOUN (O) of ADP (O) [neural NOUN (B) network NOUN - based VERB (I) acoustic ADJ (I) model NOUN (I)] and CCONJ (O) can VERB (O) remove VERB (O) the DET (O) limitations VERB (O) in ADP (O) the DET (O) conventional ADJ (O) approaches VERB (O) such ADJ (O) as SCONJ (O) two NUM - stage NOUN (O) optimization NOUN (O) and CCONJ (O) the DET (O) use NOUN (O) of ADP (O) overlapping VERB (O) frames NOUN . (O) 
Future PROPN (O) work NOUN (O) includes VERB (O) introducing VERB (O) a NOUN (O) model NOUN (O) structure NOUN (O) for ADP (O) generating NOUN (O) periodic ADJ (O) components NOUN (O) and CCONJ (O) evaluating VERB (O) the DET (O) performance NOUN (O) in ADP (O) practical ADJ (O) onditions NOUN (O) as SCONJ (O) a NOUN (O) [text NOUN - to ADP - speech NOUN (B) synthesis NOUN (I) application NOUN (I)] . 
