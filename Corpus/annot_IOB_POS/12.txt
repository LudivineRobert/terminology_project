[FastSpeech PROPN (B)] : Fast VERB , (O) Robust PROPN (O) and CCONJ (O) Controllable ADJ (O) [Text NOUN (B) to ADP (I) Speech NOUN (I)] 

 Abstract PROPN (O) 

 [Neural PROPN (B) network NOUN (I)] based VERB (O) [end NOUN - to ADP - end NOUN (B) text NOUN (I) to ADP (I) speech NOUN (I)] ([TTS PROPN (B)]) has AUX (O) significantly ADV (O) improved VERB (O) the DET (O) quality NOUN (O) of ADP (O) [synthesized VERB (B) speech NOUN (I)] . 
Prominent PROPN (O) methods NOUN (O) (e.g. ADV , (O) [Tacotron PROPN (B) 2 NUM (I)]) usually ADV (O) first ADJ (O) generate NOUN (O) [mel PROPN - spectrogram PROPN (B)] from ADP (O) text NOUN , (O) and CCONJ (O) then ADV (O) [synthesize VERB (B) speech NOUN (I)] from ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B) using VERB (I) vocoder NOUN (I)] such ADJ (O) as SCONJ (O) [WaveNet PROPN (B)] . 
Compared VERB (O) with ADP (O) traditional ADJ (O) concatenative ADJ (O) and CCONJ (O) [statistical ADJ (B) parametric NOUN (I) approaches VERB (I)] , [neural NOUN (B) network NOUN (I)] based VERB (O) [end NOUN - to ADP - end NOUN (B) models NOUN (I)] suffer VERB (O) from ADP (O) [slow ADJ (B) inference NOUN (I) speed NOUN (I)] , and CCONJ (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] is AUX (O) usually ADV (O) not PART (O) robust ADJ (O) (i.e. X , (O) some DET (O) words NOUN (O) are AUX (O) skipped VERB (O) or CCONJ (O) repeated VERB) (O) and CCONJ (O) lack NOUN (O) of ADP (O) controllability NOUN (O) ([voice NOUN (B) speed NOUN (I)] or CCONJ (O) [prosody NOUN (B) control NOUN (I)]) . 
In ADP (O) this DET (O) work NOUN , (O) we PRON (O) propose NOUN (O) a NOUN (O) novel NOUN (O) [feed NOUN - forward NOUN (B) network NOUN (I)] based VERB (O) on ADP (O) [Transformer NOUN (B)] to PART (O) generate NOUN (O) [mel PROPN - spectrogram PROPN (B)] in ADP (O) parallel NOUN (O) for ADP (O) [TTS PROPN (B)] . 
Specifically ADV , (O) we PRON (O) extract NOUN (O) [attention NOUN (B) alignments NOUN (I)] from ADP (O) an DET (O) [encoder NOUN - decoder NOUN (B) based VERB (I) teacher NOUN (I)] model NOUN (O) for ADP (O) [phoneme NOUN (B) duration NOUN (I) prediction NOUN (I)] , which DET (O) is AUX (O) used VERB (O) by ADP (O) a NOUN (O) length NOUN (O) regulator NOUN (O) to ADP (O) expand VERB (O) the DET (O) source NOUN (O) [phoneme NOUN (B) sequence NOUN (I)] to PART (O) match NOUN (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) [target NOUN (B) mel NOUN - spectrogram PROPN (I) sequence NOUN (I)] for ADP (O) parallel NOUN (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] . 
Experiments NOUN (O) on ADP (O) the DET (O) [LJSpeech NOUN (B) dataset NOUN (I)] show VERB (O) that SCONJ (O) our DET (O) parallel NOUN (O) model NOUN (O) matches NOUN (O) [autoregressive ADJ (B) models NOUN (I)] in ADP (O) terms NOUN (O) of ADP (O) [speech NOUN (B) quality NOUN (I)] , nearly ADV (O) eliminates NOUN (O) the DET (O) problem NOUN (O) of ADP (O) word NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB (O) in ADP (O) particularly ADV (O) hard ADJ (O) cases NOUN , (O) and CCONJ (O) can VERB (O) adjust NOUN (O) voice NOUN (O) speed NOUN (O) smoothly ADV . (O) 
Most ADJ (O) importantly ADV , (O) compared VERB (O) with ADP (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I)] , our DET (O) model NOUN (O) speeds VERB (O) up NOUN (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] by ADP (O) 270x NUM (O) and CCONJ (O) the DET (O) [end NOUN - to ADP - end NOUN (B) speech NOUN (I) synthesis NOUN (I)] by ADP (O) 38x X . (O) 
Therefore ADV , (O) we PRON (O) call NOUN (O) our DET (O) model NOUN (O) [FastSpeech PROPN (B)] . 

 [Synthesized VERB (B) speech NOUN (I) samples NOUN (I)] can VERB (O) be AUX (O) found VERB (O) in ADP (O) https://speechresearch.github.io/fastspeech/. PROPN (O) 

 Introduction NOUN (O) 

 [Text NOUN (B) to ADP (I) speech NOUN (I)] ([TTS PROPN (B)]) has AUX (O) attracted VERB (O) a NOUN (O) lot NOUN (O) of ADP (O) attention NOUN (O) in ADP (O) recent ADJ (O) years NOUN (O) due ADJ (O) to ADP (O) the DET (O) advance NOUN (O) in ADP (O) [deep ADJ (B) learning NOUN (I)] . [Deep ADJ (B) neural NOUN (I) network NOUN (I)] based VERB (O) systems NOUN (O) have AUX (O) become VERB (O) more ADJ (O) and CCONJ (O) more ADJ (O) popular ADJ (O) for ADP (O) [TTS PROPN (B)] , such ADJ (O) as SCONJ (O) [Tacotron PROPN (B)] , [Tacotron PROPN (B) 2 NUM (I)] , [Deep ADJ (B) Voice PROPN (I)] 3 NUM , (O) and CCONJ (O) the DET (O) fully ADV (O) [end NOUN - to ADP - end NOUN (B) ClariNet PROPN (I)] . 
Those DET (O) models NOUN (O) usually ADV (O) first ADJ (O) generate NOUN (O) [mel PROPN - spectrogram PROPN (B) autoregressively ADV (I)] from ADP (O) text NOUN (O) input NOUN (O) and CCONJ (O) then ADV (O) [synthesize VERB (B) speech NOUN (I)] from ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B) using VERB (I) vocoder NOUN (I)] such ADJ (O) as SCONJ (O) [Griffin PROPN - Lim PROPN (B)] , [WaveNet PROPN (B)] , Parallel PROPN (O) [WaveNet PROPN (B)] , or CCONJ (O) [WaveGlow PROPN (B)] . 
[Neural PROPN (B) network NOUN (I)] based VERB (O) [TTS PROPN (B)] has AUX (O) outperformed VERB (O) conventional ADJ (O) concatenative ADJ (O) and CCONJ (O) [statistical ADJ (B) parametric NOUN (I) approaches VERB (I)] in ADP (O) terms NOUN (O) of ADP (O) [speech NOUN (B) quality NOUN (I)] . 
In ADP (O) current ADJ (O) [neural NOUN (B) network NOUN (I)] based VERB (O) [TTS PROPN (B)] systems NOUN , (O) [mel PROPN - spectrogram PROPN (B)] is AUX (O) generated VERB (O) [autoregressively ADV (B)] . 
Due PROPN (O) to ADP (O) the DET (O) long ADJ (O) sequence NOUN (O) of ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B)] and CCONJ (O) the DET (O) autoregressive ADJ (O) nature NOUN , (O) those DET (O) systems NOUN (O) face NOUN (O) several ADJ (O) challenges VERB (O) : 
• X (O) [Slow ADJ (B) inference NOUN (I) speed NOUN (I)] for ADP (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] . 
Although SCONJ (O) [CNN PROPN (B)] and CCONJ (O) [Transformer NOUN (B)] based VERB (O) [TTS PROPN (B)] can VERB (O) speed NOUN (O) up NOUN (O) the DET (O) training NOUN (O) over ADP (O) [RNN PROPN - based VERB (B) models NOUN (I)] , all DET (O) models NOUN (O) generate NOUN (O) a NOUN (O) [mel PROPN - spectrogram PROPN (B)] conditioned VERB (O) on ADP (O) the DET (O) previously ADV (O) generated VERB (O) [mel NOUN - spectrograms NOUN (B)] and CCONJ (O) suffer VERB (O) from ADP (O) [slow ADJ (B) inference NOUN (I) speed NOUN (I)] , given VERB (O) the DET (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] is AUX (O) usually ADV (O) with ADP (O) a NOUN (O) length NOUN (O) of ADP (O) hundreds NOUN (O) or CCONJ (O) thousands NOUN . (O) 
• X (O) [Synthesized VERB (B) speech NOUN (I)] is AUX (O) usually ADV (O) not PART (O) robust ADJ . (O) 
Due PROPN (O) to ADP (O) error NOUN (O) propagation NOUN (O) and CCONJ (O) the DET (O) wrong NOUN (O) [attention NOUN (B) alignments NOUN (I)] between ADP (O) text NOUN (O) and CCONJ (O) [speech NOUN (B)] in ADP (O) the DET (O) autoregressive ADJ (O) generation NOUN , (O) the DET (O) generated VERB (O) [mel PROPN - spectrogram PROPN (B)] is AUX (O) usually ADV (O) deficient ADJ (O) with ADP (O) the DET (O) problem NOUN (O) of ADP (O) words NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB . (O) 
• X (O) [Synthesized VERB (B) speech NOUN (I)] is AUX (O) lack NOUN (O) of ADP (O) controllability NOUN . (O) 
Previous ADJ (O) [autoregressive ADJ (B) models NOUN (I)] generate VERB (O) [mel NOUN - spectrograms NOUN (B)] one NUM (O) by ADP (O) one NUM (O) automatically ADV , (O) without ADP (O) explicitly ADV (O) leveraging NOUN (O) the DET (O) alignments VERB (O) between ADP (O) text NOUN (O) and CCONJ (O) [speech NOUN (B)] . 
As SCONJ (O) a NOUN (O) consequence NOUN , (O) it PRON (O) is AUX (O) usually ADV (O) hard ADJ (O) to ADP (O) directly ADV (O) control NOUN (O) the DET (O) [voice NOUN (B) speed NOUN (I)] and CCONJ (O) [prosody NOUN (B)] in ADP (O) the DET (O) autoregressive ADJ (O) generation NOUN . (O) 

 Considering VERB (O) the DET (O) monotonous ADJ (O) alignment NOUN (O) between ADP (O) text NOUN (O) and CCONJ (O) [speech NOUN (B)] , to ADP (O) speed NOUN (O) up NOUN (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] , in ADP (O) this DET (O) work NOUN , (O) we PRON (O) propose NOUN (O) a NOUN (O) novel NOUN (O) model NOUN , (O) [FastSpeech PROPN (B)] , which DET (O) takes VERB (O) a NOUN (O) text NOUN (O) [(phoneme PROPN) (B) sequence NOUN (I)] as SCONJ (O) input NOUN (O) and CCONJ (O) generates VERB (O) [mel NOUN - spectrograms NOUN (B)] non-[autoregressively ADV (B)] . 
It PRON (O) adopts VERB (O) a NOUN (O) [feed NOUN - forward NOUN (B) network NOUN (I)] based VERB (O) on ADP (O) the DET (O) [self NOUN - attention NOUN (B)] in ADP (O) [Transformer NOUN (B)] and CCONJ (O) [1D PROPN (B) convolution NOUN (I)] . 
Since SCONJ (O) a NOUN (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] is AUX (O) much ADJ (O) longer ADJ (O) than SCONJ (O) its DET (O) corresponding VERB (O) [phoneme NOUN (B) sequence NOUN (I)] , in ADP (O) order NOUN (O) to ADP (O) solve VERB (O) the DET (O) problem NOUN (O) of ADP (O) length NOUN (O) mismatch NOUN (O) between ADP (O) the DET (O) two NUM (O) sequences NOUN , (O) [FastSpeech PROPN (B)] adopts VERB (O) a NOUN (O) length NOUN (O) regulator NOUN (O) that SCONJ (O) up ADP - samples NOUN (O) the DET (O) [phoneme NOUN (B) sequence NOUN (I)] according VERB (O) to ADP (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] (i.e. X , (O) the DET (O) number NOUN (O) of ADP (O) [mel NOUN - spectrograms NOUN (B)] that DET (O) each DET (O) [phoneme NOUN (B)] corresponds VERB (O) to PART) (O) to ADP (O) match NOUN (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] . 
The DET (O) regulator NOUN (O) is AUX (O) built VERB (O) on ADP (O) a NOUN (O) [phoneme NOUN (B) duration NOUN (I) predictor NOUN (I)] , which DET (O) predicts VERB (O) the DET (O) duration NOUN (O) of ADP (O) each DET (O) [phoneme NOUN (B)] . 

 Our DET (O) proposed VERB (O) [FastSpeech PROPN (B)] can VERB (O) address NOUN (O) the DET (O) above ADV - mentioned VERB (O) three NUM (O) challenges VERB (O) as SCONJ (O) follows VERB (O) : 
• X (O) Through ADP (O) parallel NOUN (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] , [FastSpeech PROPN (B)] greatly ADV (O) speeds VERB (O) up NOUN (O) the DET (O) synthesis NOUN (O) process NOUN . (O) 
• X (O) [Phoneme PROPN (B) duration NOUN (I) predictor NOUN (I)] ensures VERB (O) hard ADJ (O) alignments VERB (O) between ADP (O) a NOUN (O) [phoneme NOUN (B)] and CCONJ (O) its DET (O) [mel NOUN - spectrograms NOUN (B)] , which DET (O) is AUX (O) very ADV (O) different ADJ (O) from ADP (O) soft ADJ (O) and CCONJ (O) automatic PROPN (O) [attention NOUN (B) alignments NOUN (I)] in ADP (O) the DET (O) [autoregressive ADJ (B) models NOUN (I)] . 
Thus ADV , (O) [FastSpeech PROPN (B)] avoids VERB (O) the DET (O) issues NOUN (O) of ADP (O) error NOUN (O) propagation NOUN (O) and CCONJ (O) wrong NOUN (O) [attention NOUN (B) alignments NOUN (I)] , consequently ADV (O) reducing VERB (O) the DET (O) ratio NOUN (O) of ADP (O) the DET (O) skipped VERB (O) words NOUN (O) and CCONJ (O) repeated VERB (O) words NOUN . (O) 
• X (O) The DET (O) length NOUN (O) regulator NOUN (O) can VERB (O) easily ADV (O) adjust NOUN (O) [voice NOUN (B) speed NOUN (I)] by ADP (O) lengthening NOUN (O) or CCONJ (O) shortening VERB (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] to PART (O) determine NOUN (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) generated VERB (O) [mel NOUN - spectrograms NOUN (B)] , and CCONJ (O) can VERB (O) also ADV (O) control NOUN (O) part NOUN (O) of ADP (O) the DET (O) [prosody NOUN (B)] by ADP (O) adding VERB (O) breaks VERB (O) between ADP (O) adjacent ADJ (O) [phonemes NOUN (B)] . 

 We PRON (O) conduct NOUN (O) experiments VERB (O) on ADP (O) the DET (O) [LJSpeech NOUN (B) dataset NOUN (I)] to PART (O) test NOUN (O) [FastSpeech PROPN (B)] . 
The DET (O) results VERB (O) show NOUN (O) that SCONJ (O) in ADP (O) terms NOUN (O) of ADP (O) [speech NOUN (B) quality NOUN (I)] , [FastSpeech PROPN (B)] nearly ADV (O) matches NOUN (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) model NOUN (I)] . 
Furthermore ADV , (O) [FastSpeech PROPN (B)] achieves VERB (O) 270x NUM (O) speedup NOUN (O) on ADP (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] and CCONJ (O) 38x NOUN (O) speedup NOUN (O) on ADP (O) final ADJ (O) [speech NOUN (B) synthesis NOUN (I)] compared VERB (O) with ADP (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] , almost ADV (O) eliminates NOUN (O) the DET (O) problem NOUN (O) of ADP (O) word NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB , (O) and CCONJ (O) can VERB (O) adjust NOUN (O) voice NOUN (O) speed NOUN (O) smoothly ADV . (O) 
We PRON (O) attach NOUN (O) some DET (O) [audio NOUN (B) files NOUN (I)] generated VERB (O) by ADP (O) our DET (O) method NOUN (O) in ADP (O) the DET (O) supplementary ADJ (O) materials NOUN . (O) 

 Although SCONJ (O) [ClariNet PROPN (B)] is AUX (O) fully ADV (O) [end NOUN - to ADP - end NOUN (B)] , it PRON (O) still ADV (O) first ADJ (O) generates VERB (O) [mel PROPN - spectrogram PROPN (B) autoregressively ADV (I)] and CCONJ (O) then ADV (O) [synthesizes NOUN (B) speech NOUN (I)] in ADP (O) one NUM (O) model NOUN . (O) 

 Background NOUN (O) 

 In ADP (O) this DET (O) section NOUN , (O) we PRON (O) briefly NOUN (O) overview NOUN (O) the DET (O) background NOUN (O) of ADP (O) this DET (O) work NOUN , (O) including VERB (O) [text NOUN (B) to ADP (I) speech NOUN (I)] , [sequence NOUN (B) to ADP (I) sequence NOUN (I) learning VERB (I)] , and CCONJ (O) [non ADJ - autoregressive ADJ (B) sequence NOUN (I) generation NOUN (I)] . 

 [Text NOUN (B) to ADP (I) Speech NOUN (I)] — PUNCT (O) [TTS PROPN (B)] , which DET (O) aims VERB (O) to ADP (O) synthesize VERB (O) natural ADJ (O) and CCONJ (O) [intelligible ADJ (B) speech NOUN (I)] given VERB (O) text NOUN , (O) has AUX (O) long ADJ (O) been AUX (O) a NOUN (O) hot ADJ (O) research NOUN (O) topic NOUN (O) in ADP (O) the DET (O) field NOUN (O) of ADP (O) artificial NOUN (O) intelligence NOUN . (O) 
The DET (O) research NOUN (O) on ADP (O) [TTS PROPN (B)] has AUX (O) shifted VERB (O) from ADP (O) early ADV (O) [concatenative ADJ (B) synthesis NOUN (I)] , [statistical ADJ (B) parametric NOUN (I) synthesis NOUN (I)] to PART (O) [neural NOUN (B) network NOUN (I)] based VERB (O) [parametric NOUN (B) synthesis NOUN (I)] and CCONJ (O) [end NOUN - to ADP - end NOUN (B) models NOUN (I)] , and CCONJ (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] by ADP (O) [end NOUN - to ADP - end NOUN (B) models NOUN (I)] is AUX (O) close NOUN (O) to ADP (O) human NOUN (O) parity NOUN . (O) 
[Neural PROPN (B) network NOUN (I)] based VERB (O) [end NOUN - to ADP - end NOUN (B) TTS PROPN (I) models NOUN (I)] usually ADV (O) first ADJ (O) convert NOUN (O) the DET (O) text NOUN (O) to ADP (O) [acoustic ADJ (B) features VERB (I)] (e.g. ADV , (O) [mel PROPN (B)]-spectrograms PROPN) and CCONJ (O) then ADV (O) transform NOUN (O) [mel NOUN - spectrograms NOUN (B)] into ADP (O) [audio NOUN (B) samples NOUN (I)] . 
However ADV , (O) most ADJ (O) [neural NOUN (B) TTS PROPN (I) systems NOUN (I)] generate VERB (O) [mel NOUN - spectrograms NOUN (B) autoregressively ADV (I)] , which DET (O) suffers VERB (O) from ADP (O) [slow ADJ (B) inference NOUN (I) speed NOUN (I)] , and CCONJ (O) [synthesized VERB (B) speech NOUN (I)] usually ADV (O) lacks VERB (O) of ADP (O) robustness NOUN (O) (word NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB) (O) and CCONJ (O) controllability NOUN (O) ([voice NOUN (B) speed NOUN (I)] or CCONJ (O) [prosody NOUN (B) control NOUN (I)]) . 
In ADP (O) this DET (O) work NOUN , (O) we PRON (O) propose NOUN (O) [FastSpeech PROPN (B)] to PART (O) generate NOUN (O) [mel NOUN - spectrograms NOUN (B)] non-[autoregressively ADV (B)] , which DET (O) sufficiently ADV (O) handles VERB (O) the DET (O) above ADV (O) problems NOUN . (O) 

 [Sequence NOUN (B) to ADP (I) Sequence NOUN (I) Learning NOUN (I)] — PUNCT (O) [Sequence NOUN (B) to ADP (I) sequence NOUN (I) learning VERB (I)] is AUX (O) usually ADV (O) built VERB (O) on ADP (O) the DET (O) [encoder NOUN - decoder NOUN (B) framework NOUN (I)] : The DET (O) [encoder NOUN (B)] takes VERB (O) the DET (O) source NOUN (O) sequence NOUN (O) as SCONJ (O) input NOUN (O) and CCONJ (O) generates VERB (O) a NOUN (O) set NOUN (O) of ADP (O) representations NOUN . (O) 
After ADP (O) that SCONJ , (O) the DET (O) [decoder NOUN (B)] estimates NOUN (O) the DET (O) conditional ADJ (O) probability NOUN (O) of ADP (O) each DET (O) target NOUN (O) element NOUN (O) given VERB (O) the DET (O) source NOUN (O) representations NOUN (O) and CCONJ (O) its DET (O) preceding VERB (O) elements NOUN . (O) 
The DET (O) [attention NOUN (B) mechanism NOUN (I)] is AUX (O) further NOUN (O) introduced VERB (O) between ADP (O) the DET (O) [encoder NOUN (B)] and CCONJ (O) [decoder NOUN (B)] in ADP (O) order NOUN (O) to ADP (O) find VERB (O) which DET (O) source NOUN (O) representations NOUN (O) to ADP (O) focus NOUN (O) on ADP (O) when ADV (O) predicting VERB (O) the DET (O) current ADJ (O) element NOUN , (O) and CCONJ (O) is AUX (O) an DET (O) important ADJ (O) component NOUN (O) for ADP (O) [sequence NOUN (B) to ADP (I) sequence NOUN (I) learning VERB (I)] . 
In ADP (O) this DET (O) work NOUN , (O) instead ADV (O) of ADP (O) using VERB (O) the DET (O) conventional ADJ (O) [encoder NOUN - attention NOUN - decoder NOUN (B) framework NOUN (I)] for ADP (O) [sequence NOUN (B) to ADP (I) sequence NOUN (I) learning VERB (I)] , we PRON (O) propose NOUN (O) a NOUN (O) [feed NOUN - forward NOUN (B) network NOUN (I)] to PART (O) generate NOUN (O) a NOUN (O) sequence NOUN (O) in ADP (O) parallel NOUN . (O) 

 [Non ADJ - Autoregressive ADJ (B) Sequence NOUN (I) Generation NOUN (I)] — PUNCT (O) Unlike ADP (O) [autoregressive ADJ (B) sequence NOUN (I) generation NOUN (I)] , [non ADJ - autoregressive ADJ (B) models NOUN (I)] generate VERB (O) sequence NOUN (O) in ADP (O) parallel NOUN , (O) without ADP (O) explicitly ADV (O) depending VERB (O) on ADP (O) the DET (O) previous ADJ (O) elements NOUN , (O) which DET (O) can VERB (O) greatly ADV (O) speed NOUN (O) up NOUN (O) the DET (O) inference NOUN (O) process NOUN . (O) 
[Non ADJ - autoregressive ADJ (B) generation NOUN (I)] has AUX (O) been AUX (O) studied VERB (O) in ADP (O) some DET (O) sequence NOUN (O) generation NOUN (O) tasks NOUN (O) such ADJ (O) as SCONJ (O) [neural NOUN (B) machine NOUN (I) translation NOUN (I)] and CCONJ (O) [audio NOUN (B) synthesis NOUN (I)] . 
Our DET (O) [FastSpeech PROPN (B)] differs VERB (O) from ADP (O) the DET (O) above ADV (O) works VERB (O) in ADP (O) two NUM (O) aspects NOUN (O) : 1 X) (O) Previous ADJ (O) works VERB (O) adopt VERB (O) [non ADJ - autoregressive ADJ (B) generation NOUN (I)] in ADP (O) [neural NOUN (B) machine NOUN (I) translation NOUN (I)] or CCONJ (O) [audio NOUN (B) synthesis NOUN (I)] mainly ADV (O) for ADP (O) inference NOUN (O) speedup PROPN , (O) while SCONJ (O) [FastSpeech PROPN (B)] focuses VERB (O) on ADP (O) both DET (O) inference NOUN (O) speedup NOUN (O) and CCONJ (O) improving VERB (O) the DET (O) robustness NOUN (O) and CCONJ (O) controllability NOUN (O) of ADP (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] in ADP (O) [TTS PROPN (B)] . 
2 NUM) (O) For ADP (O) [TTS PROPN (B)] , although SCONJ (O) Parallel PROPN (O) [WaveNet PROPN (B)] , [ClariNet PROPN (B)] and CCONJ (O) [WaveGlow PROPN (B)] generate NOUN (O) [audio NOUN (B)] in ADP (O) parallel NOUN , (O) they PRON (O) are AUX (O) conditioned VERB (O) on ADP (O) [mel NOUN - spectrograms NOUN (B)] , which DET (O) are AUX (O) still ADV (O) generated VERB (O) [autoregressively ADV (B)] . 
Therefore ADV , (O) they PRON (O) do AUX (O) not PART (O) address NOUN (O) the DET (O) challenges VERB (O) considered VERB (O) in ADP (O) this DET (O) work NOUN . (O) 
There PRON (O) is AUX (O) a NOUN (O) concurrent ADJ (O) work NOUN (O) that SCONJ (O) also ADV (O) generates VERB (O) [mel PROPN - spectrogram PROPN (B)] in ADP (O) parallel NOUN . (O) 
However ADV , (O) it PRON (O) still ADV (O) adopts VERB (O) the DET (O) [encoder NOUN - decoder NOUN (B) framework NOUN (I)] with ADP (O) [attention NOUN (B) mechanism NOUN (I)] , which DET (O) 1 NUM) (O) requires VERB (O) 2∼3x NUM (O) model NOUN (O) parameters NOUN (O) compared VERB (O) with ADP (O) the DET (O) teacher NOUN (O) model NOUN (O) and CCONJ (O) thus ADV (O) achieves VERB (O) slower NOUN (O) inference NOUN (O) speedup NOUN (O) than SCONJ (O) [FastSpeech PROPN (B)] ; 2 X) (O) can VERB (O) not PART (O) totally ADV (O) solve VERB (O) the DET (O) problems NOUN (O) of ADP (O) word NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB (O) while SCONJ (O) [FastSpeech PROPN (B)] nearly ADV (O) eliminates NOUN (O) these DET (O) issues NOUN . (O) 

 [FastSpeech PROPN (B)] 

 In ADP (O) this DET (O) section NOUN , (O) we PRON (O) introduce VERB (O) the DET (O) architecture NOUN (O) design NOUN (O) of ADP (O) [FastSpeech PROPN (B)] . 
To PART (O) generate NOUN (O) a NOUN (O) [target NOUN (B) mel NOUN - spectrogram PROPN (I) sequence NOUN (I)] in ADP (O) parallel NOUN , (O) we PRON (O) design NOUN (O) a NOUN (O) novel NOUN (O) [feed NOUN - forward NOUN (B) structure NOUN (I)] , instead ADV (O) of ADP (O) using VERB (O) the DET (O) [encoder NOUN - attention NOUN - decoder NOUN (B)] based VERB (O) architecture NOUN (O) as SCONJ (O) adopted VERB (O) by ADP (O) most ADJ (O) [sequence NOUN (B) to ADP (I) sequence NOUN (I)] based VERB (O) autoregressive ADJ (O) and CCONJ (O) [non ADJ - autoregressive ADJ (B) generation NOUN (I)] . 
The DET (O) overall NOUN (O) [model NOUN (B) architecture NOUN (I)] of ADP (O) [FastSpeech PROPN (B)] is AUX (O) shown VERB (O) in ADP (O) Figure NOUN . (O) 
We PRON (O) describe NOUN (O) the DET (O) components NOUN (O) in ADP (O) detail NOUN (O) in ADP (O) the DET (O) following VERB (O) subsections NOUN . (O) 

 [Feed PROPN - Forward PROPN (B) Transformer VERB (I)] 

 The DET (O) architecture NOUN (O) for ADP (O) [FastSpeech PROPN (B)] is AUX (O) a NOUN (O) [feed NOUN - forward NOUN (B) structure NOUN (I)] based VERB (O) on ADP (O) [self NOUN - attention NOUN (B)] in ADP (O) [Transformer NOUN (B)] and CCONJ (O) [1D PROPN (B) convolution NOUN (I)] . 
We PRON (O) call NOUN (O) this DET (O) structure NOUN (O) as SCONJ (O) [Feed PROPN - Forward NOUN (B) Transformer VERB (I)] (FFT PROPN) , (O) as SCONJ (O) shown VERB (O) in ADP (O) Figure NOUN . (O) 
[Feed PROPN - Forward NOUN (B)] Transformer VERB (O) stacks VERB (O) multiple NOUN (O) [FFT PROPN (B) blocks PROPN (I)] for ADP (O) [phoneme NOUN (B)] to PART (O) [mel PROPN - spectrogram PROPN (B) transformation NOUN (I)] , with ADP (O) N NOUN (O) blocks PROPN (O) on ADP (O) the DET (O) [phoneme NOUN (B)] side NOUN , (O) and CCONJ (O) N NOUN (O) blocks PROPN (O) on ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B) side NOUN (I)] , with ADP (O) a NOUN (O) length NOUN (O) regulator NOUN (O) (which DET (O) will VERB (O) be AUX (O) described VERB (O) in ADP (O) the DET (O) next ADJ (O) subsection NOUN) (O) in ADP (O) between ADP (O) to ADP (O) bridge NOUN (O) the DET (O) length NOUN (O) gap NOUN (O) between ADP (O) the DET (O) [phoneme NOUN (B)] and CCONJ (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] . 
Each DET (O) [FFT PROPN (B) block NOUN (I)] consists VERB (O) of ADP (O) a NOUN (O) [self NOUN - attention NOUN (B)] and CCONJ (O) [1D PROPN (B) convolutional ADJ (I) network NOUN (I)] , as SCONJ (O) shown VERB (O) in ADP (O) Figure NOUN . (O) 
The DET (O) [self NOUN - attention NOUN (B) network NOUN (I)] consists VERB (O) of ADP (O) a NOUN (O) [multi ADJ - head ADJ (B) attention NOUN (I)] to PART (O) extract NOUN (O) the DET (O) cross NOUN - position ADJ (O) information NOUN . (O) 
Different ADJ (O) from ADP (O) the DET (O) 2-layer NUM (O) dense ADJ (O) network NOUN (O) in ADP (O) [Transformer NOUN (B)] , we PRON (O) use NOUN (O) a NOUN (O) 2-layer NUM (O) [1D PROPN (B) convolutional ADJ (I) network NOUN (I)] with ADP (O) [ReLU NOUN (B) activation NOUN (I)] . 
The DET (O) motivation NOUN (O) is AUX (O) that SCONJ (O) the DET (O) adjacent ADJ (O) [hidden VERB (B) states NOUN (I)] are AUX (O) more ADJ (O) closely ADV (O) related ADJ (O) in ADP (O) the DET (O) character NOUN (O) / [phoneme NOUN (B)] and CCONJ (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] in ADP (O) [speech NOUN (B) tasks NOUN (I)] . 
We PRON (O) evaluate VERB (O) the DET (O) effectiveness NOUN (O) of ADP (O) the DET (O) [1D PROPN (B) convolutional ADJ (I) network NOUN (I)] in ADP (O) the DET (O) experimental NOUN (O) section NOUN . (O) 
Following VERB (O) Transformer VERB , (O) [residual ADJ (B) connections NOUN (I)] , [layer NOUN (B) normalization NOUN (I)] , and CCONJ (O) [dropout NOUN (B)] are AUX (O) added VERB (O) after ADP (O) the DET (O) [self NOUN - attention NOUN (B) network NOUN (I)] and CCONJ (O) [1D PROPN (B) convolutional ADJ (I) network NOUN (I)] respectively ADV . (O) 

 Length NOUN (O) Regulator NOUN (O) 

 The DET (O) length NOUN (O) regulator NOUN (O) (Figure NOUN) (O) is AUX (O) used VERB (O) to ADP (O) solve VERB (O) the DET (O) problem NOUN (O) of ADP (O) length NOUN (O) mismatch NOUN (O) between ADP (O) the DET (O) [phoneme NOUN (B)] and CCONJ (O) [spectrogram NOUN (B) sequence NOUN (I)] in ADP (O) the DET (O) [Feed PROPN - Forward NOUN (B) Transformer VERB (I)] , as SCONJ (O) well INTJ (O) as SCONJ (O) to ADP (O) control NOUN (O) the DET (O) [voice NOUN (B) speed NOUN (I)] and CCONJ (O) part NOUN (O) of ADP (O) [prosody NOUN (B)] . 
The DET (O) length NOUN (O) of ADP (O) a NOUN (O) [phoneme NOUN (B) sequence NOUN (I)] is AUX (O) usually ADV (O) smaller ADJ (O) than SCONJ (O) that SCONJ (O) of ADP (O) its DET (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] , and CCONJ (O) each DET (O) [phoneme NOUN (B)] corresponds VERB (O) to ADP (O) several ADJ (O) [mel NOUN - spectrograms NOUN (B)] . 
We PRON (O) refer NOUN (O) to ADP (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) [mel NOUN - spectrograms NOUN (B)] that DET (O) corresponds VERB (O) to ADP (O) a NOUN (O) [phoneme NOUN (B)] as SCONJ (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] (we PRON (O) will VERB (O) describe VERB (O) how ADV (O) to ADP (O) predict VERB (O) [phoneme NOUN (B) duration NOUN (I)] in ADP (O) the DET (O) next ADJ (O) subsection NOUN) . (O) 
Based VERB (O) on ADP (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] d ADJ , (O) the DET (O) length NOUN (O) regulator NOUN (O) expands VERB (O) the DET (O) [hidden VERB (B) states NOUN (I)] of ADP (O) the DET (O) [phoneme NOUN (B) sequence NOUN (I)] d ADJ (O) times NOUN , (O) and CCONJ (O) then ADV (O) the DET (O) total NOUN (O) length NOUN (O) of ADP (O) the DET (O) [hidden VERB (B) states NOUN (I)] equals VERB (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) [mel NOUN - spectrograms NOUN (B)] . 
Denote PROPN (O) the DET (O) [hidden VERB (B) states NOUN (I)] of ADP (O) the DET (O) [phoneme NOUN (B) sequence NOUN (I)] as SCONJ (O) H NOUN (O) pho PROPN (O) = (h1 PROPN , (O) h2 PROPN , ... PUNCT , (O) hn PROPN) , (O) where ADV (O) n NOUN (O) is AUX (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) sequence NOUN . (O) 
Denote PROPN (O) the DET (O) [phoneme NOUN (B) duration NOUN (I) sequence NOUN (I)] as SCONJ (O) D NOUN (O) = (d1 PROPN , (O) d2 PROPN , ... PUNCT , (O) dn PROPN) , (O) where ADV (O) Σni=1 PROPN (O) di X (O) = m NOUN (O) and CCONJ (O) m NOUN (O) is AUX (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] . 
We PRON (O) denote NOUN (O) the DET (O) length NOUN (O) regulator NOUN (O) LR PROPN (O) as SCONJ (O) 
where ADV (O) α NOUN (O) is AUX (O) a NOUN (O) [hyperparameter NOUN (B)] to PART (O) determine NOUN (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) expanded VERB (O) sequence NOUN (O) Hmel PROPN , (O) thereby ADV (O) controlling NOUN (O) the DET (O) [voice NOUN (B) speed NOUN (I)] . 
For ADP (O) example NOUN , (O) given VERB (O) H NOUN (O) pho PROPN (O) = (h1 PROPN , (O) h2 PROPN , (O) h3 PROPN , (O) h4 PROPN) (O) and CCONJ (O) the DET (O) corresponding VERB (O) [phoneme NOUN (B) duration NOUN (I) sequence NOUN (I)] D PROPN (O) = (2 NUM , (O) 2 NUM , (O) 3 NUM , (O) 1 NUM) , (O) the DET (O) expanded VERB (O) sequence NOUN (O) Hmel PROPN (O) based VERB (O) on ADP (O) Equation NOUN (O) 1 NUM (O) becomes VERB (O) (h1 PROPN , (O) h1 NOUN , (O) h2 PROPN , (O) h2 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h4 PROPN) (O) if SCONJ (O) α NOUN (O) = 1 NUM (O) (normal ADJ (O) speed NOUN) . (O) 
When ADV (O) α NOUN (O) = 1.3 NUM (O) (slow ADJ (O) speed NOUN) (O) and CCONJ (O) 0.5 NUM (O) (fast ADV (O) speed NOUN) , (O) the DET (O) duration NOUN (O) sequences NOUN (O) become VERB (O) Dα=1.3 PROPN (O) = (2.6 NUM , (O) 2.6 NUM , (O) 3.9 NUM , (O) 1.3 NUM) (O) ≈ PUNCT (O) (3 NUM , (O) 3 NUM , (O) 4 NUM , (O) 1 NUM) (O) and CCONJ (O) Dα=0.5 PROPN (O) = (1 NUM , (O) 1 NUM , (O) 1.5 NUM , (O) 0.5 NUM) (O) ≈ PUNCT (O) (1 NUM , (O) 1 NUM , (O) 2 NUM , (O) 1 NUM) , (O) and CCONJ (O) the DET (O) expanded VERB (O) sequences NOUN (O) become VERB (O) (h1 PROPN , (O) h1 NOUN , (O) h1 NOUN , (O) h2 PROPN , (O) h2 PROPN , (O) h2 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h4 PROPN) (O) and CCONJ (O) (h1 PROPN , (O) h2 PROPN , (O) h3 PROPN , (O) h3 PROPN , (O) h4 PROPN) (O) respectively ADV . (O) 
We PRON (O) can VERB (O) also ADV (O) control NOUN (O) the DET (O) break NOUN (O) between ADP (O) words NOUN (O) by ADP (O) adjusting VERB (O) the DET (O) duration NOUN (O) of ADP (O) the DET (O) space NOUN (O) characters NOUN (O) in ADP (O) the DET (O) sentence NOUN , (O) so CCONJ (O) as SCONJ (O) to ADP (O) adjust NOUN (O) part NOUN (O) of ADP (O) [prosody NOUN (B)] of ADP (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] . 

 [Duration NOUN (B) Predictor NOUN (I)] 

 [Phoneme PROPN (B) duration NOUN (I) prediction NOUN (I)] is AUX (O) important ADJ (O) for ADP (O) the DET (O) length NOUN (O) regulator NOUN . (O) 
As SCONJ (O) shown VERB (O) in ADP (O) Figure NOUN , (O) the DET (O) [duration NOUN (B) predictor NOUN (I)] consists VERB (O) of ADP (O) a NOUN (O) 2-layer NUM (O) [1D PROPN (B) convolutional ADJ (I) network NOUN (I)] with ADP (O) [ReLU NOUN (B) activation NOUN (I)] , each DET (O) followed VERB (O) by ADP (O) the DET (O) [layer NOUN (B) normalization NOUN (I)] and CCONJ (O) the DET (O) [dropout NOUN (B) layer NOUN (I)] , and CCONJ (O) an DET (O) extra ADJ (O) linear NOUN (O) layer NOUN (O) to ADP (O) output NOUN (O) a NOUN (O) scalar NOUN , (O) which DET (O) is AUX (O) exactly ADV (O) the DET (O) predicted VERB (O) [phoneme NOUN (B) duration NOUN (I)] . 
Note NOUN (O) that SCONJ (O) this DET (O) module NOUN (O) is AUX (O) stacked VERB (O) on ADP (O) top NOUN (O) of ADP (O) the DET (O) [FFT PROPN (B) blocks PROPN (I)] on ADP (O) the DET (O) [phoneme NOUN (B)] side NOUN (O) and CCONJ (O) is AUX (O) jointly ADV (O) trained VERB (O) with ADP (O) the DET (O) [FastSpeech PROPN (B) model NOUN (I)] to PART (O) predict VERB (O) the DET (O) length NOUN (O) of ADP (O) [mel NOUN - spectrograms NOUN (B)] for ADP (O) each DET (O) [phoneme NOUN (B)] with ADP (O) the DET (O) [mean NOUN (B) square NOUN (I) error NOUN (I)] ([MSE PROPN (B)]) loss NOUN . (O) 
We PRON (O) predict VERB (O) the DET (O) length NOUN (O) in ADP (O) the DET (O) logarithmic NOUN (O) domain NOUN , (O) which DET (O) makes VERB (O) them PRON (O) more ADJ (O) [Gaussian PROPN (B)] and CCONJ (O) easier ADJ (O) to ADP (O) train NOUN . (O) 
Note NOUN (O) that DET (O) the DET (O) trained VERB (O) [duration NOUN (B) predictor NOUN (I)] is AUX (O) only ADV (O) used VERB (O) in ADP (O) the DET (O) [TTS PROPN (B) inference NOUN (I)] phase NOUN , (O) because SCONJ (O) we PRON (O) can VERB (O) directly ADV (O) use NOUN (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] extracted VERB (O) from ADP (O) an DET (O) autoregressive ADJ (O) teacher NOUN (O) model NOUN (O) in ADP (O) training NOUN (O) (see VERB (O) following VERB (O) discussions NOUN) . (O) 

 In ADP (O) order NOUN (O) to ADP (O) train NOUN (O) the DET (O) [duration NOUN (B) predictor NOUN (I)] , we PRON (O) extract NOUN (O) the DET (O) [ground NOUN - truth NOUN (B) phoneme PROPN (I) duration NOUN (I)] from ADP (O) an DET (O) autoregressive ADJ (O) teacher NOUN (O) [TTS PROPN (B) model NOUN (I)] , as SCONJ (O) shown VERB (O) in ADP (O) Figure NOUN . (O) 
We PRON (O) describe NOUN (O) the DET (O) detailed ADJ (O) steps NOUN (O) as SCONJ (O) follows VERB (O) : 

 • X (O) We PRON (O) first ADJ (O) train NOUN (O) an DET (O) [autoregressive ADJ (B) encoder NOUN - attention NOUN - decoder NOUN (I)] based VERB (O) [Transformer NOUN (B) TTS PROPN (I) model NOUN (I)] following VERB . (O) 
• X (O) For ADP (O) each DET (O) training NOUN (O) sequence NOUN (O) pair NOUN , (O) we PRON (O) extract NOUN (O) the DET (O) [decoder PROPN (B)]-to-[encoder NOUN attention NOUN (O) alignments NOUN] (O) from ADP (O) the DET (O) trained VERB (O) teacher NOUN (O) model NOUN . (O) 
There PRON (O) are AUX (O) multiple NOUN (O) [attention NOUN (B) alignments NOUN (I)] due ADJ (O) to ADP (O) the DET (O) [multi ADJ - head ADJ (B) self NOUN - attention NOUN (I)] , and CCONJ (O) not PART (O) all DET (O) attention NOUN (O) heads NOUN (O) demonstrate NOUN (O) the DET (O) diagonal ADJ (O) property NOUN (O) (the DET (O) [phoneme NOUN (B)] and CCONJ (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] are AUX (O) monotonously ADV (O) aligned VERB) . (O) 
We PRON (O) propose NOUN (O) a NOUN (O) focus NOUN (O) P NOUN (O) S NOUN (O) rate NOUN (O) F PROPN (O) to ADP (O) measure NOUN (O) how ADV (O) an DET (O) attention NOUN (O) head NOUN (O) is AUX (O) close NOUN (O) to ADP (O) diagonal ADJ (O) : F PROPN (O) = S NOUN (O) 1 NUM (O) s=1 NOUN (O) max NOUN (O) 1≤t≤T NUM (O) a NOUN (O) s NOUN , (O) t NOUN , (O) where ADV (O) S PROPN (O) and CCONJ (O) T NOUN (O) are AUX (O) the DET (O) lengths PROPN (O) of ADP (O) the DET (O) [ground NOUN - truth NOUN (B) spectrograms VERB (I)] and CCONJ (O) [phonemes NOUN (B)] , a DET (O) s NOUN , (O) t NOUN (O) donates VERB (O) the DET (O) element NOUN (O) in ADP (O) the DET (O) s PROPN - th NOUN (O) row NOUN (O) and CCONJ (O) t NOUN - th NOUN (O) column NOUN (O) of ADP (O) the DET (O) attention NOUN (O) matrix PROPN . (O) 
We PRON (O) compute NOUN (O) the DET (O) focus NOUN (O) rate NOUN (O) for ADP (O) each DET (O) head NOUN (O) and CCONJ (O) choose VERB (O) the DET (O) head NOUN (O) with ADP (O) the DET (O) largest ADJ (O) F NOUN (O) as SCONJ (O) the DET (O) [attention NOUN (B) alignments NOUN (I)] . 
• X (O) Finally ADV , (O) we PRON (O) extract NOUN (O) the DET (O) [phoneme NOUN (B) duration NOUN (I) sequence NOUN (I)] D PROPN (O) = (d1 PROPN , (O) d2 PROPN , ... PUNCT , (O) dn PROPN) (O) according VERB (O) to ADP (O) the DET (O) P NOUN (O) S NOUN (O) duration NOUN (O) extractor NOUN (O) d NOUN (O) i PRON (O) = s=1 NOUN (O) (arg NOUN (O) max NOUN (O) t NOUN (O) a NOUN (O) s NOUN , (O) t NOUN (O) = i NOUN) . (O) 
That DET (O) is AUX , (O) the DET (O) duration NOUN (O) of ADP (O) a NOUN (O) [phoneme NOUN (B)] is AUX (O) the DET (O) number NOUN (O) of ADP (O) [mel NOUN - spectrograms NOUN (B)] attended VERB (O) to ADP (O) it PRON (O) according VERB (O) to ADP (O) the DET (O) attention NOUN (O) head NOUN (O) selected VERB (O) in ADP (O) the DET (O) above ADV (O) step NOUN . (O) 

 Experimental PROPN (O) Setup NOUN (O) 

 Datasets VERB (O) 

 We PRON (O) conduct NOUN (O) experiments VERB (O) on ADP (O) [LJSpeech NOUN (B) dataset NOUN (I)] , which DET (O) contains VERB (O) 13,100 NUM (O) English PROPN (O) [audio NOUN (B) clips NOUN (I)] and CCONJ (O) the DET (O) corresponding VERB (O) text NOUN (O) transcripts NOUN , (O) with ADP (O) the DET (O) total NOUN (O) [audio NOUN (B) length NOUN (I)] of ADP (O) approximate NOUN (O) 24 NUM (O) hours NOUN . (O) 
We PRON (O) randomly ADV (O) split VERB (O) the DET (O) dataset NOUN (O) into ADP (O) 3 NUM (O) sets VERB (O) : 12500 NUM (O) samples NOUN (O) for ADP (O) training NOUN , (O) 300 NUM (O) samples NOUN (O) for ADP (O) validation NOUN (O) and CCONJ (O) 300 NUM (O) samples NOUN (O) for ADP (O) testing NOUN . (O) 
In ADP (O) order NOUN (O) to ADP (O) alleviate VERB (O) the DET (O) mispronunciation NOUN (O) problem NOUN , (O) we PRON (O) convert NOUN (O) the DET (O) text NOUN (O) sequence NOUN (O) into ADP (O) the DET (O) [phoneme NOUN (B) sequence NOUN (I)] with ADP (O) our DET (O) internal ADJ (O) [grapheme NOUN - to ADP - phoneme NOUN (B) conversion NOUN (I) tool NOUN (I)] , following VERB . (O) 
For ADP (O) the DET (O) [speech NOUN (B) data NOUN (I)] , we PRON (O) convert NOUN (O) the DET (O) [raw ADJ (B) waveform PROPN (I)] into ADP (O) [mel NOUN - spectrograms NOUN (B)] following VERB . (O) 
Our DET (O) frame NOUN (O) size NOUN (O) and CCONJ (O) hop NOUN (O) size NOUN (O) are AUX (O) set NOUN (O) to ADP (O) 1024 NUM (O) and CCONJ (O) 256 NUM , (O) respectively ADV . (O) 
In ADP (O) order NOUN (O) to ADP (O) evaluate VERB (O) the DET (O) robustness NOUN (O) of ADP (O) our DET (O) proposed VERB (O) [FastSpeech PROPN (B)] , we PRON (O) also ADV (O) choose VERB (O) 50 NUM (O) sentences NOUN (O) which DET (O) are AUX (O) particularly ADV (O) hard ADJ (O) for ADP (O) [TTS PROPN (B) system NOUN (I)] , following VERB (O) the DET (O) practice NOUN (O) in ADP . (O) 

 Model NOUN (O) Configuration NOUN (O) 

 [FastSpeech PROPN (B) model NOUN (I)] — PUNCT (O) Our DET (O) [FastSpeech PROPN (B) model NOUN (I)] consists VERB (O) of ADP (O) 6 NUM (O) [FFT PROPN (B) blocks PROPN (I)] on ADP (O) both DET (O) the DET (O) [phoneme NOUN (B)] side NOUN (O) and CCONJ (O) the DET (O) [mel PROPN - spectrogram PROPN (B) side NOUN (I)] . 
The DET (O) size NOUN (O) of ADP (O) the DET (O) [phoneme NOUN (B)] vocabulary NOUN (O) is AUX (O) 51 NUM , (O) including VERB (O) punctuations NOUN . (O) 
The DET (O) dimension NOUN (O) of ADP (O) [phoneme NOUN (B) embeddings NOUN (I)] , the DET (O) hidden VERB (O) size NOUN (O) of ADP (O) the DET (O) [self NOUN - attention NOUN (B)] and CCONJ (O) [1D PROPN (B) convolution NOUN (I)] in ADP (O) the DET (O) [FFT PROPN (B) block NOUN (I)] are AUX (O) all DET (O) set NOUN (O) to ADP (O) 384 NUM . (O) 
The DET (O) number NOUN (O) of ADP (O) attention NOUN (O) heads NOUN (O) is AUX (O) set NOUN (O) to ADP (O) 2 NUM . (O) 
The DET (O) kernel NOUN (O) sizes VERB (O) of ADP (O) the DET (O) [1D PROPN (B) convolution NOUN (I)] in ADP (O) the DET (O) 2-layer NUM (O) [convolutional NOUN (B) network NOUN (I)] are AUX (O) both DET (O) set NOUN (O) to ADP (O) 3 NUM , (O) with ADP (O) input NOUN (O) / output NOUN (O) size NOUN (O) of ADP (O) 384/1536 NUM (O) for ADP (O) the DET (O) first ADJ (O) layer NOUN (O) and CCONJ (O) 1536/384 NUM (O) in ADP (O) the DET (O) second NOUN (O) layer NOUN . (O) 
The DET (O) output NOUN (O) linear NOUN (O) layer NOUN (O) converts NOUN (O) the DET (O) 384-dimensional NUM (O) hidden VERB (O) into ADP (O) 80-dimensional NUM (O) [mel PROPN - spectrogram PROPN (B)] . 
In ADP (O) our DET (O) [duration NOUN (B) predictor NOUN (I)] , the DET (O) kernel NOUN (O) sizes VERB (O) of ADP (O) the DET (O) [1D PROPN (B) convolution NOUN (I)] are AUX (O) set NOUN (O) to ADP (O) 3 NUM , (O) with ADP (O) input NOUN (O) / output NOUN (O) sizes VERB (O) of ADP (O) 384/384 PROPN (O) for ADP (O) both DET (O) layers NOUN . (O) 

 [Autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] — PUNCT (O) The DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] serves VERB (O) two NUM (O) purposes VERB (O) in ADP (O) our DET (O) work NOUN (O) : 1 X) (O) to ADP (O) extract NOUN (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] as SCONJ (O) the DET (O) target NOUN (O) to ADP (O) train NOUN (O) the DET (O) [duration NOUN (B) predictor NOUN (I)] ; 2 X) (O) to ADP (O) generate NOUN (O) [mel PROPN - spectrogram PROPN (B)] in ADP (O) the DET (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)] (which DET (O) will VERB (O) be AUX (O) introduced VERB (O) in ADP (O) the DET (O) next ADJ (O) subsection NOUN) . (O) 
We PRON (O) refer NOUN (O) to ADP (O) for ADP (O) the DET (O) configurations NOUN (O) of ADP (O) this DET (O) model NOUN , (O) which DET (O) consists VERB (O) of ADP (O) a NOUN (O) 6-layer NUM (O) [encoder NOUN (B)] , a DET (O) 6-layer NUM (O) [decoder NOUN (B)] , except SCONJ (O) that SCONJ (O) we PRON (O) use NOUN (O) [1D PROPN (B) convolution NOUN (I) network NOUN (I)] instead ADV (O) of ADP (O) position NOUN - wise ADJ (O) FFN PROPN . (O) 
The DET (O) number NOUN (O) of ADP (O) parameters NOUN (O) of ADP (O) this DET (O) teacher NOUN (O) model NOUN (O) is AUX (O) similar ADJ (O) to ADP (O) that SCONJ (O) of ADP (O) our DET (O) [FastSpeech PROPN (B) model NOUN (I)] . 

 Training NOUN (O) and CCONJ (O) Inference PROPN (O) 

 We PRON (O) first ADJ (O) train NOUN (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] on ADP (O) 4 NUM (O) NVIDIA PROPN (O) V100 PROPN (O) [GPUs NOUN (B)] , with ADP (O) batchsize PROPN (O) of ADP (O) 16 NUM (O) sentences NOUN (O) on ADP (O) each DET (O) [GPU PROPN (B)] . 
We PRON (O) use NOUN (O) the DET (O) [Adam PROPN (B) optimizer NOUN (I)] with ADP (O) β X (O) 1 NUM (O) = 0.9 NUM , (O) β X (O) 2 NUM (O) = 0.98 NUM , (O) ε NOUN (O) = 10 NUM (O) −9 PUNCT (O) and CCONJ (O) follow NOUN (O) the DET (O) same ADJ (O) learning NOUN (O) rate NOUN (O) schedule NOUN (O) in ADP . (O) 
It PRON (O) takes VERB (O) 80k NOUN (O) steps NOUN (O) for ADP (O) training NOUN (O) until ADP (O) convergence PROPN . (O) 
We PRON (O) feed NOUN (O) the DET (O) text NOUN (O) and CCONJ (O) [speech NOUN (B) pairs NOUN (I)] in ADP (O) the DET (O) training NOUN (O) set NOUN (O) to ADP (O) the DET (O) model NOUN (O) again ADV (O) to ADP (O) obtain VERB (O) the DET (O) [encoder NOUN - decoder NOUN (B) attention NOUN (I) alignments VERB (I)] , which DET (O) are AUX (O) used VERB (O) to ADP (O) train NOUN (O) the DET (O) [duration NOUN (B) predictor NOUN (I)] . 
In ADP (O) addition NOUN , (O) we PRON (O) also ADV (O) leverage NOUN (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)]     that DET (O) has AUX (O) achieved VERB (O) good ADJ (O) performance NOUN (O) in ADP (O) [non ADJ - autoregressive ADJ (B) machine NOUN (I) translation NOUN (I)]     to PART (O) transfer NOUN (O) the DET (O) knowledge NOUN (O) from ADP (O) the DET (O) teacher NOUN (O) model NOUN (O) to ADP (O) the DET (O) student NOUN (O) model NOUN . (O) 
For ADP (O) each DET (O) source NOUN (O) text NOUN (O) sequence NOUN , (O) we PRON (O) generate NOUN (O) the DET (O) [mel NOUN - spectrograms NOUN (B)] with ADP (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] and CCONJ (O) take VERB (O) the DET (O) source NOUN (O) text NOUN (O) and CCONJ (O) the DET (O) generated VERB (O) [mel NOUN - spectrograms NOUN (B)] as SCONJ (O) the DET (O) paired VERB (O) data NOUN (O) for ADP (O) [FastSpeech PROPN (B) model NOUN (I)] training VERB . (O) 
We PRON (O) train NOUN (O) the DET (O) [FastSpeech PROPN (B) model NOUN (I)] together ADV (O) with ADP (O) the DET (O) [duration NOUN (B) predictor NOUN (I)] . 
The DET (O) optimizer NOUN (O) and CCONJ (O) other ADJ (O) [hyper NOUN - parameters NOUN (B)] for ADP (O) [FastSpeech PROPN (B)] are AUX (O) the DET (O) same ADJ (O) as SCONJ (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] . 
The DET (O) [FastSpeech PROPN (B) model NOUN (I)] training VERB (O) takes VERB (O) about ADP (O) 80k NOUN (O) steps VERB (O) on ADP (O) 4 NUM (O) NVIDIA PROPN (O) V100 PROPN (O) [GPUs NOUN (B)] . 
In ADP (O) the DET (O) inference NOUN (O) process NOUN , (O) the DET (O) output NOUN (O) [mel NOUN - spectrograms NOUN (B)] of ADP (O) our DET (O) [FastSpeech PROPN (B) model NOUN (I)] are AUX (O) transformed VERB (O) into ADP (O) [audio NOUN (B) samples NOUN (I)] using VERB (O) the DET (O) pretrained VERB (O) [WaveGlow PROPN (B)] . 

 https://github.com/NVIDIA/waveglow PROPN (O) 

 Results NOUN (O) 

 In ADP (O) this DET (O) section NOUN , (O) we PRON (O) evaluate VERB (O) the DET (O) performance NOUN (O) of ADP (O) [FastSpeech PROPN (B)] in ADP (O) terms NOUN (O) of ADP (O) [audio NOUN (B) quality NOUN (I)] , inference NOUN (O) speedup PROPN , (O) robustness NOUN , (O) and CCONJ (O) controllability NOUN . (O) 

 [Audio NOUN (B) Quality NOUN (I)] We PRON (O) conduct NOUN (O) the DET (O) [MOS PROPN (B)] ([mean VERB (B) opinion NOUN (I) score NOUN (I)]) evaluation NOUN (O) on ADP (O) the DET (O) test NOUN (O) set NOUN (O) to ADP (O) measure NOUN (O) the DET (O) [audio NOUN (B) quality NOUN (I)] . 
We PRON (O) keep VERB (O) the DET (O) text NOUN (O) content NOUN (O) consistent ADJ (O) among ADP (O) different ADJ (O) models NOUN (O) so CCONJ (O) as SCONJ (O) to ADP (O) exclude VERB (O) other ADJ (O) interference NOUN (O) factors NOUN , (O) only ADV (O) examining VERB (O) the DET (O) [audio NOUN (B) quality NOUN (I)] . 
Each DET (O) [audio NOUN (B)] is AUX (O) listened VERB (O) by ADP (O) at ADP (O) least ADJ (O) 20 NUM (O) testers NOUN , (O) who PRON (O) are AUX (O) all DET (O) native NOUN (O) [English PROPN (B) speakers NOUN (I)] . 
We PRON (O) compare VERB (O) the DET (O) [MOS PROPN (B)] of ADP (O) the DET (O) generated VERB (O) [audio NOUN (B) samples NOUN (I)] by ADP (O) our DET (O) 
[FastSpeech PROPN (B) model NOUN (I)] with ADP (O) other ADJ (O) systems NOUN , (O) which DET (O) include VERB (O) 1 NUM) (O) GT PROPN , (O) the DET (O) [ground NOUN (B) truth NOUN (I) audio NOUN (I)] ; 2 X) (O) GT PROPN (O) ([Mel PROPN (B)] + [WaveGlow PROPN (B)]) , where ADV (O) we PRON (O) first ADJ (O) convert NOUN (O) the DET (O) [ground NOUN (B) truth NOUN (I) audio NOUN (I)] into ADP (O) [mel NOUN - spectrograms NOUN (B)] , and CCONJ (O) then ADV (O) convert NOUN (O) the DET (O) [mel NOUN - spectrograms NOUN (B)] back ADV (O) to ADP (O) [audio NOUN (B)] using VERB (O) [WaveGlow PROPN (B)] ; 3 X) (O) [Tacotron PROPN (B) 2 NUM (I)] ([Mel PROPN (B)] + [WaveGlow PROPN (B)]) ; 4 X) (O) [Transformer NOUN (B) TTS PROPN (I)] ([Mel PROPN (B)] + [WaveGlow PROPN (B)]) . 
5 NUM) (O) [Merlin PROPN (B)] (WORLD PROPN) , (O) a NOUN (O) popular ADJ (O) [parametric NOUN (B) TTS PROPN (I) system NOUN (I)] with ADP (O) WORLD NOUN (O) as SCONJ (O) the DET (O) [vocoder NOUN (B)] . 
The DET (O) results VERB (O) are AUX (O) shown VERB (O) in ADP (O) Table NOUN . (O) 
It PRON (O) can VERB (O) be AUX (O) seen VERB (O) that SCONJ (O) our DET (O) [FastSpeech PROPN (B)] can VERB (O) nearly ADV (O) match NOUN (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) [Transformer NOUN (B) TTS PROPN (I) model NOUN (I)] and CCONJ (O) [Tacotron PROPN (B) 2 NUM (I)] . 

 Table NOUN (O) : The DET (O) [MOS PROPN (B)] with ADP (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN . (O) 

 Inference NOUN (O) Speedup PROPN (O) We PRON (O) evaluate VERB (O) the DET (O) inference NOUN (O) latency NOUN (O) of ADP (O) [FastSpeech PROPN (B)] compared VERB (O) with ADP (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] , which DET (O) has AUX (O) similar ADJ (O) number NOUN (O) of ADP (O) model NOUN (O) parameters NOUN (O) with ADP (O) [FastSpeech PROPN (B)] . 
We PRON (O) first ADJ (O) show NOUN (O) the DET (O) inference NOUN (O) speedup NOUN (O) for ADP (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] in ADP (O) Table NOUN . (O) 
It PRON (O) can VERB (O) be AUX (O) seen VERB (O) that SCONJ (O) [FastSpeech PROPN (B)] speeds VERB (O) up NOUN (O) the DET (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] by ADP (O) 269.40x NUM , (O) compared VERB (O) with ADP (O) the DET (O) [Transformer NOUN (B) TTS PROPN (I) model NOUN (I)] . 
We PRON (O) then ADV (O) show NOUN (O) the DET (O) [end NOUN - to ADP - end NOUN (B) speedup NOUN (I)] when ADV (O) using VERB (O) [WaveGlow PROPN (B)] as SCONJ (O) the DET (O) [vocoder NOUN (B)] . 
It PRON (O) can VERB (O) be AUX (O) seen VERB (O) that SCONJ (O) [FastSpeech PROPN (B)] can VERB (O) still ADV (O) achieve VERB (O) 38.30x PROPN (O) speedup NOUN (O) for ADP (O) [audio NOUN (B) generation NOUN (I)] . 

 According VERB (O) to ADP (O) our DET (O) further NOUN (O) comprehensive ADJ (O) experiments VERB (O) on ADP (O) our DET (O) [internal ADJ (B) datasets VERB (I)] , the DET (O) [voice NOUN (B) quality NOUN (I)] of ADP (O) [FastSpeech PROPN (B)] can VERB (O) always ADV (O) match NOUN (O) that SCONJ (O) of ADP (O) the DET (O) teacher NOUN (O) model NOUN (O) on ADP (O) multiple NOUN (O) languages NOUN (O) and CCONJ (O) [multiple NOUN (B) voices NOUN (I)] , if SCONJ (O) we PRON (O) use NOUN (O) more ADJ (O) unlabeled ADJ (O) text NOUN (O) for ADP (O) knowledge NOUN (O) distillation NOUN . (O) 

 Table NOUN (O) : The DET (O) comparison NOUN (O) of ADP (O) inference NOUN (O) latency NOUN (O) with ADP (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN . (O) 
The DET (O) evaluation NOUN (O) is AUX (O) conducted VERB (O) on ADP (O) a NOUN (O) server NOUN (O) with ADP (O) 12 NUM (O) Intel PROPN (O) Xeon PROPN (O) [CPU NOUN (B)] , 256 NUM (O) GB PROPN (O) memory NOUN , (O) 1 NUM (O) NVIDIA PROPN (O) V100 PROPN (O) [GPU PROPN (B)] and CCONJ (O) [batch NOUN (B) size NOUN (I)] of ADP (O) 1 NUM . (O) 
The DET (O) average NOUN (O) length NOUN (O) of ADP (O) the DET (O) generated VERB (O) [mel NOUN - spectrograms NOUN (B)] for ADP (O) the DET (O) two NUM (O) systems NOUN (O) are AUX (O) both DET (O) about ADP (O) 560 NUM . (O) 

 We PRON (O) also ADV (O) visualize NOUN (O) the DET (O) relationship NOUN (O) between ADP (O) the DET (O) inference NOUN (O) latency NOUN (O) and CCONJ (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) predicted VERB (O) [mel PROPN - spectrogram PROPN (B) sequence NOUN (I)] in ADP (O) the DET (O) test NOUN (O) set VERB . (O) 
Figure NOUN (O)     shows VERB (O) that SCONJ (O) the DET (O) inference NOUN (O) latency NOUN (O) barely ADV (O) increases VERB (O) with ADP (O) the DET (O) length NOUN (O) of ADP (O) the DET (O) predicted VERB (O) [mel PROPN - spectrogram PROPN (B)] for ADP (O) [FastSpeech PROPN (B)] , while SCONJ (O) increases VERB (O) largely ADV (O) in ADP (O) [Transformer NOUN (B) TTS PROPN (I)] . 
This DET (O) indicates VERB (O) that SCONJ (O) the DET (O) inference NOUN (O) speed NOUN (O) of ADP (O) our DET (O) method NOUN (O) is AUX (O) not PART (O) sensitive ADJ (O) to ADP (O) the DET (O) length NOUN (O) of ADP (O) generated VERB (O) [audio NOUN (B)] due ADJ (O) to ADP (O) parallel NOUN (O) generation NOUN . (O) 

 Robustness PROPN (O) The DET (O) [encoder NOUN - decoder NOUN (B) attention NOUN (I) mechanism NOUN (I)] in ADP (O) the DET (O) [autoregressive ADJ (B) model NOUN (I)] may VERB (O) cause NOUN (O) wrong NOUN (O) [attention NOUN (B) alignments NOUN (I)] between ADP (O) [phoneme NOUN (B)] and CCONJ (O) [mel PROPN - spectrogram PROPN (B)] , resulting VERB (O) in ADP (O) instability NOUN (O) with ADP (O) word NOUN (O) repeating VERB (O) and CCONJ (O) word NOUN (O) skipping NOUN . (O) 
To NOUN (O) evaluate VERB (O) the DET (O) robustness NOUN (O) of ADP (O) [FastSpeech PROPN (B)] , we PRON (O) select VERB (O) 50 NUM (O) sentences NOUN (O) which DET (O) are AUX (O) particularly ADV (O) hard ADJ (O) for ADP (O) [TTS PROPN (B) system NOUN (I)] . 
Word NOUN (O) error NOUN (O) counts VERB (O) are AUX (O) listed VERB (O) in ADP (O) Table NOUN . (O) 
It PRON (O) can VERB (O) be AUX (O) seen VERB (O) that SCONJ (O) [Transformer NOUN (B) TTS PROPN (I)] is AUX (O) not PART (O) robust ADJ (O) to ADP (O) these DET (O) hard ADJ (O) cases NOUN (O) and CCONJ (O) gets VERB (O) 34 NUM (O) % error NOUN (O) rate NOUN , (O) while SCONJ (O) [FastSpeech PROPN (B)] can VERB (O) effectively ADV (O) eliminate VERB (O) word NOUN (O) repeating VERB (O) and CCONJ (O) skipping NOUN (O) to ADP (O) improve VERB (O) intelligibility NOUN . (O) 

 Table NOUN (O) : The DET (O) comparison NOUN (O) of ADP (O) robustness NOUN (O) between ADP (O) [FastSpeech PROPN (B)] and CCONJ (O) other ADJ (O) systems NOUN (O) on ADP (O) the DET (O) 50 NUM (O) particularly ADV (O) hard ADJ (O) sentences NOUN . (O) 
Each DET (O) kind NOUN (O) of ADP (O) word NOUN (O) error NOUN (O) is AUX (O) counted VERB (O) at ADP (O) most ADJ (O) once ADV (O) per ADP (O) sentence NOUN . (O) 

 These DET (O) cases NOUN (O) include VERB (O) single ADJ (O) letters NOUN , (O) spellings NOUN , (O) repeated VERB (O) numbers NOUN , (O) and CCONJ (O) long ADJ (O) sentences NOUN . (O) We PRON (O) list NOUN (O) the DET (O) cases NOUN (O) in ADP (O) the DET (O) supplementary ADJ (O) materials NOUN . (O) 

 Length NOUN (O) Control NOUN (O) As SCONJ (O) mentioned VERB (O) in ADP (O) Section NOUN , (O) [FastSpeech PROPN (B)] can VERB (O) control NOUN (O) the DET (O) [voice NOUN (B) speed NOUN (I)] as SCONJ (O) well INTJ (O) as SCONJ (O) part NOUN (O) of ADP (O) the DET (O) [prosody NOUN (B)] by ADP (O) adjusting VERB (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] , which DET (O) can VERB (O) not PART (O) be AUX (O) supported VERB (O) by ADP (O) other ADJ (O) [end NOUN - to ADP - end NOUN (B) TTS PROPN (I) systems NOUN (I)] . 
We PRON (O) show NOUN (O) the DET (O) [mel NOUN - spectrograms NOUN (B)] before ADP (O) and CCONJ (O) after ADP (O) the DET (O) length NOUN (O) control NOUN , (O) and CCONJ (O) also ADV (O) put VERB (O) the DET (O) [audio NOUN (B) samples NOUN (I)] in ADP (O) the DET (O) supplementary ADJ (O) material NOUN (O) for ADP (O) reference NOUN . (O) 
Voice PROPN (O) Speed NOUN (O) The DET (O) generated VERB (O) [mel NOUN - spectrograms NOUN (B)] with ADP (O) [different ADJ (B) voice NOUN (I)] speeds VERB (O) by ADP (O) lengthening NOUN (O) or CCONJ (O) shortening VERB (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] are AUX (O) shown VERB (O) in ADP (O) Figure NOUN . (O) 
We PRON (O) also ADV (O) attach NOUN (O) several ADJ (O) [audio NOUN (B) samples NOUN (I)] in ADP (O) the DET (O) supplementary ADJ (O) material NOUN (O) for ADP (O) reference NOUN . (O) As SCONJ (O) demonstrated VERB (O) by ADP (O) the DET (O) samples NOUN , (O) [FastSpeech PROPN (B)] can VERB (O) adjust NOUN (O) the DET (O) [voice NOUN (B) speed NOUN (I)] from ADP (O) 0.5x X (O) to ADP (O) 1.5x NUM (O) smoothly ADV , (O) with ADP (O) stable ADJ (O) and CCONJ (O) almost ADV (O) unchanged ADJ (O) [pitch NOUN (B)] . 

 Breaks PROPN (O) Between ADP (O) Words NOUN (O) [FastSpeech PROPN (B)] can VERB (O) add VERB (O) breaks VERB (O) between ADP (O) adjacent ADJ (O) words NOUN (O) by ADP (O) lengthening NOUN (O) the DET (O) duration NOUN (O) of ADP (O) the DET (O) space NOUN (O) characters NOUN (O) in ADP (O) the DET (O) sentence NOUN , (O) which DET (O) can VERB (O) improve VERB (O) the DET (O) [prosody NOUN (B)] of ADP (O) voice NOUN . (O) 
We PRON (O) show NOUN (O) an DET (O) example NOUN (O) in ADP (O) Figure NOUN , (O) where ADV (O) we PRON (O) add VERB (O) breaks VERB (O) in ADP (O) two NUM (O) positions NOUN (O) of ADP (O) the DET (O) sentence NOUN (O) to ADP (O) improve VERB (O) the DET (O) [prosody NOUN (B)] . 

 Ablation NOUN (O) Study NOUN (O) We PRON (O) conduct NOUN (O) ablation NOUN (O) studies NOUN (O) to ADP (O) verify VERB (O) the DET (O) effectiveness NOUN (O) of ADP (O) several ADJ (O) components NOUN (O) in ADP (O) [FastSpeech PROPN (B)] , including VERB (O) [1D PROPN (B) Convolution PROPN (I)] and CCONJ (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)] . 
We PRON (O) conduct NOUN (O) CMOS PROPN (O) evaluation NOUN (O) for ADP (O) these DET (O) ablation NOUN (O) studies NOUN . (O) 

 Table NOUN (O) : [CMOS PROPN (B)] comparison NOUN (O) in ADP (O) the DET (O) ablation NOUN (O) studies NOUN . (O) 

 [1D PROPN (B) Convolution PROPN (I)] in ADP (O) [FFT PROPN (B) Block PROPN (I)] We PRON (O) propose NOUN (O) to ADP (O) replace VERB (O) the DET (O) original ADJ (O) fully ADV (O) connected VERB (O) layer NOUN (O) (adopted VERB (O) in ADP (O) [Transformer NOUN (B)]) with ADP (O) [1D PROPN (B) convolution NOUN (I)] in ADP (O) [FFT PROPN (B) block NOUN (I)] , as SCONJ (O) described VERB (O) in ADP (O) Section NOUN . (O) 
Here ADV (O) we PRON (O) conduct NOUN (O) experiments NOUN (O) to ADP (O) compare VERB (O) the DET (O) performance NOUN (O) of ADP (O) [1D PROPN (B) convolution NOUN (I)] to PART (O) the DET (O) fully ADV (O) connected VERB (O) layer NOUN (O) with ADP (O) similar ADJ (O) number NOUN (O) of ADP (O) parameters NOUN . (O) 
As SCONJ (O) shown VERB (O) in ADP (O) Table NOUN (O) 4 NUM , (O) replacing VERB (O) [1D PROPN (B) convolution NOUN (I)] with ADP (O) fully ADV (O) connected VERB (O) layer NOUN (O) results VERB (O) in ADP (O) -0.113 PUNCT (O) CMOS PROPN , (O) which DET (O) demonstrates VERB (O) the DET (O) effectiveness NOUN (O) of ADP (O) [1D PROPN (B) convolution NOUN (I)] . 
[Sequence NOUN - Level NOUN (B) Knowledge NOUN (I) Distillation NOUN (I)] As SCONJ (O) described VERB (O) in ADP (O) Section NOUN , (O) we PRON (O) leverage NOUN (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)] for ADP (O) [FastSpeech PROPN (B)] . 
We PRON (O) conduct NOUN (O) CMOS PROPN (O) evaluation NOUN (O) to ADP (O) compare VERB (O) the DET (O) performance NOUN (O) of ADP (O) [FastSpeech PROPN (B)] with ADP (O) and CCONJ (O) without ADP (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)] , as SCONJ (O) shown VERB (O) in ADP (O) Table NOUN . (O) 
We PRON (O) find VERB (O) that DET (O) removing VERB (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I) results VERB (I)] in ADP (O) -0.325 PUNCT (O) [CMOS PROPN (B)] , which DET (O) demonstrates VERB (O) the DET (O) effectiveness NOUN (O) of ADP (O) [sequence NOUN - level NOUN (B) knowledge NOUN (I) distillation NOUN (I)] . 

 Conclusions NOUN (O) 

 In ADP (O) this DET (O) work NOUN , (O) we PRON (O) have AUX (O) proposed VERB (O) [FastSpeech PROPN (B)] : a DET (O) fast ADV , (O) robust ADJ (O) and CCONJ (O) controllable ADJ (O) [neural NOUN (B) TTS PROPN (I) system NOUN (I)] . 
[FastSpeech PROPN (B)] has AUX (O) a NOUN (O) novel NOUN (O) [feed NOUN - forward NOUN (B) network NOUN (I)] to PART (O) generate NOUN (O) [mel PROPN - spectrogram PROPN (B)] in ADP (O) parallel NOUN , (O) which DET (O) consists VERB (O) of ADP (O) several ADJ (O) key NOUN (O) components NOUN (O) including VERB (O) [feed NOUN - forward NOUN (B) Transformer VERB (I) blocks PROPN (I)] , a DET (O) length NOUN (O) regulator NOUN (O) and CCONJ (O) a NOUN (O) [duration NOUN (B) predictor NOUN (I)] . 
Experiments NOUN (O) on ADP (O) [LJSpeech NOUN (B) dataset NOUN (I)] demonstrate VERB (O) that SCONJ (O) our DET (O) proposed VERB (O) [FastSpeech PROPN (B)] can VERB (O) nearly ADV (O) match NOUN (O) the DET (O) [autoregressive ADJ (B) Transformer VERB (I) TTS PROPN (I) model NOUN (I)] in ADP (O) terms NOUN (O) of ADP (O) [speech NOUN (B) quality NOUN (I)] , speed NOUN (O) up NOUN (O) the DET (O) [mel PROPN - spectrogram PROPN (B) generation NOUN (I)] by ADP (O) 270x NUM (O) and CCONJ (O) the DET (O) [end NOUN - to ADP - end NOUN (B) speech NOUN (I) synthesis NOUN (I)] by ADP (O) 38x NOUN , (O) almost ADV (O) eliminate VERB (O) the DET (O) problem NOUN (O) of ADP (O) word NOUN (O) skipping NOUN (O) and CCONJ (O) repeating VERB , (O) and CCONJ (O) can VERB (O) adjust NOUN (O) [voice NOUN (B) speed NOUN (I)] (0.5x-1.5x PUNCT) (O) smoothly ADV . (O) 
For ADP (O) future NOUN (O) work NOUN , (O) we PRON (O) will VERB (O) continue VERB (O) to ADP (O) improve VERB (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) [synthesized VERB (B) speech NOUN (I)] , and CCONJ (O) apply VERB (O) [FastSpeech PROPN (B)] to PART (O) [multi ADJ - speaker ADJ (B)] and CCONJ (O) low ADJ - resource NOUN (O) settings NOUN . (O) 
We PRON (O) will VERB (O) also ADV (O) train NOUN (O) [FastSpeech PROPN (B)] jointly ADV (O) with ADP (O) a NOUN (O) [parallel NOUN (B) neural NOUN (I) vocoder NOUN (I)] to PART (O) make VERB (O) it PRON (O) fully ADV (O) [end NOUN - to ADP - end NOUN (B)] and CCONJ (O) parallel NOUN . (O) 
