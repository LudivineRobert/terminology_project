[Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) : [Multi PROPN - Speaker PROPN (B) Neural PROPN (I) Text NOUN - to ADP - Speech NOUN (I)] 

 Abstract PROPN (O) 

 We PRON (O) introduce VERB (O) a NOUN (O) technique NOUN (O) for ADP (O) augmenting VERB (O) [neural NOUN (B) text NOUN - to ADP - speech NOUN (I)] ([TTS PROPN (B)]) with ADP (O) [low ADJ - dimensional ADJ (B) trainable NOUN (I) speaker PROPN (I) embeddings NOUN (I)] to PART (O) generate NOUN (O) [different ADJ (B) voices NOUN (I)] from ADP (O) a NOUN (O)     single ADJ (O) model NOUN . (O) 
As SCONJ (O) a NOUN (O) starting VERB (O) point NOUN , (O) we PRON (O) show NOUN (O) improvements NOUN (O) over ADP (O) the DET (O) two NUM (O) state NOUN - of ADP - the DET - art NOUN (O) approaches VERB (O) for ADP (O) single-[speaker NOUN (B) neural NOUN (I) TTS PROPN (I)] : [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) and CCONJ (O) [Tacotron PROPN (B)] . 
We PRON (O) introduce VERB (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) which DET (O) is AUX (O) based VERB (O) on ADP (O) a NOUN (O) similar ADJ (O) pipeline NOUN (O) with ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM , (O) but CCONJ (O) constructed VERB (O) with ADP (O) higher ADJ (O) performance NOUN (O) building NOUN (O) blocks PROPN (O) and CCONJ (O) demonstrates VERB (O) a NOUN (O) significant ADJ (O) [audio NOUN (B) quality NOUN (I) improvement NOUN (I)] over ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) 
We PRON (O) improve VERB (O) [Tacotron PROPN (B)] by ADP (O) introducing VERB (O) a NOUN (O) [post NOUN - processing ADJ (B) neural NOUN (I) vocoder NOUN (I)] , and CCONJ (O) demonstrate NOUN (O) a NOUN (O) significant ADJ (O) [audio NOUN (B) quality NOUN (I) improvement NOUN (I)] . We PRON (O) then ADV (O) demonstrate NOUN (O) our DET (O) technique NOUN (O) for ADP (O) [multi ADJ - speaker ADJ (B) speech NOUN (I) synthesis NOUN (I)] for ADP (O) both DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [Tacotron PROPN (B)] on ADP (O) two NUM (O) [multi ADJ - speaker ADJ (B) TTS PROPN (I) datasets VERB (I)] . 
We PRON (O) show NOUN (O) that SCONJ (O) a NOUN (O) single ADJ (O) [neural NOUN (B) TTS PROPN (I) system NOUN (I)] can VERB (O) learn VERB (O) hundreds NOUN (O) of ADP (O) [unique ADJ (B) voices NOUN (I)] from ADP (O) less ADJ (O) than SCONJ (O) half NOUN (O) an DET (O) hour NOUN (O) of ADP (O) data NOUN (O) per ADP (O) speaker NOUN , (O) while SCONJ (O) achieving VERB (O) high ADJ (O) [audio NOUN (B) quality NOUN (I) synthesis NOUN (I)] and CCONJ (O) preserving VERB (O) the DET (O) [speaker NOUN (B) identities NOUN (I)] almost ADV (O) perfectly ADV . (O) 

 Introduction NOUN (O) 

 [Artificial PROPN (B) speech NOUN (I) synthesis NOUN (I)] , commonly ADV (O) known VERB (O) as SCONJ (O) [text NOUN - to ADP - speech NOUN (B)] ([TTS PROPN (B)]) , has AUX (O) a NOUN (O) variety NOUN (O) of ADP (O) applications NOUN (O) in ADP (O) technology NOUN (O) interfaces NOUN , (O) accessibility NOUN , (O) media NOUN , (O) and CCONJ (O) entertainment NOUN . (O) 
Most ADJ (O) [TTS PROPN (B) systems NOUN (I)] are AUX (O) built VERB (O) with ADP (O) a NOUN (O) [single ADJ (B) speaker NOUN (I) voice NOUN (I)] , and CCONJ (O) [multiple NOUN (B) speaker NOUN (I) voices NOUN (I)] are AUX (O) provided VERB (O) by ADP (O) having VERB (O) distinct ADJ (O) [speech NOUN (B) databases NOUN (I)] or CCONJ (O) model NOUN (O) parameters NOUN . (O) 
As SCONJ (O) a NOUN (O) result VERB , (O) developing VERB (O) a NOUN (O) [TTS PROPN (B) system NOUN (I)] with ADP (O) support NOUN (O) for ADP (O) [multiple NOUN (B) voices NOUN (I)] requires VERB (O) much ADJ (O) [more ADJ (B) data NOUN (I)] and CCONJ (O) development NOUN (O) effort NOUN (O) than SCONJ (O) a NOUN (O) system NOUN (O) which DET (O) only ADV (O) supports VERB (O) a NOUN (O) [single ADJ (B) voice NOUN (I)] . 
In ADP (O) this DET (O) work NOUN , (O) we PRON (O) demonstrate NOUN (O) that SCONJ (O) we PRON (O) can VERB (O) build NOUN (O) all-[neural NOUN (B) multi ADJ - speaker ADJ (I) TTS PROPN (I) systems NOUN (I)] which DET (O) share NOUN (O) the DET (O) vast ADJ (O) majority NOUN (O) of ADP (O) parameters NOUN (O) between ADP (O) [different ADJ (B) speakers NOUN (I)] . 
We PRON (O) show NOUN (O) that SCONJ (O) not PART (O) only ADV (O) can VERB (O) a NOUN (O) single ADJ (O) model NOUN (O) generate NOUN (O) [speech NOUN (B)] from ADP (O) multiple NOUN (O) [different ADJ (B) voices NOUN (I)] , but CCONJ (O) also ADV (O) that SCONJ (O) significantly ADV (O) [less ADJ (B) data NOUN (I)] is AUX (O) required VERB (O) per ADP (O) speaker NOUN (O) than SCONJ (O) when ADV (O) training NOUN (O) single-[speaker NOUN (B) systems NOUN (I)] . 
Concretely PROPN , (O) we PRON (O) make VERB (O) the DET (O) following VERB (O) contributions NOUN (O) : 
1 NUM . (O) We PRON (O) present NOUN (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) an DET (O) improved VERB (O) architecture NOUN (O) based VERB (O) on ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) (Arik PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) . (O) 
2 NUM . (O) We PRON (O) introduce VERB (O) a NOUN (O) [WaveNet PROPN - based VERB (B)] (Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) [spectrogram NOUN - to ADP - audio NOUN (B) neural NOUN (I) vocoder NOUN (I)] , and CCONJ (O) use NOUN (O) it PRON (O) with ADP (O) [Tacotron PROPN (B)] (Wang PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) (O) as SCONJ (O) a NOUN (O) replacement NOUN (O) for ADP (O) [Griffin PROPN - Lim PROPN (B) audio NOUN (I) generation NOUN (I)] . 
3 NUM . (O) Using VERB (O) these DET (O) two NUM (O) single-[speaker NOUN (B) models NOUN (I)] as SCONJ (O) a NOUN (O) baseline PROPN , (O) we PRON (O) demonstrate NOUN (O) [multi ADJ - speaker ADJ (B) neural NOUN (I) speech NOUN (I) synthesis NOUN (I)] by ADP (O) introducing VERB (O) [trainable NOUN (B) speaker NOUN (I) embeddings NOUN (I)] into ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [Tacotron PROPN (B)] . 
We PRON (O) organize VERB (O) the DET (O) rest NOUN (O) of ADP (O) this DET (O) paper NOUN (O) as SCONJ (O) follows VERB . (O) 
Section NOUN (O) 2 NUM (O) discusses VERB (O) related ADJ (O) work NOUN (O) and CCONJ (O) what PRON (O) makes VERB (O) the DET (O) contributions NOUN (O) of ADP (O) this DET (O) paper NOUN (O) distinct ADJ (O) from ADP (O) prior ADJ (O) work NOUN . (O) 
Section NOUN (O) 3 NUM (O) presents VERB (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) highlights NOUN (O) the DET (O) differences NOUN (O) from ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) Section NOUN (O) 4 NUM (O) explains VERB (O) our DET (O) speaker NOUN (O) embedding NOUN (O) technique NOUN (O) for ADP (O) [neural NOUN (B) TTS PROPN (I) models NOUN (I)] and CCONJ (O) shows VERB (O) [multi ADJ - speaker ADJ (B) variants NOUN (I)] of ADP (O) the DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [Tacotron PROPN (B) architectures NOUN (I)] . 
Section NOUN (O) 5.1 NUM (O) quantifies NOUN (O) the DET (O) improvement NOUN (O) for ADP (O) [single ADJ (B) speaker NOUN (I) TTS PROPN (I)] through ADP (O) a NOUN (O) [mean NOUN (B) opinion NOUN (I) score NOUN (I) (MOS PROPN) (I) evaluation NOUN (I)] and CCONJ (O) Section NOUN (O) 5.2 NUM (O) presents VERB (O) the DET (O) synthesized VERB (O) [audio NOUN (B) quality NOUN (I)] of ADP (O) [multi ADJ - speaker ADJ (B) Deep ADV (I) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [Tacotron PROPN (B)] via ADP (O) both DET (O) [MOS PROPN (B) evaluation NOUN (I)] and CCONJ (O) a NOUN (O) [multi ADJ - speaker ADJ (B) discriminator NOUN (I) accuracy NOUN (I)] metric ADJ . (O) 
Section NOUN (O) 6 NUM (O) concludes VERB (O) with ADP (O) a NOUN (O) discussion NOUN (O) of ADP (O) the DET (O) results VERB (O) and CCONJ (O) potential NOUN (O) future NOUN (O) work NOUN . (O) 

 Related VERB (O) Work NOUN (O) 

 We PRON (O) discuss NOUN (O) the DET (O) related ADJ (O) work NOUN (O) relevant ADJ (O) to ADP (O) each DET (O) of ADP (O) our DET (O) claims VERB (O) in ADP (O) Section NOUN (O) 1 NUM (O) in ADP (O) order NOUN , (O) starting VERB (O) from ADP (O) single ADJ - speaker NOUN (O) [neural NOUN (B) speech NOUN (I) synthesis NOUN (I)] and CCONJ (O) moving VERB (O) on ADP (O) to ADP (O) [multi ADJ - speaker ADJ (B) speech NOUN (I) synthesis NOUN (I)] and CCONJ (O) metrics NOUN (O) for ADP (O) generative PROPN (O) model NOUN (O) quality NOUN . (O) 
With ADP (O) regards VERB (O) to ADP (O) single-[speaker NOUN (B) speech NOUN (I) synthesis NOUN (I)] , [deep ADJ (B) learning NOUN (I)] has AUX (O) been AUX (O) used VERB (O) for ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) subcomponents NOUN , (O) including VERB (O) duration NOUN (O) prediction NOUN (O) (Zen PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) , (O) [fundamental ADJ (B) frequency NOUN (I) prediction NOUN (I)] (Ronanki PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) , (O) acoustic ADJ (O) modeling NOUN (O) (Zen PROPN (O) and CCONJ (O) Sak PROPN , (O) 2015 NUM) , (O) and CCONJ (O) more ADJ (O) recently ADV (O) autoregressive ADJ (O) sample NOUN - by ADP - sample NOUN (O) [audio NOUN (B) waveform PROPN (I) generation NOUN (I)] (e.g. ADV , (O) Oord PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM (O) ; Mehri PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) . (O) 
Our DET (O) contributions NOUN (O) build NOUN (O) upon SCONJ (O) recent ADJ (O) work NOUN (O) in ADP (O) entirely ADV (O) [neural NOUN (B) TTS PROPN (I) systems NOUN (I)] , including VERB (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) (Arik PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) , (O) [Tacotron PROPN (B)] (Wang PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) , (O) and CCONJ (O) Char2Wav PROPN (O) (Sotelo PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) . (O) 
While SCONJ (O) these DET (O) works VERB (O) focus NOUN (O) on ADP (O) building NOUN (O) single-[speaker NOUN (B) TTS PROPN (I) systems NOUN (I)] , our DET (O) paper NOUN (O) focuses VERB (O) on ADP (O) extending VERB (O) [neural NOUN (B) TTS PROPN (I) systems NOUN (I)] to PART (O) handle VERB (O) [multiple NOUN (B) speakers NOUN (I)] with ADP (O) [less ADJ (B) data NOUN (I)] per ADP (O) speaker NOUN . (O) 
Our DET (O) work NOUN (O) is AUX (O) not PART (O) the DET (O) first ADJ (O) to ADP (O) attempt NOUN (O) a NOUN (O) [multi ADJ - speaker ADJ (B) TTS PROPN (I) system NOUN (I)] . 
For ADP (O) instance NOUN , (O) in ADP (O) traditional ADJ (O) [HMM PROPN - based VERB (B) TTS PROPN (I) synthesis NOUN (I)] (e.g. ADV , (O) Yamagishi PROPN (O) et NOUN (O) al PROPN . , (O) 2009 NUM) , (O) an DET (O) [average NOUN (B) voice NOUN (I) model NOUN (I)] is AUX (O) trained VERB (O) using VERB (O) [multiple NOUN (B) speakers NOUN (I)] ’ PUNCT data NOUN , (O) which DET (O) is AUX (O) then ADV (O) adapted VERB (O) to ADP (O) [different ADJ (B) speakers NOUN (I)] . 
[DNN PROPN - based VERB (B) systems NOUN (I)] (e.g. ADV , (O) Yang PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) have AUX (O) also ADV (O) been AUX (O) used VERB (O) to ADP (O) build NOUN (O) [average NOUN (B) voice NOUN (I) models NOUN (I)] , with ADP (O) [i PROPN - vectors PROPN (B) representing VERB (I) speakers NOUN (I)] as SCONJ (O) additional ADJ (O) inputs VERB (O) and CCONJ (O) separate ADJ (O) [output NOUN (B) layers NOUN (I)] for ADP (O) each DET (O) [target NOUN (B) speaker NOUN (I)] . 
Similarly ADV , (O) Fan PROPN (O) et NOUN (O) al PROPN . (O) (2015 NUM) (O) uses VERB (O) a NOUN (O) shared VERB (O) hidden VERB (O) representation NOUN (O) among ADP (O) [different ADJ (B) speakers NOUN (I)] with ADP (O) speaker NOUN - dependent ADJ (O) [output NOUN (B) layers NOUN (I)] predicting VERB (O) [vocoder NOUN (B) parameters NOUN (I)] (e.g. ADV , (O) line NOUN (O) [spectral NOUN (B) pairs NOUN (I)] , aperiodicity NOUN (O) parameters NOUN (O) etc X .) . (O) 
For ADP (O) further NOUN (O) context NOUN , (O) Wu PROPN (O) et NOUN (O) al PROPN . (O) (2015 NUM) (O) empirically ADV (O) studies NOUN (O) [DNN PROPN - based VERB (B) multi ADJ - speaker ADJ (I) modeling VERB (I)] . 
More ADJ (O) recently ADV , (O) [speaker NOUN (B) adaptation NOUN (I)] has AUX (O) been AUX (O) tackled VERB (O) with ADP (O) [generative PROPN (B) adversarial ADJ (I) networks NOUN (I)] (GANs NOUN) (O) (Hsu PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) . (O) 
We PRON (O) instead ADV (O) use NOUN (O) [trainable NOUN (B) speaker NOUN (I) embeddings NOUN (I)] for ADP (O) [multi ADJ - speaker ADJ (B) TTS PROPN (I)] . 
The DET (O) approach NOUN (O) was AUX (O) investigated VERB (O) in ADP (O) [speech NOUN (B) recognition NOUN (I)] (Abdel PROPN - Hamid PROPN (O) and CCONJ (O) Jiang PROPN , (O) 2013 NUM) , (O) but CCONJ (O) is AUX (O) a NOUN (O) novel NOUN (O) technique NOUN (O) in ADP (O) [speech NOUN (B) synthesis NOUN (I)] . 
Unlike PROPN (O) prior ADJ (O) work NOUN (O) which DET (O) depends VERB (O) on ADP (O) fixed VERB (O) embeddings NOUN (O) (e.g. ADV (O) i PROPN - vectors PROPN) , (O) the DET (O) [speaker NOUN (B) embeddings NOUN (I)] used VERB (O) in ADP (O) this DET (O) work NOUN (O) are AUX (O) trained VERB (O) jointly ADV (O) with ADP (O) the DET (O) rest NOUN (O) of ADP (O) the DET (O) model NOUN (O) from ADP (O) scratch NOUN , (O) and CCONJ (O) thus ADV (O) can VERB (O) directly ADV (O) learn VERB (O) the DET (O) features VERB (O) relevant ADJ (O) to ADP (O) the DET (O) [speech NOUN (B) synthesis NOUN (I) task NOUN (I)] . 
In ADP (O) addition NOUN , (O) this DET (O) work NOUN (O) does AUX (O) not PART (O) rely VERB (O) on ADP (O) per-[speaker NOUN (B) output NOUN (I) layers NOUN (I)] or CCONJ (O) [average NOUN (B) voice NOUN (I)] modeling VERB , (O) which DET (O) leads VERB (O) to ADP (O) [higher ADJ - quality NOUN (B) synthesized VERB (I) samples NOUN (I)] and CCONJ (O) [lower ADJ (B) data NOUN (I)] requirements NOUN (O) (as SCONJ (O) there PRON (O) are AUX (O) fewer ADJ (O) unique ADJ (O) parameters VERB (O) per ADP (O) speaker NOUN (O) to ADP (O) learn VERB) . (O) 
In ADP (O) order NOUN (O) to ADP (O) evaluate VERB (O) the DET (O) distinctiveness NOUN (O) of ADP (O) the DET (O) generated VERB (O) voices NOUN (O) in ADP (O) an DET (O) automated VERB (O) way NOUN , (O) we PRON (O) propose NOUN (O) using VERB (O) the DET (O) classification NOUN (O) accuracy NOUN (O) of ADP (O) a NOUN (O) [speaker NOUN (B) discriminator NOUN (I)] . 
Similar PROPN (O) metrics NOUN (O) such ADJ (O) as SCONJ (O) an DET (O) “ PUNCT (O) Inception NOUN (O) score NOUN (O) ” PUNCT (O) have AUX (O) been AUX (O) used VERB (O) for ADP (O) quantitative NOUN (O) quality NOUN (O) evaluations NOUN (O) of ADP (O) GANs PROPN (O) for ADP (O) image NOUN (O) synthesis NOUN (O) (e.g. ADV , (O) Salimans PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) . (O) 
[Speaker PROPN (B) classification NOUN (I)] has AUX (O) been AUX (O) studied VERB (O) with ADP (O) both DET (O) traditional ADJ (O) [GMM PROPN - based VERB (B) methods NOUN (I)] (e.g. ADV , (O) Reynolds PROPN (O) et NOUN (O) al PROPN . , (O) 2000 NUM) (O) and CCONJ (O) more ADJ (O) recently ADV (O) with ADP (O) [deep ADJ (B) learning NOUN (I) approaches VERB (I)] (e.g. ADV , (O) Li PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) . (O) 

 Single PROPN - Speaker PROPN (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) 

 In ADP (O) this DET (O) section NOUN , (O) we PRON (O) present NOUN (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) a NOUN (O) [neural NOUN (B) TTS PROPN (I) system NOUN (I)] based VERB (O) on ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) (Arik PROPN (O) et NOUN (O) al PROPN . ,2017 PUNCT) . (O) 
We PRON (O) keep VERB (O) the DET (O) general NOUN (O) structure NOUN (O) of ADP (O) the DET (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) (Arik PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) , (O) as SCONJ (O) depicted VERB (O) in ADP (O) Fig PROPN . (O) 1 NUM (O) (the DET (O) corresponding VERB (O) training NOUN (O) pipeline NOUN (O) is AUX (O) depicted VERB (O) in ADP (O) Appendix PROPN (O) A NOUN) . (O) Our DET (O) primary NOUN (O) motivation NOUN (O) for ADP (O) presenting VERB (O) an DET (O) improved VERB (O) single-[speaker NOUN (B) model NOUN (I)] is AUX (O) to ADP (O) use NOUN (O) it PRON (O) as SCONJ (O) the DET (O) starting VERB (O) point NOUN (O) for ADP (O) a NOUN (O) [high ADJ - quality NOUN (B) multi ADJ - speaker ADJ (I) model NOUN (I)] . 
One NUM (O) major NOUN (O) difference NOUN (O) between ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) is AUX (O) the DET (O) separation NOUN (O) of ADP (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] and CCONJ (O) frequency NOUN (O) models NOUN . (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) has AUX (O) a NOUN (O) single ADJ (O) model NOUN (O) to ADP (O) jointly ADV (O) predict VERB (O) [phoneme NOUN (B) duration NOUN (I)] and CCONJ (O) frequency NOUN (O) profile NOUN (O) (voicedness NOUN (O) and CCONJ (O) [time NOUN - dependent ADJ (B) fundamental ADJ (I) frequency NOUN (I)] , F PROPN (O) 0 PUNCT) . (O) 
In ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) the DET (O) [phoneme NOUN (B) durations NOUN (I)] are AUX (O) predicted VERB (O) first ADJ (O) and CCONJ (O) then ADV (O) are AUX (O) used VERB (O) as SCONJ (O) inputs VERB (O) to ADP (O) the DET (O) frequency NOUN (O) model NOUN . (O) 
In ADP (O) the DET (O) subsequent ADJ (O) subsections NOUN , (O) we PRON (O) present NOUN (O) the DET (O) models NOUN (O) used VERB (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM . (O) 
All DET (O) models NOUN (O) are AUX (O) trained VERB (O) separately ADV (O) using VERB (O) the DET (O) [hyperparameters NOUN (B)] specified VERB (O) in ADP (O) Appendix PROPN (O) B. PROPN (O) 
We PRON (O) will VERB (O) provide VERB (O) a NOUN (O) quantitative NOUN (O) comparison NOUN (O) of ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) and CCONJ (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) in ADP (O) Section NOUN (O) 5.1 NUM . (O) 

 [Segmentation NOUN (B) model NOUN (I)] 

 Estimation NOUN (O) of ADP (O) [phoneme NOUN (B) locations NOUN (I)] is AUX (O) treated VERB (O) as SCONJ (O) an DET (O) [unsupervised ADJ (B) learning NOUN (I)] problem NOUN (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) similar ADJ (O) to ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) 
The DET (O) [segmentation NOUN (B) model NOUN (I)] is AUX (O) convolutional ADJ - recurrent NOUN (O) architecture NOUN (O) with ADP (O) [connectionist NOUN (B) temporal NOUN (I) classification NOUN (I)] (CTC PROPN) (O) loss NOUN (O) (Graves NOUN (O) et NOUN (O) al PROPN . , (O) 2006 NUM) (O) applied VERB (O) to ADP (O) classify NOUN (O) [phoneme NOUN (B) pairs NOUN (I)] , which DET (O) are AUX (O) then ADV (O) used VERB (O) to ADP (O) extract NOUN (O) the DET (O) boundaries NOUN (O) between ADP (O) them PRON . (O) 
The DET (O) major NOUN (O) architecture NOUN (O) changes VERB (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) are AUX (O) the DET (O) addition NOUN (O) of ADP (O) [batch NOUN (B) normalization NOUN (I)] and CCONJ (O) [residual ADJ (B) connections NOUN (I)] in ADP (O) the DET (O) [convolutional NOUN (B) layers NOUN (I)] . 
Specifically ADV , (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM ’s PART (O) [segmentation NOUN (B) model NOUN (I)] computes VERB (O) the DET (O) output NOUN (O) of ADP (O) each DET (O) layer NOUN (O) as SCONJ (O)     h NOUN (O) (l NOUN) (O) = [relu NOUN (B)] W NOUN (O) (l NOUN) (O) ⇤ PROPN (O) h NOUN (O) (l NOUN (O) 1 NUM) (O) + b NOUN (O) (l NOUN) , (O) (1 NUM) (O)     where ADV (O) h NOUN (O) (l NOUN) (O) is AUX (O) the DET (O) output NOUN (O) of ADP (O) the DET (O) l PROPN - th NOUN (O) layer NOUN , (O) W NOUN (O) (l NOUN) (O) is AUX (O) the DET (O) convolution NOUN (O) filterbank NOUN , (O) b NOUN (O) (l NOUN) (O) is AUX (O) the DET (O) bias NOUN (O) [vector NOUN (B)] , and CCONJ (O) ⇤ NOUN (O) is AUX (O) the DET (O) convolution NOUN (O) operator NOUN . (O) 
In ADP (O) contrast NOUN , (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM ’s PART (O) [segmentation NOUN (B) model NOUN (I) layers NOUN (I)] instead ADV (O) compute NOUN (O)      h NOUN (O) (l NOUN) (O) = [relu NOUN (B)] h PROPN (O) (l NOUN (O) 1 NUM) (O) + BN NOUN (O) W NOUN (O) (l NOUN) (O) ⇤ PROPN (O) h NOUN (O) (l NOUN (O) 1 NUM) , (O) (2 X) (O)     where ADV (O) BN NOUN (O) is AUX (O) [batch NOUN (B) normalization NOUN (I)] (Ioffe PROPN (O) and CCONJ (O) Szegedy PROPN , (O) 2015 NUM) . (O) 
In ADP (O) addition NOUN , (O) we PRON (O) find VERB (O) that SCONJ (O) the DET (O) [segmentation NOUN (B) model NOUN (I)] often ADV (O) makes VERB (O) mistakes NOUN (O) for ADP (O) boundaries NOUN (O) between ADP (O) silence NOUN (O) [phonemes NOUN (B)] and CCONJ (O) other ADJ (O) [phonemes NOUN (B)] , which DET (O) can VERB (O) significantly ADV (O) reduce VERB (O) segmentation NOUN (O) accuracy NOUN (O) on ADP (O) some DET (O) datasets VERB . (O) 
We PRON (O) introduce VERB (O) a NOUN (O) small ADJ (O) [post NOUN - processing ADJ (B) step NOUN (I)] to PART (O) correct ADJ (O) these DET (O) mistakes NOUN (O) : whenever ADV (O) the DET (O) [segmentation NOUN (B) model NOUN (I)] decodes VERB (O) a NOUN (O) silence NOUN (O) boundary ADJ , (O) we PRON (O) adjust NOUN (O) the DET (O) location NOUN (O) of ADP (O) the DET (O) boundary ADJ (O) with ADP (O) a NOUN (O) silence NOUN (O) detection NOUN (O) heuristic ADJ . (O) 

 We PRON (O) compute NOUN (O) the DET (O) smoothed VERB (O) normalized ADJ (O) [audio NOUN (B)] power NOUN (O) as SCONJ (O) p(n NOUN) (O) = (x(n PROPN) (O) 2 NUM (O) /x PUNCT (O) max NOUN (O) 2 X) (O) ⇤ PROPN (O) g(n PROPN) , (O) where ADV (O) x(n PROPN) (O) is AUX (O) the DET (O) [audio NOUN (B) signal NOUN (I)] , g(n PROPN) (O) is AUX (O) the DET (O) impulse PROPN (O) response NOUN (O) of ADP (O) a NOUN (O) [Gaussian PROPN (B) filter NOUN (I)] , x SYM (O) max NOUN (O) is AUX (O) the DET (O) maximum NOUN (O) value NOUN (O) of ADP (O) x(n PROPN) (O) and CCONJ (O) ⇤ NOUN (O) is AUX (O) one NUM - dimensional ADJ (O) convolution NOUN (O) operation NOUN . (O) We PRON (O) assign NOUN (O) the DET (O) silence NOUN (O) [phoneme NOUN (B) boundaries NOUN (I)] when ADV (O) p(n NOUN) (O) exceeds VERB (O) a NOUN (O) fixed VERB (O) 
threshold NOUN . (O) The DET (O) optimal PROPN (O) parameter NOUN (O) values NOUN (O) for ADP (O) the DET (O) [Gaussian PROPN (B) filter NOUN (I)] and CCONJ (O) the DET (O) threshold NOUN (O) depend VERB (O) on ADP (O) the DET (O) dataset NOUN (O) and CCONJ (O) [audio NOUN (B) sampling NOUN (I) rate NOUN (I)] . 

 Duration NOUN (O) Model NOUN (O) 

 In ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) instead ADV (O) of ADP (O) predicting VERB (O) a NOUN (O) continuous ADJ - valued VERB (O) duration NOUN , (O) we PRON (O) formulate VERB (O) duration NOUN (O) prediction NOUN (O) as SCONJ (O) a NOUN (O) sequence NOUN (O) labeling NOUN (O) problem NOUN . (O) 
We PRON (O) discretize VERB (O) the DET (O) [phoneme NOUN (B) duration NOUN (I)] into ADP (O) log NOUN - scaled VERB (O) buckets NOUN , (O) and CCONJ (O) assign NOUN (O) each DET (O) input NOUN (O) [phoneme NOUN (B)] to PART (O) the DET (O) bucket NOUN (O) label NOUN (O) corresponding VERB (O) to ADP (O) its DET (O) duration NOUN . (O) 
We PRON (O) model NOUN (O) the DET (O) sequence NOUN (O) by ADP (O) a NOUN (O) [conditional ADJ (B) random ADJ (I) field NOUN (I)] ([CRF NOUN (B)]) with ADP (O) pairwise NOUN (O) potentials NOUN (O) at ADP (O) [output NOUN (B) layer NOUN (I)] (Lample PROPN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) . (O) 
During ADP (O) inference NOUN , (O) we PRON (O) decode NOUN (O) discretized ADJ (O) durations NOUN (O) from ADP (O) the DET (O) [CRF NOUN (B)] using VERB (O) the DET (O) [Viterbi PROPN (B) forward ADV - backward NOUN (I) algorithm PROPN (I)] . 
We PRON (O) find VERB (O) that DET (O) quantizing NOUN (O) the DET (O) duration NOUN (O) prediction NOUN (O) and CCONJ (O) introducing VERB (O) the DET (O) pairwise NOUN (O) dependence NOUN (O) implied VERB (O) by ADP (O) the DET (O) [CRF NOUN (B)] improves VERB (O) synthesis NOUN (O) quality NOUN . (O) 

 Frequency NOUN (O) Model NOUN (O) 

 After ADP (O) decoding VERB (O) from ADP (O) the DET (O) duration NOUN (O) model NOUN , (O) the DET (O) predicted VERB (O) [phoneme NOUN (B) durations NOUN (I)] are AUX (O) upsampled ADJ (O) from ADP (O) a NOUN (O) per-[phoneme PROPN (B) input NOUN (I) features VERB (I)] to PART (O) a NOUN (O) per ADP - frame NOUN (O) input NOUN (O) for ADP (O) the DET (O) frequency NOUN (O) model NOUN . (O) 
[Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) frequency NOUN (O) model NOUN (O) consists VERB (O) of ADP (O) multiple NOUN (O) layers NOUN (O) : firstly ADV , (O) [bidirectional NOUN (B) gated VERB (I) recurrent ADJ (I) unit NOUN (I) (GRU PROPN) (I) layers NOUN (I)] (Cho PROPN (O) et NOUN (O) al PROPN . ,2014 PUNCT) (O) generate NOUN (O) [hidden VERB (B) states NOUN (I)] from ADP (O) the DET (O) [input NOUN (B) features VERB (I)] . 
From ADP (O) these DET (O) [hidden VERB (B) states NOUN (I)] , an DET (O) affine NOUN (O) projection NOUN (O) followed VERB (O) by ADP (O) a NOUN (O) [sigmoid NOUN (B) nonlinearity NOUN (I)] produces VERB (O) the DET (O) probability NOUN (O) that SCONJ (O) each DET (O) frame NOUN (O) is AUX (O) voiced VERB . (O) 
[Hidden PROPN (B) states NOUN (I)] are AUX (O) also ADV (O) used VERB (O) to ADP (O) make VERB (O) two NUM (O) separate ADJ (O) normalized ADJ (O) F PROPN (O) 0 PUNCT (O) predictions NOUN . (O) 
The DET (O) first ADJ (O) prediction NOUN , (O) f X (O) [GRU PROPN (B)] , is AUX (O) made VERB (O) with ADP (O) a NOUN (O) single ADJ - layer NOUN (O) [bidirectional ADJ (B) GRU PROPN (I)] followed VERB (O) by ADP (O) an DET (O) affine NOUN (O) projection NOUN . (O) 
The DET (O) second NOUN (O) prediction NOUN , (O) f X (O) conv NOUN , (O) is AUX (O) made VERB (O) by ADP (O) adding VERB (O) up NOUN (O) the DET (O) contributions NOUN (O) of ADP (O) multiple NOUN (O) convolutions NOUN (O) with ADP (O) varying NOUN (O) convolution NOUN (O) widths VERB (O) and CCONJ (O) a NOUN (O) single ADJ (O) output NOUN (O) channel PROPN . (O) 
Finally ADV , (O) the DET (O) [hidden VERB (B) state NOUN (I)] is AUX (O) used VERB (O) with ADP (O) an DET (O) affine NOUN (O)     projection NOUN (O) and CCONJ (O) a NOUN (O) [sigmoid NOUN (B) nonlinearity NOUN (I)] to PART (O) predict VERB (O) a NOUN (O) mixture NOUN (O) ratio NOUN (O) ! , (O) which DET (O) is AUX (O) used VERB (O) to ADP (O) weigh NOUN (O) the DET (O) two NUM (O) normalized ADJ (O) [frequency NOUN (B) predictions NOUN (I)] and CCONJ (O) combine VERB (O) them PRON (O) into ADP (O) 
The DET (O) normalized ADJ (O) prediction NOUN (O) f X (O) is AUX (O) then ADV (O) converted VERB (O) to ADP (O) the DET (O) true ADJ (O) frequency NOUN (O) F0 NOUN (O) prediction NOUN (O) via ADP (O) where ADV (O) μ NOUN (O) F0 NOUN (O) and CCONJ (O) F0 NOUN (O) are AUX , (O) respectively ADV , (O) the DET (O) mean VERB (O) and CCONJ (O) standard NOUN (O) deviation NOUN (O) of ADP (O) F PROPN (O) 0 PUNCT (O) for ADP (O) the DET (O) speaker NOUN (O) the DET (O) model NOUN (O) is AUX (O) trained VERB (O) on ADV . (O) We PRON (O) find VERB (O) that DET (O) predicting VERB (O) F PROPN (O) 0 PUNCT (O) with ADP (O) a NOUN (O) mixture NOUN (O) of ADP (O) convolutions NOUN (O) and CCONJ (O) a NOUN (O) [recurrent NOUN (B) layer NOUN (I)] 
performs VERB (O) better ADJ (O) than SCONJ (O) predicting VERB (O) with ADP (O) either CCONJ (O) one NUM (O) individually ADV . (O) 
We PRON (O) attribute NOUN (O) this DET (O) to ADP (O) the DET (O) hypothesis NOUN (O) that SCONJ (O) including VERB (O) the DET (O) wide ADJ (O) convolutions NOUN (O) reduces VERB (O) the DET (O) burden NOUN (O) for ADP (O) the DET (O) [recurrent NOUN (B) layers NOUN (I)] to PART (O) maintain VERB (O) state NOUN (O) over ADP (O) a NOUN (O) large ADJ (O) number NOUN (O) of ADP (O) input NOUN (O) frames NOUN , (O) while SCONJ (O) processing NOUN (O) the DET (O) entire ADJ (O) context NOUN (O) information NOUN (O) efficiently ADV . (O) 

 Each DET (O) frame NOUN (O) is AUX (O) ensured VERB (O) to ADP (O) be AUX (O) 10 NUM (O) milliseconds VERB . (O) For ADP (O) example NOUN , (O) if SCONJ (O) a NOUN (O) [phoneme NOUN (B)] lasts VERB (O) 20 NUM (O) milliseconds NOUN , (O) the DET (O) [input NOUN (B) features VERB (I)] corresponding VERB (O) to ADP (O) that SCONJ (O) [phoneme NOUN (B)] will VERB (O) be AUX (O) repeated VERB (O) in ADP (O) 2 NUM (O) frames NOUN . (O) If SCONJ (O) it PRON (O) lasts VERB (O) less ADJ (O) than SCONJ (O) 10 NUM (O) milliseconds NOUN , (O) it PRON (O) is AUX (O) extend VERB (O) to ADP (O) a NOUN (O) single ADJ (O) frame NOUN . (O) 

 [Vocal PROPN (B) Model NOUN (I)] 

 The DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) [vocal NOUN (B) model NOUN (I)] is AUX (O) based VERB (O) on ADP (O) a NOUN (O) [WaveNet PROPN (B) architecture NOUN (I)] (Oord NOUN (O) et NOUN (O) al PROPN . , (O) 2016 NUM) (O) with ADP (O) a NOUN (O) two NUM - layer NOUN (O) [bidirectional ADJ (B) QRNN PROPN (I)] (Bradbury NOUN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) (O) conditioning NOUN (O) network NOUN , (O) similar ADJ (O) to ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) However ADV , (O) we PRON (O) remove VERB (O) the DET (O) 1 NUM (O) ⇥ PROPN (O) 1 NUM (O) convolution NOUN (O) between ADP (O) the DET (O) gated VERB (O) [tanh NOUN (B) nonlinearity NOUN (I)] and CCONJ (O) the DET (O) [residual ADJ (B) connection NOUN (I)] . In ADP (O) addition NOUN , (O) we PRON (O) use NOUN (O) the DET (O) same ADJ (O) conditioner NOUN (O) bias NOUN (O) for ADP (O) every DET (O) layer NOUN (O) of ADP (O) the DET (O) [WaveNet PROPN (B)] , instead ADV (O) of ADP (O)     generating NOUN (O) a NOUN (O) separate ADJ (O) bias NOUN (O) for ADP (O) every DET (O) layer NOUN (O) as SCONJ (O) was AUX (O) done VERB (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) 

 We PRON (O) find VERB (O) that SCONJ (O) these DET (O) changes VERB (O) reduce VERB (O) model NOUN (O) size NOUN (O) by ADP (O) a NOUN (O) factor NOUN (O) of ADP (O) ⇠ PROPN (O) 7 NUM (O) and CCONJ (O) speed NOUN (O) up NOUN (O) inference NOUN (O) by ADP (O) ⇠ PROPN (O) 25 NUM (O) % , (O) while SCONJ (O) yielding VERB (O) no DET (O) perceptual NOUN (O) change NOUN (O) in ADP (O) quality NOUN . (O) However ADV , (O) we PRON (O) do AUX (O) not PART (O) focus NOUN (O) on ADP (O) demonstrating VERB (O) these DET (O) claims VERB (O) in ADP (O) this DET (O) paper NOUN . (O) 

 [Multi PROPN - Speaker PROPN (B) Models NOUN (I)] with ADP (O) [Trainable NOUN (B) Speaker PROPN (I) Embeddings NOUN (I)] 

 In ADP (O) order NOUN (O) to ADP (O) [synthesize VERB (B) speech NOUN (I)] from ADP (O) [multiple NOUN (B) speakers NOUN (I)] , we PRON (O) augment NOUN (O) each DET (O) of ADP (O) our DET (O) models NOUN (O) with ADP (O) a NOUN (O) single ADJ (O) [low ADJ - dimensional ADJ (B) speaker NOUN (I)] embedding VERB (O) [vector NOUN (B)] per ADP (O) speaker NOUN . (O) 
Unlike PROPN (O) previous ADJ (O) work NOUN , (O) our DET (O) approach NOUN (O) does AUX (O) not PART (O) rely VERB (O) on ADP (O) per-[speaker NOUN (B) weight NOUN (I)] matrices NOUN (O) or CCONJ (O) layers NOUN . (O) 
Speaker PROPN - dependent ADJ (O) parameters NOUN (O) are AUX (O) stored VERB (O) in ADP (O) a NOUN (O) very ADV (O) [low ADJ - dimensional ADJ (B) vector NOUN (I)] and CCONJ (O) thus ADV (O) there PRON (O) is AUX (O) near ADV - complete ADJ (O) weight NOUN (O) sharing NOUN (O) between ADP (O) speakers NOUN . (O) 
We PRON (O) use NOUN (O) [speaker NOUN (B) embeddings NOUN (I)] to PART (O) produce NOUN (O) [recurrent NOUN (B) neural NOUN (I) network NOUN (I)] ([RNN PROPN (B)]) initial ADJ (O) states NOUN , (O) nonlinearity NOUN (O) biases NOUN , (O) and CCONJ (O) multiplicative NOUN (O) gating VERB (O) factors NOUN , (O) used VERB (O) throughout ADP (O) the DET (O) networks NOUN . (O) 
[Speaker PROPN (B) embeddings NOUN (I)] are AUX (O) initialized VERB (O) randomly ADV (O) with ADP (O) a NOUN (O) uniform NOUN (O) distribution NOUN (O) over ADP (O) (0.1 NUM , (O) 0.1 NUM) (O) and CCONJ (O) trained VERB (O) jointly ADV (O) via ADP (O) backpropagation NOUN (O) ; each DET (O) model NOUN (O) has AUX (O) its DET (O) own ADJ (O) set NOUN (O) of ADP (O) [speaker NOUN (B) embeddings NOUN (I)] . 
To PART (O) encourage VERB (O) each DET (O) speaker NOUN ’s PUNCT (O) [unique ADJ (B) voice NOUN (I)] signature NOUN (O) to ADP (O) influence NOUN (O) the DET (O) model NOUN , (O) we PRON (O) incorporate NOUN (O) the DET (O) [speaker NOUN (B) embeddings NOUN (I)] into ADP (O) multiple NOUN (O) portions NOUN (O) of ADP (O) the DET (O) model NOUN . (O) 
Empirically ADV , (O) we PRON (O) find VERB (O) that SCONJ (O) simply ADV (O) providing VERB (O) the DET (O) [speaker NOUN (B) embeddings NOUN (I)] to PART (O) the DET (O) input NOUN (O) layers NOUN (O) does AUX (O) not PART (O) work NOUN (O) as SCONJ (O) well INTJ (O) for ADP (O) any DET (O) of ADP (O) the DET (O) presented VERB (O) models NOUN (O) besides SCONJ (O) the DET (O) [vocal NOUN (B) model NOUN (I)] , possibly ADV (O) due ADJ (O) to ADP (O) the DET (O) high ADJ (O) degree NOUN (O) of ADP (O) [residual ADJ (B) connections NOUN (I)] present ADJ (O) in ADP (O) the DET (O) [WaveNet PROPN (B)] and CCONJ (O) due ADJ (O) to ADP (O) the DET (O) difficulty NOUN (O) of ADP (O) learning NOUN (O) [high ADJ - quality NOUN (B) speaker NOUN (I) embeddings NOUN (I)] . 
We PRON (O) observed VERB (O) that SCONJ (O) several ADJ (O) patterns NOUN (O) tend NOUN (O) to ADP (O) yield NOUN (O) high ADJ (O) performance NOUN (O) : 
• X (O) Site-[Specific NOUN (B) Speaker PROPN (I) Embeddings NOUN (I)] : For ADP (O) every DET (O) use NOUN (O) site NOUN (O) in ADP (O) the DET (O) [model NOUN (B) architecture NOUN (I)] , transform NOUN (O) the DET (O) shared VERB (O) speaker NOUN (O) embedding NOUN (O) to ADP (O) the DET (O) appropriate ADJ (O) dimension NOUN (O) and CCONJ (O) form NOUN (O) through ADP (O) an DET (O) affine NOUN (O) projection NOUN (O) and CCONJ (O) a NOUN (O) nonlinearity NOUN . (O) 
• X (O) Recurrent NOUN (O) Initialization NOUN (O) : Initialize VERB (O) [recurrent NOUN (B) layer NOUN (I) hidden PROPN (I) states VERB (I)] with ADP (O) site-[specific PUNCT (B) speaker NOUN (I) embeddings NOUN (I)] . 
• X (O) Input NOUN (O) Augmentation NOUN (O) : Concatenate NOUN (O) a NOUN (O) site-[specific PUNCT (B) speaker NOUN (I)] embedding VERB (O) to ADP (O) the DET (O) input NOUN (O) at ADP (O) every DET (O) timestep NOUN (O) of ADP (O) a NOUN (O) [recurrent NOUN (B) layer NOUN (I)] . 
• X (O) Feature NOUN (O) Gating NOUN (O) : Multiply PROPN (O) layer NOUN (O) activations VERB (O) elementwise VERB (O) with ADP (O) a NOUN (O) site-[specific PUNCT (B) speaker NOUN (I)] embedding VERB (O) to ADP (O) render NOUN (O) adaptable ADJ (O) information NOUN (O) flow NOUN . (O) 

 We PRON (O) hypothesize NOUN (O) that SCONJ (O) feature NOUN (O) gating VERB (O) lets VERB (O) the DET (O) model NOUN (O) learn VERB (O) the DET (O) union NOUN (O) of ADP (O) all DET (O) [necessary ADJ (B) features VERB (I)] while SCONJ (O) allowing VERB (O) [speaker NOUN (B) embeddings NOUN (I)] to PART (O) determine NOUN (O) what PRON (O) features VERB (O) are AUX (O) used VERB (O) for ADP (O) each DET (O) speaker NOUN (O) and CCONJ (O) how ADV (O) much ADJ (O) influence NOUN (O) they PRON (O) will VERB (O) have AUX (O) on ADP (O) the DET (O) activations VERB . (O) 

 Next ADV , (O) we PRON (O) describe VERB (O) how ADV (O) [speaker NOUN (B) embeddings NOUN (I)] are AUX (O) used VERB (O) in ADP (O) each DET (O) architecture NOUN . (O) 

 [Multi PROPN - Speaker PROPN (B) Deep ADV (I) Voice PROPN (I)] 2 NUM (O) 

 The DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) models NOUN (O) have AUX (O) [separate ADJ (B) speaker NOUN (I) embeddings NOUN (I)] for ADP (O) each DET (O) model NOUN . (O) 
Yet ADV , (O) they PRON (O) can VERB (O) be AUX (O) viewed VERB (O) softsign VERB (O) BN NOUN (O) + [ReLu PROPN (B)] as SCONJ (O) chunks VERB (O) of ADP (O) a NOUN (O) [larger ADJ (B) speaker NOUN (I) embedding VERB (I)] , which DET (O) are AUX (O) trained VERB (O) independently ADV . (O) 

 [Segmentation NOUN (B) Model NOUN (I)] 

 In ADP (O) [multi ADJ - speaker ADJ (B) segmentation NOUN (I) model NOUN (I)] , we PRON (O) use NOUN (O) feature NOUN (O) gating VERB (O) in ADP (O) the DET (O) [residual ADJ (B) connections NOUN (I)] of ADP (O) the DET (O) convolution NOUN (O) layers NOUN . (O) Instead ADV (O) of ADP (O) Eq PROPN . , (O) we PRON (O) multiply NOUN (O) the DET (O) batch NOUN - normalized ADJ (O) activations VERB (O) by ADP (O) a NOUN (O) site-[specific PUNCT (B) speaker NOUN (I)] embedding VERB (O) : 
where ADV (O) g NOUN (O) s NOUN (O) is AUX (O) a NOUN (O) site-[specific PUNCT (B) speaker NOUN (I)] embedding VERB . (O) The DET (O) same ADJ (O) site NOUN - specific ADJ (O) embedding NOUN (O) is AUX (O) shared VERB (O) for ADP (O) all DET (O) the DET (O) [convolutional NOUN (B) layers NOUN (I)] . 
In ADP (O) addition NOUN , (O) we PRON (O) initialize VERB (O) each DET (O) of ADP (O) the DET (O) [recurrent NOUN (B) layers NOUN (I)] with ADP (O) a NOUN (O) second ADJ (O) site NOUN (O) specific ADJ (O) embedding NOUN . (O) 
Similarly ADV , (O) each DET (O) layer NOUN (O) shares NOUN (O) the DET (O) same ADJ (O) site NOUN - specific ADJ (O) embedding NOUN , (O) rather ADV (O) than SCONJ (O) having VERB (O) a NOUN (O) separate ADJ (O) embedding NOUN (O) per ADP (O) layer NOUN . (O) 

 Duration NOUN (O) Model NOUN (O) 

 The DET (O) [multi ADJ - speaker ADJ (B) duration NOUN (I) model NOUN (I)] uses VERB (O) speaker NOUN - dependent ADJ (O) recurrent NOUN (O) initialization NOUN (O) and CCONJ (O) input NOUN (O) augmentation NOUN . (O) A NOUN (O) site NOUN - specific ADJ (O) embedding NOUN (O) is AUX (O) used VERB (O) to ADP (O) initialize VERB (O) [RNN PROPN (B)] hidden VERB (O) states NOUN , (O) and CCONJ (O) another DET (O) site NOUN - specific ADJ (O) embedding NOUN (O) is AUX (O) provided VERB (O) as SCONJ (O) input NOUN (O) to ADP (O) the DET (O) first ADJ (O) [RNN PROPN (B) layer NOUN (I)] by ADP (O) concatenating VERB (O) it PRON (O) to ADP (O) the DET (O) [feature NOUN (B) vectors NOUN (I)] . 

 Frequency NOUN (O) Model NOUN (O) 

 The DET (O) [multi ADJ - speaker ADJ (B) frequency NOUN (I) model NOUN (I)] uses VERB (O) recurrent NOUN (O) initialization NOUN , (O) which DET (O) initializes VERB (O) the DET (O) [recurrent NOUN (B) layers NOUN (I)] (except SCONJ (O) for ADP (O) the DET (O) recurrent NOUN (O) [output NOUN (B) layer NOUN (I)]) with ADP (O) a NOUN (O) single ADJ (O) site-[specific PUNCT (B) speaker NOUN - embedding VERB (I)] . 
As SCONJ (O) described VERB (O) in ADP (O) Section NOUN (O) 3.3 NUM , (O) the DET (O) recurrent NOUN (O) and CCONJ (O) [convolutional NOUN (B) output NOUN (I) layers NOUN (I)] in ADP (O) the DET (O) single-[speaker NOUN (B) frequency NOUN (I)] model NOUN (O) predict VERB (O) a NOUN (O) normalized ADJ (O) frequency NOUN , (O) which DET (O) is AUX (O) then ADV (O) converted VERB (O) into ADP (O) the DET (O) true ADJ (O) F0 NOUN (O) by ADP (O) a NOUN (O) fixed VERB (O) linear NOUN (O) transformation NOUN . (O) 
The DET (O) linear NOUN (O) transformation NOUN (O) depends VERB (O) on ADP (O) the DET (O) mean VERB (O) and CCONJ (O) standard NOUN (O) deviation NOUN (O) of ADP (O) observed VERB (O) F PROPN (O) 0 PUNCT (O) for ADP (O) the DET (O) speaker NOUN . (O) 
These DET (O) values NOUN (O) vary VERB (O) greatly ADV (O) between ADP (O) speakers NOUN (O) : [male NOUN (B) speakers NOUN (I)] , for ADP (O) instance NOUN , (O) tend NOUN (O) to ADP (O) have AUX (O) a NOUN (O) much ADJ (O) lower ADJ (O) mean VERB (O) F PROPN (O) 0 PUNCT . (O) 
To NOUN (O) better ADJ (O) adapt NOUN (O) to ADP (O) these DET (O) variations NOUN , (O) we PRON (O) make VERB (O) the DET (O) mean VERB (O) and CCONJ (O) standard NOUN (O) deviation NOUN (O) trainable NOUN (O) model NOUN (O) parameters NOUN (O) and CCONJ (O) multiply NOUN (O) them PRON (O) by ADP (O) scaling VERB (O) terms NOUN (O) which DET (O) depend VERB (O) on ADP (O) the DET (O) [speaker NOUN (B) embeddings NOUN (I)] . 
Specifically ADV , (O) instead ADV (O) of ADP (O) Eq PROPN . , (O) we PRON (O) compute NOUN (O) the DET (O) F PROPN (O) 0 PUNCT (O) prediction NOUN (O) as SCONJ (O) 
where ADV (O) g NOUN (O) f NOUN (O) is AUX (O) a NOUN (O) site-[specific PUNCT (B) speaker NOUN (I) embedding VERB (I)] , μ NOUN (O) F PROPN (O) 0 PUNCT (O) and CCONJ (O) F PROPN (O) 0 PUNCT (O) are AUX (O) trainable NOUN (O) scalar NOUN (O) parameters NOUN (O) initialized VERB (O) to ADP (O) the DET (O) F PROPN (O) 0 PUNCT (O) mean VERB (O) and CCONJ (O) standard NOUN (O) deviation NOUN (O) on ADP (O) the DET (O) dataset NOUN , (O) and CCONJ (O) V NOUN (O) μ NOUN (O) and CCONJ (O) V NOUN (O) are AUX (O) trainable NOUN (O) parameter NOUN (O) [vectors NOUN (B)] . 

 [Vocal PROPN (B) Model NOUN (I)] 

 The DET (O) [multi ADJ - speaker ADJ (B) vocal NOUN (I) model NOUN (I)] uses VERB (O) only ADV (O) input NOUN (O) augmentation NOUN , (O) with ADP (O) the DET (O) site-[specific PUNCT (B) speaker NOUN (I) embedding VERB (I)] concatenated VERB (O) onto ADP (O) each DET (O) input NOUN (O) frame NOUN (O) of ADP (O) the DET (O) conditioner NOUN . (O) 
This DET (O) differs VERB (O) from ADP (O) the DET (O) global ADJ (O) conditioning NOUN (O) suggested VERB (O) in ADP (O) Oord NOUN (O) et NOUN (O) al PROPN . (O) (2016 NUM) (O) and CCONJ (O) allows VERB (O) the DET (O) speaker NOUN (O) embedding NOUN (O) to ADP (O) influence NOUN (O) the DET (O) local ADJ (O) conditioning NOUN (O) network NOUN (O) as SCONJ (O) well INTJ . (O) 
Without ADP (O) [speaker NOUN (B) embeddings NOUN (I)] , the DET (O) [vocal NOUN (B) model NOUN (I)] is AUX (O) still ADV (O) able ADJ (O) to ADP (O) generate NOUN (O) somewhat ADV (O) distinct ADJ - sounding NOUN (O) voices NOUN (O) because SCONJ (O) of ADP (O) the DET (O) [disctinctive NOUN (B) features VERB (I)] provided VERB (O) by ADP (O) the DET (O) frequency NOUN (O) and CCONJ (O) duration NOUN (O) models NOUN . (O) 
Yet ADV , (O) having VERB (O) [speaker NOUN (B) embeddings NOUN (I)] in ADP (O) the DET (O) [vocal NOUN (B) model NOUN (I)] increases VERB (O) the DET (O) [audio NOUN (B) quality NOUN (I)] . 
We PRON (O) indeed ADV (O) observe VERB (O) that SCONJ (O) the DET (O) embeddings NOUN (O) converge VERB (O) to ADP (O) a NOUN (O) meaningful ADJ (O) latent NOUN (O) space NOUN . (O) 

 [Multi PROPN - Speaker PROPN (B) Tacotron PROPN (I)] 

 In ADP (O) addition NOUN (O) to ADP (O) extending VERB (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) with ADP (O) [speaker NOUN (B) embeddings NOUN (I)] , we PRON (O) also ADV (O) extend VERB (O) [Tacotron PROPN (B)] (Wang PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) , (O) a NOUN (O) [sequence NOUN - to ADP - sequence NOUN (B) character NOUN - to ADP - waveform PROPN (I) model NOUN (I)] . 
When ADV (O) training NOUN (O) [multi ADJ - speaker ADJ (B) Tacotron PROPN (I) variants VERB (I)] , we PRON (O) find VERB (O) that DET (O) model NOUN (O) performance NOUN (O) is AUX (O) highly ADV (O) dependent ADJ (O) on ADP (O) model NOUN (O) [hyperparameters NOUN (B)] , and CCONJ (O) that SCONJ (O) some DET (O) models NOUN (O) often ADV (O) fail VERB (O) to ADP (O) learn VERB (O) [attention NOUN (B) mechanisms NOUN (I)] for ADP (O) a NOUN (O) small ADJ (O) subset NOUN (O) of ADP (O) speakers NOUN . (O) 
We PRON (O) also ADV (O) find VERB (O) that SCONJ (O) if SCONJ (O) the DET (O) [speech NOUN (B)] in ADP (O) each DET (O) [audio NOUN (B) clip NOUN (I)] does AUX (O) not PART (O) start VERB (O) at ADP (O) the DET (O) same ADJ (O) timestep NOUN , (O) the DET (O) models NOUN (O) are AUX (O) much ADJ (O) less ADJ (O) likely ADV (O) to ADP (O) converge VERB (O) to ADP (O) a NOUN (O) meaningful ADJ (O) attention NOUN (O) curve NOUN (O) and CCONJ (O) recognizable ADJ (O) [speech NOUN (B)] ; thus ADV , (O) we PRON (O) trim VERB (O) all DET (O) initial NOUN (O) and CCONJ (O) final ADJ (O) silence NOUN (O) in ADP (O) each DET (O) [audio NOUN (B) clip NOUN (I)] . 
Due PROPN (O) to ADP (O) the DET (O) sensitivity NOUN (O) of ADP (O) the DET (O) model NOUN (O) to ADP (O) [hyperparameters NOUN (B)] and CCONJ (O) [data NOUN (B) preprocessing NOUN (I)] , we PRON (O) believe VERB (O) that SCONJ (O) additional ADJ (O) tuning NOUN (O) may VERB (O) be AUX (O) necessary ADJ (O) to ADP (O) obtain VERB (O) maximal NOUN (O) quality NOUN . (O) 
Thus ADV , (O) our DET (O) work NOUN (O) focuses VERB (O) on ADP (O) demonstrating VERB (O) that SCONJ (O) [Tacotron PROPN (B)] , like SCONJ (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) is AUX (O) capable ADJ (O) of ADP (O) handling VERB (O) [multiple NOUN (B) speakers NOUN (I)] through ADP (O) [speaker NOUN (B) embeddings NOUN (I)] , rather ADV (O) than SCONJ (O) comparing VERB (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) two NUM (O) architectures NOUN . (O) 

 [Character NOUN - to ADP - Spectrogram PROPN (B) Model NOUN (I)] 

 The DET (O) [Tacotron PROPN (B) character NOUN - to ADP - spectrogram PROPN (I) architecture NOUN (I)] consists VERB (O) of ADP (O) a NOUN (O) convolution NOUN - bank NOUN - highway-[GRU NOUN (B)] ([CBHG PROPN (B)]) [encoder NOUN (B)] , an DET (O) [attentional PROPN (B) decoder NOUN (I)] , and CCONJ (O) a NOUN (O) [CBHG PROPN (B) post NOUN - processing VERB (I) network NOUN (I)] . 
Due PROPN (O) to ADP (O) the DET (O) complexity NOUN (O) of ADP (O) the DET (O) architecture NOUN , (O) we PRON (O) leave VERB (O) out NOUN (O) a NOUN (O) complete ADJ (O) description NOUN (O) and CCONJ (O) instead ADV (O) focus NOUN (O) on ADP (O) our DET (O) modifications NOUN . (O) 
We PRON (O) find VERB (O) that SCONJ (O) incorporating VERB (O) [speaker NOUN (B) embeddings NOUN (I)] into ADP (O) the DET (O) [CBHG PROPN (B) post NOUN - processing VERB (I) network NOUN (I) degrades NOUN (I) output NOUN (I)] quality NOUN , (O) whereas SCONJ (O) incorporating VERB (O) [speaker NOUN (B) embeddings NOUN (I)] into ADP (O) the DET (O) character NOUN (O) [encoder NOUN (B)] is AUX (O) necessary ADJ . (O) 
Without ADP (O) a NOUN (O) speaker NOUN - dependent ADJ (O) [CBHG PROPN (B) encoder NOUN (I)] , the DET (O) model NOUN (O) is AUX (O) incapable ADJ (O) of ADP (O) learning NOUN (O) its DET (O) [attention NOUN (B) mechanism NOUN (I)] and CCONJ (O) can VERB (O) not PART (O) generate NOUN (O) meaningful ADJ (O) output NOUN (O) (see VERB (O) Appendix PROPN (O) D.2 NOUN (O) for ADP (O) speaker NOUN - dependent ADJ (O) attention NOUN (O) visualizations NOUN) . (O) 
In ADP (O) order NOUN (O) to ADP (O) condition NOUN (O) the DET (O) [encoder NOUN (B)] on ADP (O) the DET (O) speaker NOUN , (O) we PRON (O) use NOUN (O) one NUM (O) site NOUN - specific ADJ (O) embedding NOUN (O) as SCONJ (O) an DET (O) extra ADJ (O) input NOUN (O) to ADP (O) each DET (O) highway NOUN (O) layer NOUN (O) at ADP (O) each DET (O) timestep NOUN (O) and CCONJ (O) initialize VERB (O) the DET (O) [CBHG PROPN (B) RNN PROPN (I)] state NOUN (O) with ADP (O) a NOUN (O) second ADJ (O) site NOUN - specific ADJ (O) embedding NOUN . (O) 
We PRON (O) also ADV (O) find VERB (O) that DET (O) augmenting VERB (O) the DET (O) [decoder NOUN (B)] with ADP (O) [speaker NOUN (B) embeddings NOUN (I)] is AUX (O) helpful ADJ . (O) 
We PRON (O) use NOUN (O) one NUM (O) site NOUN - specific ADJ (O) embedding NOUN (O) as SCONJ (O) an DET (O) extra ADJ (O) input NOUN (O) to ADP (O) the DET (O) [decoder NOUN (B) pre ADJ - net ADJ (I)] , one NUM (O) extra ADJ (O) site NOUN - specific ADJ (O) embedding NOUN (O) as SCONJ (O) the DET (O) initial NOUN (O) [attention NOUN (B) context NOUN (I) vector NOUN (I)] for ADP (O) the DET (O) [attentional PROPN (B) RNN PROPN (I)] , one NUM (O) site NOUN - specific ADJ (O) embedding NOUN (O) as SCONJ (O) the DET (O) initial NOUN (O) [decoder NOUN (B) GRU PROPN (I) hidden PROPN (I) state NOUN (I)] , and CCONJ (O) one NUM (O) site NOUN - specific ADJ (O) embedding NOUN (O) as SCONJ (O) a NOUN (O) bias NOUN (O) to ADP (O) the DET (O) [tanh NOUN (B)] in ADP (O) the DET (O) content NOUN - based VERB (O) [attention NOUN (B) mechanism NOUN (I)] . 

 Table NOUN (O) : [Mean PROPN (B) Opinion NOUN (I) Score PROPN (I) (MOS PROPN) (I) evaluations NOUN (I)] with ADP (O) 95 NUM (O) % confidence NOUN (O) intervals NOUN (O) of ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM , (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) and CCONJ (O) [Tacotron PROPN (B)] . 
Using VERB (O) the DET (O) crowdMOS X (O) [toolkit NOUN (B)] , batches NOUN (O) of ADP (O) samples NOUN (O) from ADP (O) these DET (O) models NOUN (O) were AUX (O) presented VERB (O) to ADP (O) raters NOUN (O) on ADP (O) Mechanical PROPN (O) Turk PROPN . (O) 
Since SCONJ (O) batches NOUN (O) contained VERB (O) samples NOUN (O) from ADP (O) all DET (O) models NOUN , (O) the DET (O) experiment NOUN (O) naturally ADV (O) induces VERB (O) a NOUN (O) comparison NOUN (O) between ADP (O) the DET (O) models NOUN . (O) 

 [Spectrogram PROPN - to ADP - Waveform PROPN (B) Model NOUN (I)] 

 The DET (O) original ADJ (O) [Tacotron PROPN (B) implementation NOUN (I)] in ADP (O) (Wang PROPN (O) et NOUN (O) al PROPN . , (O) 2017 NUM) (O) uses VERB (O) the DET (O) [Griffin PROPN - Lim PROPN (B) algorithm NOUN (I)] to PART (O) convert NOUN (O) [spectrograms NOUN (B)] to PART (O) time NOUN - domain NOUN (O) [audio NOUN (B) waveforms NOUN (I)] by ADP (O) iteratively ADV (O) estimating VERB (O) the DET (O) unknown ADJ (O) phases NOUN . (O) 
We PRON (O) observe VERB (O) that DET (O) minor NOUN (O) noise NOUN (O) in ADP (O) the DET (O) input NOUN (O) [spectrogram NOUN (B)] causes VERB (O) noticeable ADJ (O) estimation NOUN (O) errors NOUN (O) in ADP (O) the DET (O) GriffinLim PROPN (O) algorithm NOUN (O) and CCONJ (O) the DET (O) generated VERB (O) [audio NOUN (B) quality NOUN (I)] is AUX (O) degraded VERB . (O) 
To NOUN (O) produce NOUN (O) higher ADJ (O) quality NOUN (O) [audio NOUN (B)] using VERB (O) [Tacotron PROPN (B)] , instead ADV (O) of ADP (O) using VERB (O) [Griffin PROPN - Lim PROPN (B)] , we PRON (O) train NOUN (O) a NOUN (O) [WaveNet PROPN - based VERB (B) neural NOUN (I) vocoder NOUN (I)] to PART (O) convert NOUN (O) from ADP (O) linear NOUN (O) [spectrograms NOUN (B)] to PART (O) [audio NOUN (B) waveforms NOUN (I)] . 
The DET (O) model NOUN (O) used VERB (O) is AUX (O) equivalent NOUN (O) to ADP (O) the DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) [vocal NOUN (B) model NOUN (I)] , but CCONJ (O) takes VERB (O) [linear NOUN - scaled VERB (B) log NOUN - magnitude NOUN (I) spectrograms VERB (I)] instead ADV (O) of ADP (O) [phoneme NOUN (B)] identity NOUN (O) and CCONJ (O) F PROPN (O) 0 PUNCT (O) as SCONJ (O) input NOUN . (O) 
The DET (O) combined VERB (O) [Tacotron PROPN - WaveNet PROPN (B) model NOUN (I)] is AUX (O) shown VERB (O) in ADP (O) Fig PROPN . (O) 3 NUM . (O) 
As SCONJ (O) we PRON (O) will VERB (O) show NOUN (O) in ADP (O) Section NOUN (O) 5.1 NUM , (O) [WaveNet PROPN - based VERB (B) neural NOUN (I) vocoder NOUN (I)] indeed ADV (O) significantly ADV (O) improves VERB (O) single-[speaker NOUN (B) Tacotron PROPN (I)] as SCONJ (O) well INTJ . (O) 

 Results NOUN (O) 

 In ADP (O) this DET (O) section NOUN , (O) we PRON (O) will VERB (O) present NOUN (O) the DET (O) results VERB (O) on ADP (O) both DET (O) single ADJ - speaker NOUN (O) and CCONJ (O) [multi ADJ - speaker ADJ (B) speech NOUN (I) synthesis NOUN (I)] using VERB (O) the DET (O) described VERB (O) architectures NOUN . (O) 
All DET (O) model NOUN (O) [hyperparameters NOUN (B)] are AUX (O) presented VERB (O) in ADP (O) Appendix PROPN (O) B. PROPN (O) 

 Single-[Speaker NOUN (B) Speech NOUN (I) Synthesis PROPN (I)] 

 We PRON (O) train NOUN (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM , (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) and CCONJ (O) [Tacotron PROPN (B)] on ADP (O) an DET (O) internal ADJ (O) English PROPN (O) [speech NOUN (B) database NOUN (I)] containing VERB (O) approximately ADV (O) 20 NUM (O) hours NOUN (O) of ADP (O) single-[speaker NOUN (B) data NOUN (I)] . 
The DET (O) intermediate ADJ (O) evaluations NOUN (O) of ADP (O) models NOUN (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM (O) and CCONJ (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) can VERB (O) be AUX (O) found VERB (O) in ADP (O) Table NOUN (O) 3 NUM (O) within ADP (O) Appendix PROPN (O) A. NOUN (O) 
We PRON (O) run NOUN (O) an DET (O) [MOS PROPN (B) evaluation NOUN (I)] using VERB (O) the DET (O) crowdMOS X (O) framework NOUN (O) (Ribeiro PROPN (O) et NOUN (O) al PROPN . , (O) 2011 NUM) (O) to ADP (O) compare VERB (O) the DET (O) quality NOUN (O) of ADP (O) samples NOUN (O) (Table NOUN (O) 1 NUM) . (O) 
The DET (O) results VERB (O) show NOUN (O) conclusively ADV (O) that SCONJ (O) the DET (O) architecture NOUN (O) improvements NOUN (O) in ADP (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) yield NOUN (O) significant ADJ (O) gains NOUN (O) in ADP (O) quality NOUN (O) over ADP (O) [Deep ADJ (B) Voice PROPN (I)] 1 NUM . (O) 
They PRON (O) also ADV (O) demonstrate NOUN (O) that SCONJ (O) converting VERB (O) [Tacotron PROPN - generated VERB (B) spectrograms VERB (I)] to PART (O) [audio NOUN (B)] using VERB (O) [WaveNet PROPN (B)] is AUX (O) preferable ADJ (O) to ADP (O) using VERB (O) the DET (O) iterative ADJ (O) [Griffin PROPN - Lim PROPN (B) algorithm NOUN (I)] . 

 [Multi PROPN - Speaker PROPN (B) Speech NOUN (I) Synthesis PROPN (I)] 

 We PRON (O) train NOUN (O) all DET (O) the DET (O) aforementioned ADJ (O) models NOUN (O) on ADP (O) the DET (O) [VCTK NOUN (B) dataset NOUN (I)] with ADP (O) 44 NUM (O) hours NOUN (O) of ADP (O) [speech NOUN (B)] , which DET (O) contains VERB (O) 108 NUM (O) speakers NOUN (O) with ADP (O) approximately ADV (O) 400 NUM (O) utterances VERB (O) each DET . (O) 
We PRON (O) also ADV (O) train NOUN (O) all DET (O) models NOUN (O) on ADP (O) an DET (O) [internal ADJ (B) dataset NOUN (I)] of ADP (O) audiobooks VERB , (O) which DET (O) contains VERB (O) 477 NUM (O) speakers NOUN (O) with ADP (O) 30 NUM (O) minutes NOUN (O) of ADP (O) [audio NOUN (B)] each DET (O) (for ADP (O) a NOUN (O) total NOUN (O) of ADP (O) ⇠ PROPN (O) 238 NUM (O) hours NOUN) . (O) 
The DET (O) consistent ADJ (O) sample NOUN (O) quality NOUN (O) observed VERB (O) from ADP (O) our DET (O) models NOUN (O) indicates VERB (O) that SCONJ (O) our DET (O) architectures VERB (O) can VERB (O) easily ADV (O) learn VERB (O) hundreds NOUN (O) of ADP (O) [distinct ADJ (B) voices NOUN (I)] with ADP (O) a NOUN (O) variety NOUN (O) of ADP (O) different ADJ (O) accents VERB (O) and CCONJ (O) cadences NOUN . (O) 
We PRON (O) also ADV (O) observe VERB (O) that SCONJ (O) the DET (O) learned VERB (O) embeddings NOUN (O) lie NOUN (O) in ADP (O) a NOUN (O) meaningful ADJ (O) latent NOUN (O) space NOUN (O) (see VERB (O) Fig PROPN . (O) 4 NUM (O) as SCONJ (O) an DET (O) example NOUN (O) and CCONJ (O) Appendix PROPN (O) D NOUN (O) for ADP (O) more ADJ (O) details NOUN) . (O) 
In ADP (O) order NOUN (O) to ADP (O) evaluate VERB (O) the DET (O) quality NOUN (O) of ADP (O) the DET (O) synthesized VERB (O) [audio NOUN (B)] , we PRON (O) run NOUN (O) [MOS PROPN (B) evaluations NOUN (I)] using VERB (O) the DET (O) crowdMOS X (O) framework NOUN , (O) and CCONJ (O) present NOUN (O) the DET (O) results VERB (O) in ADP (O) Table NOUN (O) 2 NUM . (O) 
We PRON (O) purposefully ADV (O) include VERB (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] in ADP (O) the DET (O) set NOUN (O) being NOUN (O) evaluated VERB , (O) because SCONJ (O) the DET (O) accents VERB (O) in ADP (O) datasets VERB (O) are AUX (O) likely ADV (O) to ADP (O) be AUX (O) unfamiliar ADJ (O) to ADP (O) our DET (O) North NOUN (O) American PROPN (O) crowdsourced VERB (O) raters NOUN (O) and CCONJ (O) will VERB (O) thus ADV (O) be AUX (O) rated VERB (O) poorly ADV (O) due ADJ (O) to ADP (O) the DET (O) accent NOUN (O) rather ADV (O) than SCONJ (O) due ADJ (O) to ADP (O) the DET (O) model NOUN (O) quality NOUN . (O) 
By ADP (O) including VERB (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] , we PRON (O) are AUX (O) able ADJ (O) to ADP (O) compare VERB (O) the DET (O) [MOS PROPN (B)] of ADP (O) the DET (O) models NOUN (O) with ADP (O) the DET (O) ground NOUN (O) truth NOUN (O) [MOS PROPN (B)] and CCONJ (O) thus ADV (O) evaluate VERB (O) the DET (O) model NOUN (O) quality NOUN (O) rather ADV (O) than SCONJ (O) the DET (O) [data NOUN (B) quality NOUN (I)] ; however ADV , (O) the DET (O) resulting VERB (O) [MOS PROPN (B)] may VERB (O) be AUX (O) lower ADJ , (O) due ADJ (O) to ADP (O) the DET (O) implicit PROPN (O) comparison NOUN (O) with ADP (O) the DET (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] . 
Overall ADV , (O) we PRON (O) observe VERB (O) that SCONJ (O) the DET (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM (O) model NOUN (O) can VERB (O) approach NOUN (O) an DET (O) [MOS PROPN (B) value NOUN (I)] that DET (O) is AUX (O) close NOUN (O) to ADP (O) the DET (O) ground NOUN (O) truth NOUN , (O) when ADV (O) low NOUN (O) sampling NOUN (O) rate NOUN (O) and CCONJ (O) companding NOUN (O) / expanding VERB (O) taken VERB (O) into ADP (O) account NOUN . (O) 

 Table NOUN (O) : [MOS PROPN (B)] and CCONJ (O) classification NOUN (O) accuracy NOUN (O) for ADP (O) all DET (O) [multi ADJ - speaker ADJ (B) models NOUN (I)] . 
To PART (O) obtain VERB (O) [MOS PROPN (B)] , we PRON (O) use NOUN (O) crowdMOS X (O) [toolkit NOUN (B)] as SCONJ (O) detailed ADJ (O) in ADP (O) Table NOUN (O) 1 NUM . (O) 
We PRON (O) also ADV (O) present NOUN (O) classification NOUN (O) accuracies VERB (O) of ADP (O) the DET (O) speaker NOUN (O) discriminative NOUN (O) models NOUN (O) (see VERB (O) Appendix PROPN (O) E NOUN (O) for ADP (O) details NOUN) (O) on ADP (O) the DET (O) samples NOUN , (O) showing VERB (O) that SCONJ (O) the DET (O) synthesized VERB (O) 
voices NOUN (O) are AUX (O) as SCONJ (O) distinguishable ADJ (O) as SCONJ (O) [ground NOUN (B) truth NOUN (I) audio NOUN (I)] . 

 A DET (O) [multi ADJ - speaker ADJ (B) TTS PROPN (I) system NOUN (I)] with ADP (O) high ADJ (O) sample NOUN (O) quality NOUN (O) but CCONJ (O) [indistinguishable ADJ (B) voices NOUN (I)] would VERB (O) result NOUN (O) in ADP (O) high ADJ (O) [MOS PROPN (B)] , but CCONJ (O) fail VERB (O) to ADP (O) meet NOUN (O) the DET (O) desired VERB (O) objective NOUN (O) of ADP (O) reproducing VERB (O) the DET (O) [input NOUN (B) voices NOUN (I)] accurately ADV . (O) 
To NOUN (O) show NOUN (O) that SCONJ (O) our DET (O) models NOUN (O) not PART (O) only ADV (O) generate NOUN (O) high ADJ (O) quality NOUN (O) samples NOUN , (O) but CCONJ (O) also ADV (O) generate NOUN (O) [distinguishable ADJ (B) voices NOUN (I)] , we PRON (O) also ADV (O) measure NOUN (O) the DET (O) classification NOUN (O) accuracy NOUN (O) of ADP (O) a NOUN (O) speaker NOUN (O) discriminative NOUN (O) model NOUN (O) on ADP (O) our DET (O) generated VERB (O) samples NOUN . (O) 
The DET (O) [speaker NOUN (B) discriminative NOUN (I)] is AUX (O) a NOUN (O) [convolutional NOUN (B) network NOUN (I)] trained VERB (O) to ADP (O) classify NOUN (O) utterances VERB (O) to ADP (O) their DET (O) speakers NOUN , (O) trained VERB (O) on ADP (O) the DET (O) [same ADJ (B) dataset NOUN (I)] as SCONJ (O) the DET (O) [TTS PROPN (B) systems NOUN (I)] themselves PRON . (O) 
If SCONJ (O) the DET (O) voices NOUN (O) were AUX (O) indistinguishable ADJ (O) (or CCONJ (O) the DET (O) [audio NOUN (B) quality NOUN (I)] was AUX (O) low ADJ) , (O) the DET (O) classification NOUN (O) accuracy NOUN (O) would VERB (O) be AUX (O) much ADJ (O) lower ADJ (O) for ADP (O) synthesized VERB (O) samples NOUN (O) than SCONJ (O) it PRON (O) is AUX (O) for ADP (O) the DET (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] . 
As SCONJ (O) we PRON (O) demonstrate NOUN (O) in ADP (O) Table NOUN (O) 2 NUM , (O) classification NOUN (O) accuracy NOUN (O) demonstrates VERB (O) that SCONJ (O) samples NOUN (O) generated VERB (O) from ADP (O) our DET (O) models NOUN (O) are AUX (O) as SCONJ (O) distinguishable ADJ (O) as SCONJ (O) the DET (O) [ground NOUN (B) truth NOUN (I) samples NOUN (I)] (see VERB (O) Appendix PROPN (O) E NOUN (O) for ADP (O) more ADJ (O) details NOUN) . (O) 
The DET (O) classification NOUN (O) accuracy NOUN (O) is AUX (O) only ADV (O) significantly ADV (O) lower ADJ (O) for ADP (O) [Tacotron PROPN (B)] with ADP (O) [WaveNet PROPN (B)] , and CCONJ (O) we PRON (O) suspect NOUN (O) that SCONJ (O) generation NOUN (O) errors NOUN (O) in ADP (O) the DET (O) [spectrogram NOUN (B)] are AUX (O) exacerbated VERB (O) by ADP (O) the DET (O) [WaveNet PROPN (B)] , as SCONJ (O) it PRON (O) is AUX (O) trained VERB (O) with ADP (O) ground NOUN (O) truth NOUN (O) [spectrograms NOUN (B)] . 

 Conclusion NOUN (O) 

 In ADP (O) this DET (O) work NOUN , (O) we PRON (O) explore VERB (O) how ADV (O) entirely-[neural NOUN (B) speech NOUN (I) synthesis NOUN (I) pipelines NOUN (I)] may VERB (O) be AUX (O) extended ADJ (O) to ADP (O) [multi ADJ - speaker ADJ (B) text NOUN - to ADP - speech NOUN (I)] via ADP (O) [low ADJ - dimensional ADJ (B) trainable NOUN (I) speaker PROPN (I) embeddings NOUN (I)] . 
We PRON (O) start VERB (O) by ADP (O) presenting VERB (O) [Deep ADJ (B) Voice PROPN (I)] 2 NUM , (O) an DET (O) improved VERB (O) single-[speaker NOUN (B) model NOUN (I)] . 
Next ADV , (O) we PRON (O) demonstrate NOUN (O) the DET (O) applicability NOUN (O) of ADP (O) our DET (O) technique NOUN (O) by ADP (O) training NOUN (O) both DET (O) [multi ADJ - speaker ADJ (B) Deep ADV (I) Voice PROPN (I)] 2 NUM (O) and CCONJ (O) [multi ADJ - speaker ADJ (B) Tacotron PROPN (I) models NOUN (I)] , and CCONJ (O) evaluate VERB (O) their DET (O) quality NOUN (O) through ADP (O) [MOS PROPN (B)] . 
In ADP (O) conclusion NOUN , (O) we PRON (O) use NOUN (O) our DET (O) speaker NOUN (O) embedding NOUN (O) technique NOUN (O) to ADP (O) create VERB (O) high ADJ (O) quality NOUN (O) [text NOUN - to ADP - speech NOUN (B) systems NOUN (I)] and CCONJ (O) conclusively ADV (O) show NOUN (O) that SCONJ (O) [neural NOUN (B) speech NOUN (I) synthesis NOUN (I) models NOUN (I)] can VERB (O) learn VERB (O) effectively ADV (O) from ADP (O) small ADJ (O) amounts VERB (O) of ADP (O) data NOUN (O) spread NOUN (O) among ADP (O) hundreds NOUN (O) of ADP (O) [different ADJ (B) speakers NOUN (I)] . 
The DET (O) results VERB (O) presented VERB (O) in ADP (O) this DET (O) work NOUN (O) suggest VERB (O) many ADJ (O) directions NOUN (O) for ADP (O) future NOUN (O) research NOUN . (O) 
Future PROPN (O) work NOUN (O) may VERB (O) test NOUN (O) the DET (O) limits NOUN (O) of ADP (O) this DET (O) technique NOUN (O) and CCONJ (O) explore VERB (O) how ADV (O) [many ADJ (B) speakers NOUN (I)] these DET (O) models NOUN (O) can VERB (O) generalize VERB (O) to PART , (O) how ADV (O) [little ADJ (B) data NOUN (I)] is AUX (O) truly ADV (O) required VERB (O) per ADP (O) speaker NOUN (O) for ADP (O) high ADJ (O) quality NOUN (O) synthesis NOUN , (O) whether SCONJ (O) [new PROPN (B) speakers NOUN (I)] can VERB (O) be AUX (O) added VERB (O) to ADP (O) a NOUN (O) system NOUN (O) by ADP (O) fixing VERB (O) model NOUN (O) parameters NOUN (O) and CCONJ (O) solely ADV (O) training NOUN (O) [new PROPN (B) speaker NOUN (I) embeddings NOUN (I)] , and CCONJ (O) whether SCONJ (O) the DET (O) [speaker NOUN (B) embeddings NOUN (I)] can VERB (O) be AUX (O) used VERB (O) as SCONJ (O) a NOUN (O) meaningful ADJ (O) [vector NOUN (B)] space NOUN , (O) as SCONJ (O) is AUX (O) possible ADJ (O) with ADP (O) word NOUN (O) embeddings NOUN . (O) 
