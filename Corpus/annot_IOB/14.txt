[GlobalPhone (B)] : A (O) [Multilingual (B) Text (I)] & [Speech (B) Database (I)] in (O) 20 (O) Languages (O) 

Abstract (O) 

This (O) paper (O) describes (O) the (O) advances (O) in (O) the (O) [multilingual (B) text (I)] and (O) [speech (B) database (I) GlobalPhone (I)], a (O) [multilingual (B) database (I)] of (O) [high-quality (B) read (I) speech (I)] with (O) corresponding (O) transcriptions (O) and (O) [pronunciation (B) dictionaries (I)] in (O) 20 (O) languages. (O) 
[GlobalPhone (B)] was (O) designed (O) to (O) be (O) uniform (O) across (O) languages (O) with (O) respect (O) to (O) the (O) amount (O) of (O) data, (O) [speech (B) quality (I)], the (O) collection (O) scenario, (O) the (O) transcription (O) and (O) [phone (B) set (I)] conventions. (O) 
With (O) more (O) than (O) 400 (O) hours (O) of (O) transcribed (O) [audio (B) data (I)] from (O) more (O) than (O) 2000 (O) [native (B) speakers (I) GlobalPhone (I)] supplies (O) an (O) excellent (O) basis (O) for (O) research (O) in (O) the (O) areas (O) of (O) [multilingual (B) speech (I) recognition (I)], rapid (O) deployment (O) of (O) [speech (B) processing (I) systems (I)] to (O) yet (O) unsupported (O) languages, (O) language (O) identification (O) tasks, (O) [speaker (B) recognition (I)] in (O) multiple (O) languages, (O) [multilingual (B) speech (I) synthesis (I)], as (O) well (O) as (O) [monolingual (B) speech (I) recognition (I)] in (O) a (O) large (O) variety (O) of (O) languages. (O) 
Index (O) Terms (O) : [Speech (B)], Text, (O) and (O) Dictionary (O) Resources (O) for (O) [Multilingual (B) Speech (I) Processing (I)] 

Introduction (O) 

With (O) more (O) than (O) 6900 (O) languages (O) in (O) the (O) world (O) and (O) the (O) need (O) to (O) support (O) multiple (O) input (O) and (O) output (O) languages, (O) it (O) is (O) one (O) of (O) the (O) most (O) pressing (O) challenge (O) for (O) the (O) [speech (B)] and (O) language (O) community (O) to (O) develop (O) and (O) deploy (O) [speech (B) processing (I) systems (I)] in (O) yet (O) unsupported (O) languages (O) rapidly (O) and (O) at (O) reasonable (O) costs. (O) 
Major (O) bottlenecks (O) are (O) the (O) sparseness (O) of (O) [speech (B) and (I) text (I) data (I)] with (O) corresponding (O) [pronunciation (B) dictionaries (I)], the (O) lack (O) of (O) language (O) conventions, (O) and (O) the (O) gap (O) between (O) technology (O) and (O) language (O) expertise. (O) 
[Data (B) sparseness (I)] is (O) a (O) critical (O) issue (O) due (O) to (O) the (O) fact (O) that (O) today’s (O) [speech (B) technologies (I)] heavily (O) rely (O) on (O) statistically (O) based (O) modeling (O) schemes, (O) such (O) as (O) [Hidden (B) Markov (I) Models (I)] and (O) [n-gram (B) language (I) modeling (I)]. 
Although (O) statistical (O) modeling (O) algorithms (O) are (O) mostly (O) [language (B) independent (I)] and (O) proved (O) to (O) work (O) well (O) for (O) a (O) variety (O) of (O) languages, (O) reliable (O) parameter (O) estimation (O) requires (O) vast (O) amounts (O) of (O) [training (B) data (I)]. 
Large-[scale (B) data (I)] resources (O) for (O) research (O) are (O) available (O) for (O) less (O) than (O) 100 (O) languages (O) and (O) the (O) costs (O) for (O) these (O) collections (O) are (O) prohibitive (O) to (O) all (O) but (O) the (O) most (O) widely (O) spoken (O) and (O) economically (O) viable (O) languages. (O) 
The (O) lack (O) of (O) language (O) conventions (O) concerns (O) a (O) surprisingly (O) large (O) number (O) of (O) languages (O) and (O) dialects. (O) 
The (O) lack (O) of (O) a (O) standardized (O) writing (O) system (O) for (O) example (O) hinders (O) web (O) harvesting (O) of (O) large (O) text (O) corpora (O) and (O) the (O) construction (O) of (O) [pronunciation (B) dictionaries (I)] and (O) [lexicons (B)]. 
Last (O) but (O) not (O) least, (O) despite (O) the (O) well-defined (O) process (O) of (O) system (O) building, (O) it (O) is (O) cost (O) and (O) time (O) consuming (O) to (O) handle (O) [language-specific (B) peculiarities (I)], and (O) requires (O) substantial (O) language (O) expertise. (O) 
Unfortunately, (O) it (O) is (O) extremely (O) difficult (O) to (O) find (O) system (O) developers (O) who (O) have (O) both, (O) the (O) necessary (O) technical (O) background (O) and (O) the (O) native (O) expertise (O) of (O) a (O) language (O) in (O) question. (O) 
As (O) a (O) result, (O) one (O) of (O) the (O) pivotal (O) issues (O) for (O) developing (O) [speech (B) processing (I) systems (I)] in (O) multiple (O) languages (O) is (O) the (O) challenge (O) of (O) bridging (O) the (O) gap (O) between (O) language (O) and (O) technology (O) expertise. (O) 

To (O) date, (O) the (O) standard (O) way (O) of (O) building (O) [speech (B)] applications (O) for (O) an (O) unsupported (O) language (O) is (O) to (O) collect (O) a (O) sizable (O) [training (B) corpus (I)] and (O) to (O) train (O) [statistical (B) models (I)] for (O) the (O) new (O) language (O) from (O) scratch. (O) 
Considering (O) the (O) enormous (O) number (O) of (O) languages (O) and (O) dialects (O) in (O) the (O) world, (O) this (O) is (O) clearly (O) a (O) suboptimal (O) strategy, (O) which (O) highlights (O) the (O) need (O) for (O) more (O) sophisticated (O) modeling (O) techniques. (O) 
It (O) would (O) be (O) desirable (O) to (O) develop (O) models (O) that (O) can (O) take (O) advantage (O) of (O) similarities (O) between (O) dialects (O) and (O) languages (O) of (O) similar (O) type (O) and (O) models (O) that (O) can (O) share (O) data (O) across (O) different (O) varieties. (O) 
This (O) would (O) have (O) two (O) benefits, (O) first (O) leading (O) to (O) truly (O) [multilingual (B) speech (I) processing (I)] which (O) can (O) handle (O) common (O) phenomenon (O) such (O) as (O) code (O) switching, (O) and (O) second (O) providing (O) models (O) that (O) are (O) likely (O) to (O) be (O) more (O) robust (O) toward (O) dialectal (O) and (O) [cross-lingual (B) accent (I) variations (I)]. 
These (O) multilingual (O) shared (O) models (O) can (O) then (O) be (O) used (O) as (O) seed (O) models (O) to (O) jump-start (O) a (O) system (O) in (O) an (O) unsupported (O) language (O) by (O) efficiently (O) adapting (O) the (O) seeds (O) using (O) [limited (B) data (I)] from (O) the (O) language (O) in (O) questions. (O) We (O) refer (O) to (O) this (O) development (O) strategy (O) as (O) rapid (O) language (O) adaptation. (O) 

Ten (O) years (O) ago (O) we (O) released (O) a (O) [multilingual (B) text (I)] and (O) [speech (B) corpus (I) GlobalPhone (I)] to (O) address (O) the (O) lack (O) of (O) databases (O) which (O) are (O) consistent (O) across (O) languages. (O) 
By (O) that (O) time (O) the (O) database (O) consisted (O) of (O) 15 (O) languages (O) but (O) since (O) then (O) has (O) been (O) significantly (O) extended (O) to (O) cover (O) more (O) languages, (O) [more (B) speakers (I)], more (O) word (O) tokens (O) along (O) with (O) their (O) pronunciations, (O) and (O) more (O) text (O) resources. (O) 
In (O) addition, (O) [GlobalPhone (B)] was (O) adopted (O) as (O) a (O) [benchmark (B) database (I)] for (O) research (O) and (O) development (O) of (O) [multilingual (B) speech (I) processing (I) systems (I)]. 
Therefore, (O) we (O) believe (O) the (O) time (O) is (O) right (O) to (O) present (O) the (O) latest (O) status (O) of (O) [GlobalPhone (B)]. 
This (O) paper (O) summarizes (O) the (O) resources (O) and (O) systems (O) available (O) in (O) 20 (O) languages, (O) and (O) describes (O) [speech (B) recognition (I)] performances (O) to (O) provide (O) a (O) reference (O) and (O) benchmark (O) for (O) researchers (O) and (O) developers (O) working (O) with (O) this (O) database. (O) 

The (O) [GlobalPhone (B) Corpus (I)] 

[GlobalPhone (B)] is (O) a (O) [multilingual (B) data (I) corpus (I)] developed (O) in (O) collaboration (O) with (O) the (O) Karlsruhe (O) Institute (O) of (O) Technology (O) (KIT). (O) 
The (O) [complete (B) data (I) corpus (I)] comprises (O) (1) (O) [audio (B) / (I) speech (I) data (I)], i.e. (O) [high-quality (B) recordings (I)] of (O) spoken (O) utterances (O) read (O) by (O) [native (B) speakers (I)], (2) (O) corresponding (O) transcriptions, (O) (3) (O) [pronunciation (B) dictionaries (I)] covering (O) the (O) vocabulary (O) of (O) the (O) transcripts, (O) and (O) (4) (O) baseline (O) [n-gram (B) language (I) models (I)]. 
The (O) first (O) two (O) are (O) referred (O) to (O) as (O) [GlobalPhone (B) Speech (I)] and (O) [Text (B) Database (I)] (GP-ST), (O) the (O) third (O) as (O) [GlobalPhone (B) Dictionaries (I)] (GP-Dict), (O) and (O) the (O) latter (O) as (O) [GlobalPhone (B) Language (I) Models (I)] (GP-LM). (O) GP-ST (O) is (O) distributed (O) under (O) a (O) research (O) or (O) commercial (O) license (O) by (O) two (O) authorized (O) distributors, (O) the (O) European (O) Language (O) Resources (O) Association (O) (ELRA) (O) and (O) Appen (O) Butler (O) Hill (O) Pty (O) Ltd (O) GP-Dict (O) is (O) distributed (O) by (O) ELRA, (O) while (O) the (O) GP-LMs (O) are (O) freely (O) available (O) for (O) download (O) from (O) our (O) website. (O) 

The (O) entire (O) [GlobalPhone (B) corpus (I)] provides (O) a (O) [multilingual (B) database (I)] of (O) word-level (O) transcribed (O) [high-quality (B) speech (I)] for (O) the (O) development (O) and (O) evaluation (O) of (O) large (O) vocabulary (O) [speech (B) processing (I) systems (I)] in (O) the (O) most (O) widespread (O) languages (O) of (O) the (O) world. (O) 
[GlobalPhone (B)] is (O) designed (O) to (O) be (O) uniform (O) across (O) languages (O) with (O) respect (O) to (O) the (O) amount (O) of (O) data (O) per (O) language, (O) the (O) [audio (B) quality (I)] (microphone, (O) noise, (O) channel), (O) the (O) collection (O) scenario (O) (task, (O) setup, (O) speaking (O) style), (O) as (O) well (O) as (O) the (O) transcription (O) and (O) [phone (B) set (I)] conventions (O) ([IPA-based (B) naming (I)] of (O) phones (O) in (O) all (O) [pronunciation (B) dictionaries (I)]). 
Thus, (O) [GlobalPhone (B)] supplies (O) an (O) excellent (O) basis (O) for (O) research (O) in (O) the (O) areas (O) of (O) (1) (O) [multilingual (B) speech (I) recognition (I)], (2) (O) rapid (O) deployment (O) of (O) [speech (B) processing (I) systems (I)] to (O) yet (O) unsupported (O) languages, (O) (3) (O) language (O) identification (O) tasks, (O) (4) (O) [speaker (B) recognition (I)] in (O) multiple (O) languages, (O) (5) (O) [multilingual (B) speech (I) synthesis (I)], as (O) well (O) as (O) (6) (O) [monolingual (B) speech (I) recognition (I)] in (O) a (O) large (O) variety (O) of (O) languages. (O) 

Language (O) Coverage (O) 

To (O) date, (O) the (O) [GlobalPhone (B) corpus (I)] covers (O) 20 (O) languages, (O) i.e. (O) Arabic (O) (Modern (O) Standard (O) Arabic), (O) Bulgarian, (O) Chinese (O) (Mandarin (O) and (O) Shanghai), (O) Croatian, (O) Czech, (O) French, (O) German, (O) Hausa, (O) Japanese, (O) Korean, (O) Polish, (O) Portuguese (O) (Brazilian), (O) Russian, (O) Spanish (O) (Latin (O) American), (O) Swedish, (O) Tamil, (O) Thai, (O) Turkish, (O) Ukrainian, (O) and (O) Vietnamese. (O) 
This (O) selection (O) covers (O) a (O) broad (O) variety (O) of (O) language (O) peculiarities (O) relevant (O) for (O) [Speech (B)] and (O) Language (O) research (O) and (O) development. (O) 
It (O) comprises (O) [wide-spread (B) languages (I)] (e.g. (O) Arabic, (O) Chinese, (O) Spanish, (O) Russian), (O) contains (O) economically (O) and (O) politically (O) important (O) languages, (O) and (O) spans (O) wide (O) geographical (O) areas (O) (Europe, (O) Africa, (O) America, (O) Asia). (O) 

The (O) spoken (O) [speech (B)] covers (O) a (O) broad (O) selection (O) of (O) [phonetic (B) characteristics (I)], e.g. (O) tonal (O) sounds (O) (Mandarin, (O) Shanghai, (O) Thai, (O) Vietnamese), (O) pharyngeal (O) sounds (O) (Arabic), (O) consonantal (O) clusters (O) (German), (O) nasals (O) (French, (O) Portuguese), (O) and (O) palatized (O) sounds (O) (Russian). (O) 
The (O) written (O) language (O) contains (O) all (O) types (O) of (O) writing (O) systems, (O) i.e. (O) logographic (O) scripts (O) (Chinese (O) Hanzi (O) and (O) Japanese (O) Kanji), (O) phonographic (O) segmental (O) scripts (O) (Roman, (O) Cyrillic), (O) phonographic (O) consonantal (O) scripts (O) (Arabic), (O) phonographic (O) syllabic (O) scripts (O) (Japanese (O) Kana, (O) Thai), (O) and (O) phonographic (O) featural (O) scripts (O) (Korean (O) Hangul). (O) 
The (O) languages (O) cover (O) many (O) morphological (O) variations, (O) e.g. (O) agglutinative (O) languages (O) (Turkish, (O) Korean), (O) compounding (O) languages (O) (German), (O) and (O) also (O) include (O) scripts (O) that (O) completely (O) lack (O) word (O) segmentation (O) (Chinese, (O) Thai). (O) 

[Data (B) Acquisition (I)] 

The (O) [data (B) acquisition (I)] was (O) performed (O) in (O) countries (O) where (O) the (O) language (O) is (O) officially (O) spoken. (O) 
In (O) each (O) language (O) about (O) 100 (O) adult (O) [native (B) speakers (I)] were (O) asked (O) to (O) read (O) about (O) 100 (O) sentences. (O) 
The (O) first (O) batch (O) of (O) [data (B) collection (I)] was (O) done (O) from (O) May (O) 1996 (O) to (O) November (O) 1997, (O) and (O) a (O) second (O) batch (O) between (O) 2003 (O) and (O) 2012. (O) During (O) the (O) first (O) batch (O) we (O) collected (O) Arabic (O) [speech (B)] in (O) Tunis, (O) Sfax (O) and (O) Djerba, (O) Tunisia (O) ; Mandarin (O) in (O) Beijing, (O) Wuhan (O) and (O) Hekou, (O) China (O) ; Shanghai (O) in (O) Shanghai, (O) China (O) ; Croatian (O) in (O) Zagreb, (O) Croatia, (O) and (O) parts (O) of (O) Bosnia (O) ; Czech (O) in (O) Prague, (O) Czech (O) Republic (O) ; French (O) in (O) Grenoble, (O) France (O) ; German (O) in (O) Karlsruhe, (O) Germany (O) ; Japanese (O) in (O) Tokyo, (O) Japan (O) ; Korean (O) in (O) Seoul, (O) Korea (O) ; Portuguese (O) in (O) Porto (O) Velho (O) and (O) Sao (O) Paulo, (O) Brazil (O) ; Polish (O) in (O) Poland, (O) Russian (O) in (O) Minsk, (O) Belarus (O) ; Spanish (O) in (O) Heredia (O) and (O) San (O) Jose, (O) Costa (O) Rica (O) ; Swedish (O) in (O) Stockholm (O) and (O) Vaernamo, (O) Sweden (O) ; Tamil (O) in (O) India, (O) and (O) Turkish (O) in (O) Istanbul, (O) Turkey. (O) 
In (O) the (O) second (O) batch (O) we (O) collected (O) Bulgarian (O) in (O) Sofia, (O) Hausa (O) in (O) Cameroon, (O) Thai (O) in (O) Bangkok, (O) Ukrainian (O) in (O) Donezk, (O) and (O) Vietnamese (O) in (O) Hanoi (O) and (O) Ho (O) Chi (O) Minh (O) City. (O) 

The (O) read (O) texts (O) were (O) selected (O) from (O) national (O) newspaper (O) articles (O) available (O) from (O) the (O) web (O) to (O) cover (O) a (O) wide (O) domain (O) with (O) large (O) vocabulary. (O) 
The (O) articles (O) report (O) national (O) and (O) international (O) political (O) news, (O) as (O) well (O) as (O) economic (O) news, (O) which (O) makes (O) it (O) possible (O) to (O) compare (O) the (O) usage (O) of (O) proper (O) names (O) (Politicians, (O) companies, (O) etc.) (O) across (O) languages. (O) 
We (O) used (O) the (O) following (O) newspapers (O) : Assabah (O) for (O) Arabic, (O) Banker, (O) Cash, (O) and (O) Sega (O) for (O) Bulgarian, (O) Peoples (O) Daily (O) for (O) Mandarin (O) and (O) Shanghai (O) Chinese, (O) HRT (O) and (O) Obzor (O) Nacional (O) for (O) Croatian, (O) Ceskomoravsky (O) Profit (O) Journal (O) and (O) Lidove (O) Noviny (O) newspaper (O) for (O) Czech, (O) Le (O) Monde (O) for (O) French, (O) Frankfurter (O) Allgemeine (O) und (O) Sueddeutsche (O) Zeitung (O) for (O) German, (O) CRI (O) online (O) and (O) RFI (O) for (O) Hausa, (O) Hankyoreh (O) Daily (O) News (O) for (O) Korean, (O) Nikkei (O) Shinbun (O) for (O) Japanese, (O) Folha (O) de (O) Sao (O) Paulo (O) for (O) Portuguese, (O) Dziennik (O) Polski (O) for (O) Polish, (O) Ogonyok (O) Gaseta (O) and (O) express-chronika (O) for (O) Russian, (O) La (O) Nacion (O) for (O) Spanish, (O) Goeteborgs-Posten (O) for (O) Swedish, (O) Thinaboomi (O) Tamil (O) Daily (O) for (O) Tamil, (O) Bangkok (O) Biz (O) news (O) and (O) Daily (O) News (O) for (O) Thai, (O) Zaman (O) for (O) Turkish, (O) Pravda (O) among (O) 9 (O) other (O) online (O) newspapers (O) for (O) Ukrainian, (O) and (O) Tin (O) Tuc (O) among (O) others (O) for (O) Vietnamese. (O) 

The (O) [speech (B) data (I)] was (O) recorded (O) with (O) a (O) close-speaking (O) microphone (O) and (O) is (O) available (O) in (O) identical (O) characteristics (O) for (O) all (O) languages (O) : PCM (O) encoding, (O) mono (O) quality, (O) 16bit (O) quantization, (O) and (O) 16kHz (O) sampling (O) rate. (O) 
Most (O) recordings (O) were (O) done (O) in (O) ordinary (O) rooms, (O) in (O) the (O) majority (O) without (O) background (O) noise, (O) so (O) that (O) the (O) speakers (O) were (O) not (O) distracted. (O) 
The (O) quality (O) of (O) noise (O) level (O) and (O) recording (O) room (O) setup (O) is (O) reported (O) for (O) each (O) session. (O) The (O) speakers (O) were (O) given (O) instructions (O) about (O) the (O) equipment (O) handling (O) in (O) advance. (O) 
They (O) were (O) introduced (O) to (O) the (O) projects (O) goals (O) and (O) were (O) allowed (O) to (O) read (O) the (O) texts (O) before (O) recording. (O) 
The (O) transcriptions (O) are (O) available (O) in (O) the (O) original (O) script (O) of (O) the (O) corresponding (O) language. (O) 
In (O) addition, (O) all (O) transcriptions (O) have (O) been (O) romanized, (O) i.e. (O) transformed (O) into (O) Roman (O) script (O) applying (O) reversible (O) character (O) mappings. (O) 
The (O) transcripts (O) were (O) internally (O) validated (O) and (O) supplemented (O) by (O) special (O) markers (O) for (O) spontaneous (O) effects (O) like (O) stuttering, (O) false (O) starts, (O) and (O) non-verbal (O) effects (O) such (O) as (O) breathing, (O) laughing, (O) and (O) hesitations. (O) 
[Speaker (B) information (I)], such (O) as (O) age, (O) gender, (O) place (O) of (O) birth, (O) dialect, (O) occupation, (O) etc. (O) as (O) well (O) as (O) information (O) about (O) the (O) recording (O) setup (O) complement (O) the (O) database. (O) 

Table (O) : [GlobalPhone (B) Corpus (I)] Statistic (O) 

[Corpus (B) Statistics (I)] 

The (O) entire (O) [GlobalPhone (B) corpus (I)] contains (O) over (O) 400 (O) hours (O) of (O) [speech (B)] spoken (O) by (O) more (O) than (O) 2000 (O) native (O) [adult (B) speakers (I)]. 
The (O) data (O) are (O) organized (O) by (O) languages (O) and (O) speakers (O) and (O) are (O) divided (O) into (O) [speaker (B) disjoint (I)] sets (O) for (O) training (O) (80 (O) %), (O) development (O) (10 (O) %), (O) and (O) evaluation (O) (10 (O) %). (O) 
Table (O) 1 (O) summarizes (O) the (O) amount (O) of (O) transcribed (O) [speech (B) data (I)] per (O) language. (O) 

Rapid (O) Language (O) Adaptation (O) [Toolkit (B)] (RLAT) (O) 

The (O) project (O) SPICE (O) (NSF, (O) 2004-2008) (O) performed (O) at (O) the (O) Language (O) Technologies (O) Institute (O) at (O) Carnegie (O) Mellon (O) and (O) the (O) Rapid (O) Language (O) Adaptation (O) project (O) at (O) the (O) Cognitive (O) Systems (O) Lab (O) (CSL) (O) aim (O) at (O) bridging (O) the (O) gap (O) between (O) the (O) language (O) and (O) technology (O) expertise. (O) 
For (O) this (O) purpose (O) RLAT (O) provides (O) innovative (O) methods (O) and (O) interactive (O) web-based (O) tools (O) to (O) enable (O) users (O) to (O) develop (O) [speech (B) processing (I) models (I)], to (O) collect (O) appropriate (O) [speech (B) and (I) text (I) data (I)] to (O) build (O) these (O) models, (O) as (O) well (O) as (O) to (O) evaluate (O) the (O) results (O) allowing (O) for (O) iterative (O) improvements. (O) 
The (O) [toolkit (B)] significantly (O) reduces (O) the (O) amount (O) of (O) time (O) and (O) effort (O) involved (O) in (O) building (O) [speech (B) processing (I) systems (I)] for (O) unsupported (O) languages. (O) 
In (O) particular, (O) the (O) [toolkit (B)] allows (O) the (O) user (O) to (O) (1) (O) [design (B) databases (I)] for (O) new (O) languages (O) at (O) low (O) cost (O) by (O) enabling (O) users (O) to (O) record (O) appropriate (O) [speech (B) data (I)] along (O) with (O) transcriptions, (O) (2) (O) to (O) continuously (O) harvest, (O) normalize, (O) and (O) process (O) massive (O) amounts (O) of (O) [text (B) data (I)] from (O) the (O) web, (O) (3) (O) to (O) select (O) appropriate (O) [phone (B) sets (I)] for (O) new (O) languages (O) efficiently, (O) (4) (O) to (O) create (O) vocabulary (O) lists, (O) (5) (O) to (O) automatically (O) generate (O) [pronunciation (B) dictionaries (I)], (6) (O) to (O) apply (O) these (O) resources (O) by (O) developing (O) acoustic (O) and (O) language (O) models (O) for (O) [speech (B) recognition (I)], (7) (O) to (O) develop (O) models (O) for (O) [text-to-speech (B) synthesis (I)], and (O) (8) (O) to (O) finally (O) integrate (O) the (O) built (O) components (O) into (O) an (O) application (O) and (O) evaluate (O) the (O) results (O) using (O) online (O) [speech (B) recognition (I)] and (O) synthesis (O) in (O) a (O) talk-back (O) function. (O) 
RLAT (O) and (O) SPICE (O) leverage (O) off (O) the (O) two (O) projects (O) [GlobalPhone (B)] and (O) FestVox (O) to (O) implement (O) bootstrapping (O) techniques (O) that (O) are (O) based (O) on (O) extensive (O) knowledge (O) and (O) data (O) sharing (O) across (O) languages, (O) as (O) well (O) as (O) sharing (O) across (O) system (O) components. (O) 
Examples (O) for (O) [data (B) sharing (I)] techniques (O) are (O) the (O) training (O) of (O) [multilingual (B) acoustic (I) models (I)] across (O) languages (O) based (O) on (O) the (O) definition (O) of (O) global (O) [phone (B) sets (I)]. 
Sharing (O) across (O) components (O) happens (O) on (O) all (O) levels (O) between (O) recognition (O) and (O) synthesis, (O) including (O) [phone (B) sets (I)], [pronunciation (B) dictionaries (I)], [acoustic (B) models (I)], and (O) text (O) resources. (O) 
RLAT (O) and (O) SPICE (O) are (O) a (O) freely (O) available (O) online (O) service (O) which (O) provides (O) an (O) interface (O) to (O) the (O) web-based (O) tools (O) and (O) has (O) been (O) designed (O) to (O) accommodate (O) all (O) potential (O) users, (O) ranging (O) from (O) novices (O) to (O) experts. (O) 
Novice (O) users (O) are (O) able (O) to (O) read (O) easy-to-follow, (O) step-by-step (O) guidelines (O) as (O) they (O) build (O) a (O) [speech (B) processing (I) system (I)]. 
Expert (O) users (O) can (O) skip (O) past (O) these (O) instructions. (O) 
In (O) addition, (O) file-uploading (O) routines (O) allow (O) for (O) feeding (O) the (O) bootstrapping (O) algorithms (O) with (O) [available (B) data (I)] and (O) thus (O) shortcut (O) the (O) process. (O) 
As (O) a (O) result (O) the (O) tools (O) collect (O) information (O) from (O) the (O) broadest (O) array (O) of (O) people (O) : a (O) general (O) audience (O) of (O) Internet (O) users (O) who (O) may (O) have (O) little (O) experience (O) with (O) [speech (B) tools (I)], and (O) a (O) specific (O) audience (O) of (O) [speech (B)] and (O) language (O) experts, (O) who (O) can (O) use (O) data (O) they (O) already (O) have. (O) 
By (O) keeping (O) the (O) users (O) in (O) the (O) developmental (O) loop, (O) the (O) RLAT (O) and (O) SPICE (O) tools (O) can (O) learn (O) from (O) their (O) expertise (O) to (O) constantly (O) adapt (O) and (O) improve (O) the (O) resulting (O) models (O) and (O) systems. (O) 
The (O) tools (O) are (O) regularly (O) used (O) for (O) training (O) and (O) teaching (O) purposes (O) at (O) two (O) universities (O) (KIT (O) and (O) CMU). (O) 
Students (O) are (O) asked (O) to (O) rely (O) solely (O) on (O) the (O) tools (O) when (O) building (O) [speech (B) processing (I) systems (I)] and (O) report (O) back (O) on (O) problems (O) and (O) limitations (O) of (O) the (O) system. (O) 
Results (O) indicate (O) that (O) it (O) is (O) feasible (O) to (O) build (O) [end-to-end (B) speech (I) processing (I) systems (I)] in (O) various (O) languages (O) (more (O) than (O) 15) (O) for (O) small (O) domains (O) within (O) the (O) framework (O) of (O) a (O) six-week (O) hands-on (O) lab (O) course. (O) 
Our (O) tools (O) will (O) hopefully (O) revolutionize (O) the (O) system (O) development (O) process (O) in (O) the (O) future. (O) 
Archiving (O) the (O) data (O) gathered (O) on-the-fly (O) from (O) many (O) cooperative (O) native (O) users (O) will (O) significantly (O) increase (O) the (O) repository (O) of (O) languages (O) and (O) resources. (O) 
Data (O) and (O) components (O) for (O) under-supported (O) languages (O) will (O) become (O) available (O) at (O) large (O) to (O) let (O) everyone (O) participate (O) in (O) the (O) information (O) revolution, (O) improve (O) the (O) mutual (O) understanding, (O) bridge (O) language (O) barriers, (O) and (O) thus (O) foster (O) educational (O) and (O) cultural (O) exchange. (O) 

[GlobalPhone (B) Pronunciation (I) Dictionaries (I)] 

[Phone-based (B) pronunciation (I) dictionaries (I)] are (O) available (O) for (O) each (O) [GlobalPhone (B)] language. (O) 
The (O) dictionaries (O) cover (O) the (O) words (O) which (O) appear (O) in (O) the (O) transcriptions. (O) 
The (O) majority (O) of (O) the (O) dictionaries (O) were (O) constructed (O) in (O) a (O) [rule-based (B) manner (I)] using (O) language (O) specific (O) [phone (B) sets (I)]. 
After (O) this (O) automatic (O) creation (O) process (O) the (O) dictionaries (O) were (O) manually (O) post-processed (O) word-by-word (O) by (O) [native (B) speakers (I)], correcting (O) errors (O) in (O) the (O) automatic (O) pronunciation (O) generation (O) and (O) introducing (O) pronunciation (O) variants. (O) 
To (O) enable (O) the (O) development (O) of (O) [multilingual (B) speech (I) processing (I)], the (O) phone (O) names (O) are (O) consistent (O) across (O) languages, (O) leveraging (O) the (O) [International (B) Phonetic (I) Alphabet (I)] ([IPA (B)]). 
Table (O) 2 (O) gives (O) an (O) overview (O) of (O) the (O) size (O) of (O) the (O) [phone (B) sets (I)], amount (O) of (O) vocabulary (O) words (O) covered, (O) and (O) amount (O) of (O) pronunciation (O) variants (O) in (O) the (O) [GlobalPhone (B) pronunciation (I) dictionaries (I)]. 

Table (O) : [GlobalPhone (B) Pronunciation (I) Dictionaries (I)] 


[GlobalPhone (B) Language (I) Models (I)] 

We (O) applied (O) RLAT (O) to (O) crawl (O) a (O) massive (O) amount (O) of (O) [text (B) data (I)] and (O) used (O) the (O) strategy (O) presented (O) in (O) to (O) quickly (O) and (O) efficiently (O) build (O) the (O) [GlobalPhone (B) language (I) models (I)] for (O) 19 (O) languages. (O) 
We (O) crawled (O) [text (B) data (I)] for (O) several (O) days, (O) and (O) each (O) day (O) one (O) language (O) model (O) was (O) built (O) based (O) on (O) the (O) daily (O) crawled (O) [text (B) data (I)]. 
The (O) final (O) language (O) model (O) was (O) then (O) created (O) by (O) a (O) linear (O) interpolation (O) of (O) all (O) daily (O) language (O) models. (O) 
The (O) interpolation (O) weights (O) were (O) computed (O) using (O) the (O) [SRI (B) Language (I) Model (I) Toolkit (I)], optimized (O) on (O) the (O) [GlobalPhone (B)] development (O) sets. (O) 
The (O) experimental (O) results (O) in (O) indicated (O) that (O) the (O) [text (B) data (I)] from (O) the (O) first (O) few (O) days (O) are (O) most (O) helpful (O) and (O) therefore (O) receive (O) the (O) highest (O) interpolation (O) weights (O) in (O) the (O) final (O) language (O) model. (O) 
Since (O) the (O) outcome (O) of (O) the (O) crawling (O) process (O) depends (O) on (O) the (O) input (O) websites, (O) the (O) starting (O) pages (O) have (O) to (O) be (O) chosen (O) carefully. (O) 
In (O) some (O) cases (O) (Croatian, (O) Japanese, (O) Korean, (O) Thai) (O) the (O) crawling (O) process (O) finished (O) prematurely. (O) 
In (O) those (O) cases (O) we (O) selected (O) additional (O) websites (O) to (O) harvest (O) more (O) diverse (O) [text (B) data (I)]. 
The (O) final (O) best (O) language (O) model (O) were (O) then (O) built (O) based (O) on (O) the (O) interpolation (O) of (O) the (O) language (O) models (O) from (O) a (O) variety (O) of (O) websites. (O) 
Since (O) some (O) scripts (O) lack (O) a (O) segmentation (O) into (O) words (O) or (O) do (O) not (O) provide (O) a (O) suitable (O) definition (O) of’ (O) word (O) units’ (O) (Chinese, (O) Korean, (O) Japanese, (O) Tamil, (O) Thai, (O) and (O) Vietnamese) (O) we (O) defined (O) syllables (O) or (O) characters (O) as (O) token (O) units (O) for (O) the (O) purpose (O) of (O) [speech (B) recognition (I)]. 
Table (O) 3 (O) gives (O) an (O) overview (O) of (O) the (O) amount (O) of (O) crawled (O) [text (B) data (I)], the (O) trigram (O) perplexities (O) (PPL), (O) out-of-vocabulary (O) (OOV) (O) rates, (O) and (O) the (O) vocabulary (O) sizes (O) of (O) the (O) [GlobalPhone (B) language (I) models (I)], for (O) both (O) the (O) full (O) (LM) (O) and (O) the (O) pruned (O) [benchmark (B) language (I) models (I)] ([LM-BM (B)]), which (O) are (O) available (O) for (O) download (O) from (O) our (O) website. (O) 
The (O) symbols (O) in (O) parantheses (O) after (O) the (O) language (O) name (O) indicate (O) the (O) token (O) units (O) used, (O) i.e. (O) (w) (O) for (O) [word-based (B)], (s) (O) for (O) [syllable-based (B)], and (O) (c) (O) for (O) [character-based (B) token (I) units (I)]. 

Table (O) : [GlobalPhone (B)] Text (O) Resources (O) and (O) Language (O) Models (O) 

[Speech (B) Recognition (I) Systems (I)] 

In (O) this (O) section, (O) we (O) present (O) the (O) large (O) vocabulary (O) [speech (B) recognition (I) systems (I)] trained (O) and (O) evaluated (O) on (O) 19 (O) [GlobalPhone (B)] languages, (O) i.e. (O) all (O) languages (O) but (O) Arabic (O) and (O) Shanghai, (O) for (O) the (O) latter (O) no (O) transcripts (O) are (O) available (O) at (O) this (O) point. (O) 
For (O) training, (O) development, (O) and (O) evaluation (O) we (O) used (O) the (O) [audio (B) data (I)] as (O) described (O) in (O) Table (O) 1, (O) the (O) dictionaries (O) shown (O) in (O) Table (O) 2, (O) and (O) the (O) language (O) models (O) listed (O) in (O) Table (O) 3. (O) 
All (O) recognition (O) systems (O) were (O) build (O) in (O) the (O) same (O) fashion. (O) 
The (O) systems (O) use (O) [Bottle-Neck (B) front-end (I) features (I)] with (O) a (O) multilingual (O) initialization (O) scheme (O) as (O) proposed (O) in. (O) 
In (O) this (O) approach (O) a (O) [multilingual (B) multilayer (I) perceptron (I)] ([ML-MLP (B)]) was (O) trained (O) using (O) the (O) [training (B) data (I)] from (O) 12 (O) languages (O) (Bulgarian, (O) Chinese, (O) English, (O) French, (O) German, (O) Croatian, (O) Japanese, (O) Korean, (O) Polish, (O) Russian, (O) Spanish, (O) and (O) Thai). (O) 
To (O) initialize (O) [MLP (B) training (I)] for (O) a (O) system, (O) we (O) select (O) the (O) output (O) from (O) the (O) [ML-MLP (B)] based (O) on (O) the (O) [IPA (B) phone (I) set (I)] and (O) use (O) it (O) as (O) a (O) starting (O) point (O) for (O) [MLP (B) training (I)]. 
All (O) weights (O) from (O) the (O) [ML-MLP (B)] were (O) taken (O) and (O) only (O) the (O) output (O) biases (O) from (O) the (O) selected (O) targets (O) were (O) used. (O) 

To (O) rapidly (O) bootstrap (O) the (O) system, (O) the (O) phone (O) models (O) were (O) seeded (O) by (O) the (O) closest (O) matches (O) of (O) the (O) multilingual (O) phone (O) inventory (O) MM7 (O) derived (O) from (O) an (O) [IPA-based (B) phone (I) mapping (I)]. 
The (O) [acoustic (B) model (I)] uses (O) a (O) fully-continuous (O) 3-state (O) left-to-right (O) [Hidden-Markov-Model (B)]. 
The (O) emission (O) probabilities (O) are (O) modeled (O) by (O) [Gaussian (B)] Mixtures (O) with (O) diagonal (O) covariances. (O) 
For (O) [context-dependent (B) acoustic (I) models (I)], we (O) trained (O) a (O) quintphone (O) system (O) and (O) stopped (O) the (O) [decision (B) tree (I)] splitting (O) process (O) at (O) a (O) specified (O) language (O) dependent (O) threshold (O) (varies (O) between (O) 500 (O) and (O) 3,000 (O) leaves (O) depending (O) on (O) the (O) available (O) amount (O) of (O) [training (B) data (I)]). 
After (O) context (O) clustering, (O) a (O) merge-and-split (O) training (O) was (O) applied, (O) which (O) selects (O) the (O) number (O) of (O) [Gaussians (B)] according (O) to (O) the (O) amount (O) of (O) data. (O) 
For (O) all (O) models, (O) we (O) used (O) one (O) global (O) semi-tied (O) covariance (O) (STC) (O) matrix (O) after (O) [Linear (B) Discriminant (I) Analysis (I)] ([LDA (B)]). 

To (O) model (O) tonal (O) languages (O) such (O) as (O) Chinese, (O) Hausa, (O) Thai, (O) and (O) Vietnamese, (O) we (O) apply (O) the (O) ” (O) Data-driven (O) tone (O) modeling (O) “ (O) approach, (O) where (O) all (O) tonal (O) variants (O) of (O) a (O) phone (O) share (O) one (O) base (O) model. (O) 
The (O) information (O) about (O) the (O) tone (O) is (O) added (O) to (O) the (O) dictionary (O) in (O) form (O) of (O) a (O) tone (O) tag. (O) 
These (O) tags (O) are (O) used (O) as (O) questions (O) to (O) be (O) asked (O) in (O) the (O) context (O) [decision (B) tree (I)] when (O) building (O) [context-dependent (B) acoustic (I) models (I)]. 
This (O) way, (O) the (O) data (O) decide (O) during (O) model (O) clustering (O) whether (O) different (O) tonal (O) variants (O) of (O) the (O) same (O) basic (O) phone (O) end (O) up (O) being (O) represented (O) by (O) different (O) models (O) or (O) share (O) the (O) basic (O) phone (O) model. (O) 
Figure (O) 1 (O) illustrates (O) the (O) recognition (O) performance (O) for (O) 19 (O) [GlobalPhone (B) systems (I)], tested (O) on (O) the (O) evaluation (O) set (O) using (O) both, (O) the (O) full (O) language (O) models (O) (LM) (O) and (O) the (O) pruned (O) [benchmark (B) language (I) models (I)] ([LM-BM (B)]). 

Figure (O) : Word (O) / Syllable (O) / Character (O) Error (O) rates (O) of (O) the (O) [GlobalPhone (B) speech (I) recognition (I) systems (I)] in (O) 19 (O) languages (O) 

Summary (O) 

In (O) this (O) paper (O) we (O) presented (O) the (O) latest (O) status (O) of (O) the (O) [GlobalPhone (B) speech (I)] and (O) language (O) resources (O) in (O) 20 (O) different (O) languages. (O) 
We (O) summarized (O) the (O) amount (O) of (O) [speech (B) data (I)] recordings, (O) the (O) number (O) of (O) entries (O) covered (O) in (O) the (O) [pronunciation (B) dictionaries (I)] and (O) the (O) amount (O) of (O) [text (B) data (I)] along (O) with (O) the (O) characteristics (O) of (O) the (O) language (O) models. (O) 
These (O) resources (O) are (O) available (O) to (O) the (O) community (O) for (O) research (O) and (O) development (O) of (O) [multilingual (B) speech (I) processing (I) systems (I)]. 
We (O) also (O) described (O) the (O) Rapid (O) Language (O) Adaptation (O) [Toolkit (B)] which (O) was (O) used (O) to (O) crawl (O) additional (O) text (O) resources (O) for (O) language (O) model (O) building. (O) 
Finally, (O) we (O) present (O) the (O) performance (O) of (O) our (O) [speech (B) recognition (I) systems (I)] based (O) on (O) the (O) data (O) described (O) to (O) provide (O) a (O) reference (O) and (O) benchmark (O) numbers (O) for (O) researchers (O) and (O) developers (O) who (O) work (O) with (O) the (O) [GlobalPhone (B) corpus (I)]. 
