[TUNDRA (B)] : A (O) [Multilingual (B) Corpus (I)] of (O) Found (O) Data (O) for (O) [TTS (B) Research (I)] Created (O) with (O) [Light (B) Supervision (I)] 

Abstract (O)        
[Simple4All (B) Tundra (I)] (version (O) 1.0) (O) is (O) the (O) first (O) release (O) of (O) a (O) standardised (O) [multilingual (B) corpus (I)] designed (O) for (O) [text-to-speech (B) research (I)] with (O) imperfect (O) or (O) found (O) data. (O) 
The (O) corpus (O) consists (O) of (O) approximately (O) 60 (O) hours (O) of (O) [speech (B) data (I)] from (O) audiobooks (O) in (O) 14 (O) languages, (O) as (O) well (O) as (O) [utterance-level (B) alignments (I)] obtained (O) with (O) a (O) [lightly-supervised (B) process (I)]. 
Future (O) versions (O) of (O) the (O) corpus (O) will (O) include (O) finer-grained (O) alignment (O) and (O) prosodic (O) annotation, (O) all (O) of (O) which (O) will (O) be (O) made (O) freely (O) available. (O) 
This (O) paper (O) gives (O) a (O) general (O) outline (O) of (O) the (O) data (O) collected (O) so (O) far, (O) as (O) well (O) as (O) a (O) detailed (O) description (O) of (O) how (O) this (O) has (O) been (O) done, (O) emphasizing (O) the (O) minimal (O) [language-specific (B) knowledge (I)] and (O) manual (O) intervention (O) used (O) to (O) compile (O) the (O) corpus. (O) 
To (O) demonstrate (O) its (O) potential (O) use, (O) [text-to-speech (B) systems (I)] have (O) been (O) built (O) for (O) all (O) languages (O) using (O) unsupervised (O) or (O) [lightly (B) supervised (I) methods (I)], also (O) briefly (O) presented (O) in (O) the (O) paper. (O) 
Index (O) Terms (O) : [multilingual (B) corpus (I)], [light (B) supervision (I)], [imperfect (B) data (I)], found (O) data, (O) [text-to-speech (B)], [audiobook (B) data (I)] 

Introduction (O) 
Building (O) a (O) [text-to-speech (B) (TTS) (I) conversion (I) system (I)] for (O) a (O) new (O) language (O) has (O) in (O) the (O) past (O) been (O) an (O) expensive (O) and (O) time-consuming (O) activity. (O) 
Using (O) data-driven (O) methods (O) to (O) build, (O) for (O) example, (O) a (O) [statistical (B) parametric (I) waveform (I) generation (I)] module (O) or (O) [TTS (B) back-end (I)], can (O) alleviate (O) to (O) some (O) extent (O) the (O) lack (O) of (O) expert (O) [linguistic (B) knowledge (I)]. 
Even (O) then, (O) however, (O) a (O) recording (O) script (O) must (O) be (O) prepared, (O) a (O) [voice (B) talent (I)] recruited (O) and (O) [high-quality (B) speech (I)] recording (O) carefully (O) supervised. (O) 
Also (O) problematic (O) is (O) the (O) text-processing (O) component (O) of (O) the (O) system, (O) i.e. (O) the (O) [TTS (B) front-end (I)], if (O) none (O) is (O) available (O) for (O) the (O) [target (B) language (I)]. 
A (O) [front-end (B)] is (O) made (O) up (O) of (O) [rule-based (B)] or (O) statistical (O) modules (O) ; acquiring (O) the (O) expert (O) knowledge (O) required (O) either (O) to (O) manually (O) specify (O) those (O) rules, (O) or (O) to (O) annotate (O) a (O) learning (O) sample (O) on (O) which (O) to (O) train (O) the (O) [statistical (B) models (I)], represents (O) a (O) major (O) obstacle (O) to (O) creating (O) a (O) [TTS (B) system (I)] for (O) a (O) new (O) [target (B) language (I)] and (O) requires (O) highly (O) specialised (O) knowledge. (O) 
Such (O) non-trivial (O) tasks (O) include, (O) for (O) example, (O) specifying (O) a (O) [phoneme-set (B)] or (O) [part (B) of (I) speech (I)] (POS) (O) [tag-set (B)] for (O) a (O) language (O) where (O) one (O) has (O) not (O) already (O) been (O) defined (O) ; annotating (O) plain (O) text (O) with (O) POS (O) tags, (O) as (O) required (O) to (O) train (O) a (O) [POS (B) tagger (I)] and (O) annotating (O) the (O) surface (O) forms (O) of (O) words (O) with (O) [phonemes (B)] to (O) build (O) a (O) [pronunciation (B) lexicon (I)]. 
One (O) of (O) the (O) primary (O) goals (O) of (O) the (O) project (O) Simple4All1 (O) is (O) to (O) produce (O) freely (O) available (O) tools (O) for (O) building (O) [TTS (B) systems (I)] with (O) little (O) or (O) no (O) expert (O) supervision (O) from (O) freely (O) available (O) existing (O) data. (O) 
These (O) tools (O) enable (O) us (O) to (O) sidestep (O) the (O) expense (O) associated (O) with (O) engineering (O) a (O) [speech (B) corpus (I)] in (O) each (O) new (O) [target (B) language (I)] from (O) scratch, (O) in (O) the (O) case (O) where (O) data (O) is (O) not (O) readily (O) available. (O) 
Our (O) [toolkit (B)] includes (O) modules (O) for (O) handling (O) imperfect (O) recording (O) conditions, (O) segmenting (O) [audio (B)] into (O) manageable (O) chunks, (O) and (O) aligning (O) those (O) chunks (O) with (O) a (O) chapter (O) or (O) book-level (O) text (O) transcription. (O) 
We (O) here (O) explain (O) how (O) these (O) tools (O) have (O) been (O) applied (O) to (O) existing (O) [audiobook (B) data (I)] in (O) 14 (O) languages, (O) most (O) of (O) it (O) freely (O) available, (O) to (O) create (O) a (O) [multilingual (B) corpus (I)] with (O) minimal (O) manual (O) intervention (O) and (O) [language-specific (B) expert (I) knowledge (I)]. 
The (O) result (O) of (O) this (O) processing (O) is (O) a (O) standardised (O) [multilingual (B) database (I)] of (O) ‘ (O) found’ (O) data, (O) which (O) we (O) release (O) under (O) the (O) name (O) [Tundra (B)]. 
There (O) has (O) been (O) much (O) recent (O) interest (O) in (O) in (O) using (O) found (O) data (O) to (O) produce (O) [TTS (B) systems (I)], in (O) particular, (O) [speech (B) data (I)] from (O) audiobook (O) recordings. (O) 
We (O) note (O) that (O) the (O) [Arctic (B) databases (I)] have (O) provided (O) a (O) valuable (O) resource (O) for (O) research (O) into (O) [TTS (B)] using (O) conventional (O) purpose-recorded (O) databases, (O) in (O) that (O) they (O) are (O) freely (O) available (O) and (O) serve (O) as (O) a (O) common (O) point (O) of (O) reference (O) for (O) benchmarking. (O) 
In (O) view (O) of (O) this (O) significant (O) and (O) growing (O) interest (O) in (O) building (O) [TTS (B) systems (I)] from (O) found (O) data, (O) we (O) feel (O) there (O) is (O) a (O) need (O) for (O) a (O) similarly (O) standardised (O) and (O) freely-[available (B) corpus (I)] of (O) found (O) data. (O) We (O) present (O) [Tundra (B)] to (O) the (O) [TTS (B)] researchommunity (O) in (O) the (O) hope (O) that (O) it (O) can (O) start (O) to (O) fill (O) that (O) need. (O) 
Our (O) [toolkit (B)] also (O) includes (O) modules (O) for (O) selecting (O) a (O) subset (O) of (O) utterances (O) with (O) a (O) uniform (O) speaking (O) style, (O) and (O) constructing (O) [TTS (B) systems (I)] from (O) text (O) and (O) [speech (B) data (I)] without (O) reliance (O) on (O) [language-specific (B) expert (I) knowledge (I)] or (O) on (O) conventional (O) linguistic (O) resources (O) such (O) as (O) [lexicons (B)], phonesets, (O) [part-of-speech (B) taggersetc (I)]. 
In (O) order (O) to (O) show (O) that (O) it (O) is (O) feasible (O) to (O) build (O) voices (O) on (O) corpora (O) built (O) with (O) such (O) minimal (O) expert (O) supervision, (O) we (O) also (O) present (O) a (O) demonstration (O) of (O) [TTS (B) systems (I)] that (O) we (O) have (O) built (O) by (O) applying (O) these (O) tools (O) to (O) [Tundra (B)]. 
We (O) do (O) not (O) present (O) detailed (O) explanation, (O) evaluation (O) and (O) analysis (O) of (O) these (O) demo (O) systems (O) here (O) due (O) to (O) space (O) limitations, (O) and (O) refer (O) interested (O) readers (O) to, (O) where (O) such (O) details (O) will (O) be (O) given. (O) 
An (O) initial (O) public (O) version (O) of (O) the (O) [Simple4All (B) tools (I)] used (O) to (O) compile (O) the (O) corpus (O) and (O) build (O) the (O) [demo (B) voices (I)] is (O) due (O) to (O) be (O) released (O) in (O) November (O) 2013. (O) 

www.simple4all.org/ (O)    

[Corpus (B) Construction (I)] 
In (O) this (O) section (O) we (O) describe (O) the (O) pipeline (O) of (O) [data (B) processing (I)] involved (O) in (O) building (O) the (O) [Tundra (B) corpus (I)], from (O) [speech (B)] denoisingand (O) deverberation (O) to (O) [lightly (B) supervised (I) speech (I)] and (O) text (O) alignment. (O) 
All (O) the (O) steps (O) presented (O) in (O) the (O) following (O) subsections (O) are (O) based (O) solely (O) on (O) found (O) [speech (B)] and (O) text (O) resources (O) and (O) could (O) be (O) easily (O) applied (O) to (O) any (O) other (O) resource, (O) even (O) by (O) non-expert (O) users. (O) 
As (O) regards (O) language (O) dependency, (O) the (O) only (O) step (O) which (O) requires (O) familiarity (O) with (O) at (O) least (O) the (O) script (O) of (O) the (O) [target (B) language (I)] is (O) the (O) first (O) step (O) of (O) matching (O) 10 (O) minutes (O) of (O) [speech (B)] with (O) an (O) orthographic (O) transcript. (O) 
All (O) the (O) other (O) processes (O) can (O) be (O) performed (O) by (O) the (O) users (O) with (O) little (O) or (O) no (O) training (O) in (O) [speech (B) processing (I)] and (O) without (O) relying (O) on (O) any (O) [target (B) language (I) knowledge (I)]. 

[Speech (B)] Pre-processing (O) 
Conventional (O) [TTS (B) corpora (I)] deliver (O) [speech (B)] recorded (O) in (O) noise-free (O) non-reverberant (O) environments, (O) and (O) thus (O) lead (O) to (O) [high-quality (B) synthetic (I) speech (I)]. 
Found (O) data, (O) on (O) the (O) other (O) hand (O) are (O) usually (O) recorded (O) in (O) sub-optimal (O) conditions, (O) and (O) without (O) professional (O) recording (O) equipment. (O) 
Therefore, (O) when (O) building (O) [TTS (B) systems (I)] on (O) this (O) type (O) of (O) data, (O) some (O) pre-processing (O) steps (O) are (O) in (O) order. (O) 
For (O) [Tundra (B)], recordings (O) which (O) casual (O) listening (O) suggested (O) were (O) sub-optimal (O) went (O) through (O) the (O) following (O) pre-processing (O) steps, (O) applied (O) to (O) each (O) recording (O) session (O) individually,2 (O) so (O) that (O) variations (O) in (O) between (O) them (O) can (O) be (O) normalised (O) : 
Noise (O) reduction (O) : uses (O) a (O) multi-band (O) noise (O) gate (O) removal (O) with (O) a (O) 20dB (O) noise (O) reduction (O) threshold, (O) a (O) frequency (O) smoothing (O) of (O) 150 (O) Hz (O) and (O) 0.15 (O) second (O) decay (O) time. (O) 
The (O) noise (O) profile (O) was (O) selected (O) from (O) the (O) initial (O) silence (O) segments (O) of (O) each (O) [speech (B) file (I)]. 
Normalisation (O) : DC (O) offset (O) was (O) removed, (O) and (O) the (O) recordings (O) were (O) normalised (O) to (O) a (O) maximum (O) amplitude (O) of (O) -0.1 (O) dB, (O) so (O) that (O) the (O) average (O) energy (O) level (O) is (O) the (O) same (O) across (O) different (O) recording (O) sessions. (O) 
Deverberation (O) : was (O) performed (O) using (O) a (O) RMS (O) based (O) algorithm, (O) with (O) a (O) smoothing (O) of (O) 40 (O) ms (O) and (O) a (O) release (O) of (O) 400ms. (O) 

[Lightly-supervised (B) Audio (I) Segmentation (I)] 
Current (O) [parametric (B) TTS (I) systems (I)] generally (O) use (O) [training (B) data (I)] which (O) is (O) segmented (O) into (O) sentence-length (O) chunks, (O) and (O) rarely (O) make (O) use (O) of (O) contexts (O) beyond (O) the (O) current (O) sentence. (O) 
The (O) small (O) length (O) of (O) the (O) [training (B) data (I)] is (O) also (O) a (O) limitation (O) of (O) the (O) forced (O) alignment (O) algorithm (O) while (O) training. (O) 
Although (O) several (O) algorithms (O) have (O) been (O) proposed (O) to (O) enable (O) the (O) use (O) of (O) longer (O) [speech (B) segments (I)], we (O) still (O) consider (O) that (O) sentence-length (O) utterances (O) are (O) the (O) building (O) blocks (O) of (O) [TTS (B)], and (O) longer (O) segments (O) can (O) be (O) easily (O) obtained (O) by (O) concatenating (O) the (O) former, (O) thus (O) ensuring (O) a (O) paragraph (O) or (O) maybe (O) chapter (O) level (O) analysis (O) or (O) training. (O) 
presents (O) a (O) [lightly (B) supervised (I) method (I)] for (O) the (O) segmentation (O) of (O) [speech (B)] into (O) sentences. (O) The (O) method (O) uses (O) a (O) small (O) amount (O) of (O) manually (O) labelled (O) data, (O) in (O) which (O) the (O) silence (O) between (O) sentences (O) is (O) marked (O) for (O) around (O) 5 (O) to (O) 10 (O) minutes (O) of (O) [speech (B)]. 
Silence (O) marking (O) is (O) a (O) trivial (O) task (O) and (O) requires (O) no (O) technical (O) knowledge. (O) 
Using (O) the (O) initial (O) [training (B) data (I)], standard (O) [Gaussian (B)] mixture (O) models (O) (GMMs) (O) with (O) 16 (O) components (O) are (O) trained (O) for (O) [speech (B)] and (O) silence (O) respectively. (O) 
The (O) observation (O) [vectors (B)] consist (O) of (O) energy, (O) 12 (O) dimensional (O) MFCCs, (O) their (O) [delta (B) features (I)], and (O) the (O) number (O) of (O) zero (O) crossings (O) in (O) a (O) frame. (O) 
The (O) distinction (O) between (O) [speech (B)] and (O) silence (O) is (O) made (O) by (O) calculating (O) the (O) [log (B) likelihood (I)] ratio (O) (LLR) (O) of (O) each (O) frame. (O) 
The (O) framewise (O) LLR (O) is (O) smoothed (O) using (O) a (O) moving (O) median (O) filter. (O) 
While (O) doing (O) sentence (O) level (O) segmentation, (O) an (O) important (O) aspect (O) is (O) to (O) discriminate (O) between (O) within-sentence (O) breaks, (O) and (O) sentence (O) boundary (O) breaks. (O) 
Therefore, (O) the (O) trained (O) GMMs (O) likelihood (O) scores (O) are (O) evaluated (O) on (O) the (O) [training (B) data (I)], and (O) the (O) durations (O) of (O) the (O) sentence (O) boundary (O) silence (O) segments (O) and (O) the (O) durations (O) of (O) within-sentence (O) silence (O) segments (O) are (O) computed. (O) 
Two (O) [Gaussian (B)] PDFs (O) are (O) then (O) fitted (O) to (O) the (O) two (O) model (O) durations. (O) 
The (O) intersection (O) point (O) of (O) the (O) two (O) PDFs (O) is (O) used (O) as (O) a (O) duration (O) threshold (O) to (O) classify (O) silent (O) segments (O) as (O) either (O) sentence-internal (O) or (O) sentence (O) boundary (O) breaks. (O) 
Results (O) presented (O) in (O) showed (O) that (O) this (O) method (O) when (O) applied (O) to (O) an (O) English (O) audiobook, (O) successfully (O) identified (O) most (O) of (O) the (O) sentence (O) boundaries. (O) 
We (O) also (O) evaluate (O) it (O) in (O) this (O) paper (O) by (O) comparing (O) [speech (B)]-based segmentation (O) results (O) against (O) the (O) text (O) based (O) ones. (O) 

Audiobooks (O) are (O) usually (O) distributed (O) in (O) chapter-size (O) chunks (O) which (O) correspond (O) to (O) one (O) recording (O) session. (O) 

[Lightly-supervised (B) Speech (I)] and (O) Text (O) Alignment (O) 
In (O)   we (O) first (O) introduced (O) a (O) method (O) for (O) the (O) automatic (O) alignment (O) of (O) [speech (B) data (I)] with (O) unsynchronised, (O) imperfect (O) transcripts, (O) for (O) a (O) domain (O) where (O) no (O) initial (O) [acoustic (B) models (I)] are (O) available. (O) 
As (O) opposed (O) to, (O) where (O) existing (O) [high-quality (B)] acoustic (O) and (O) language (O) models (O) are (O) used, (O) our (O) method (O) requires (O) only (O) relatively (O) low-quality (O) [grapheme-based (B) acoustic (I) models (I)] trained (O) solely (O) on (O) the (O) [speech (B)] resource (O) to (O) be (O) aligned. (O) 
To (O) overcome (O) the (O) lack (O) of (O) good (O) [acoustic (B) models (I)], the (O) [ASR (B)] decoding (O) network (O) is (O) limited (O) to (O) a (O) sequence (O) of (O) words (O) derived (O) from (O) the (O) approximate (O) transcript, (O) similar (O) to. (O) 
This (O) sequence (O) is (O) called (O) a (O) skip (O) network. (O) 
The (O) confidence (O) of (O) the (O) alignment (O) is (O) ranked (O) based (O) on (O) the (O) acoustic (O) scores (O) obtained (O) in (O) the (O) decoding (O) process (O) with (O) different (O) degrees (O) of (O) freedom (O) included (O) in (O) the (O) skip (O) network. (O) 
Manual (O) intervention (O) is (O) limited (O) to (O) matching (O) the (O) first (O) 10 (O) minutes (O) of (O) [speech (B)] with (O) the (O) correct (O) text (O) transcription, (O) to (O) provide (O) data (O) for (O) training (O) the (O) initial (O) [acoustic (B) models (I)], similar (O) to. (O) 
This (O) feature (O) makes (O) the (O) method (O) easily (O) applicable (O) in (O) any (O) language (O) employing (O) an (O) alphabetic (O) writing (O) system, (O) and (O) enables (O) the (O) use (O) of (O) found (O) data (O) without (O) the (O) hassle (O) of (O) manually (O) transcribing (O) its (O) entirety. (O) 
Initial (O) results (O) on (O) the (O) English (O) audiobook (O) A (O) Tramp (O) Abroad (O) by (O) Mark (O) Twain3 (O) showed (O) an (O) average (O) 55 (O) % [confident (B) data (I)], with (O) a (O) [WER (B)] of (O) 1 (O) % and (O) SER (O) of (O) 8 (O) %. (O) 
Since (O) then, (O) the (O) [acoustic (B) model (I) training (I)] has (O) been (O) extended (O) to (O) [tri-grapheme (B)] and (O) [lightly (B) supervised (I)] discriminative (O) training, (O) which (O) led (O) to (O) an (O) average (O) of75 (O) % [confident (B) data (I)] with (O) similar (O) word (O) and (O) sentence (O) error (O) rates. (O) 
One (O) major (O) loss (O) in (O) sentence (O) accuracy (O) rates (O) is (O) due (O) to (O) utterance (O) initial (O) and (O) final (O) word (O) deletions (O) and (O) insertions, (O) which (O) can (O) not (O) be (O) correctly (O) detected (O) by (O) the (O) current (O) confidence (O) measure. (O) However, (O) previous (O) studies (O) showed (O) that (O) phone (O) errors (O) less (O) than (O) 1 (O) % do (O) not (O) degrade (O) the (O) quality (O) of (O) the (O) [synthetic (B) speech (I)]. 
The (O) output (O) of (O) the (O) alignment (O) process (O) is (O) a (O) set (O) of (O) segmented (O) [speech (B) files (I)] with (O) their (O) corresponding (O) orthographic (O) transcripts, (O) including (O) punctuation, (O) and (O) also (O) a (O) time (O) alignment (O) of (O) the (O) segments (O) within (O) the (O) initial (O) [speech (B) data (I)]. 

The (O) Corpus (O) 
The (O) procedures (O) described (O) above (O) have (O) been (O) applied (O) to (O) a (O) number (O) of (O) freely (O) available (O) found (O) resources. (O) 
Audiobooks (O) were (O) a (O) first (O) choice, (O) as (O) they (O) are (O) a (O) readily (O) available (O) in (O) multiple (O) languages (O) and (O) are (O) generally (O) read (O) by (O) a (O) [single (B) speaker (I)] and (O) recorded (O) with (O) equipment (O) of (O) at (O) least (O) reasonable (O) quality. (O) 
Another (O) advantage (O) would (O) be (O) that (O) by (O) using (O) cohesive (O) and (O) expressive (O) [spoken (B) data (I)] as (O) the (O) basis (O) for (O) training (O) a (O) [TTS (B) system (I)] might (O) yield (O) more (O) cohesive (O) and (O) expressive (O) multi-utterance (O) [TTS (B) output (I)], fact (O) which (O) explains (O) the (O) high (O) interest (O) in (O) them (O) lately. (O) 
This (O) latter (O) advantage (O) is (O) not (O) especially (O) made (O) use (O) of (O) in (O) the (O) [demo (B) voices (I)] presented (O) here, (O) but (O) is (O) the (O) subject (O) of (O) on-going (O) work (O) for (O) us (O) elsewhere. (O) 
To (O) emphasise (O) the (O) utility (O) of (O) audiobooks (O) in (O) [TTS (B)] systems, (O) in (O) Fig. (O)   we (O) present (O) a (O) comparison (O) between (O) standard (O) [TTS (B) corpora (I)] and (O) audiobooks (O) with (O) respect (O) to (O) logF0 (O) in (O) 4 (O) different (O) languages. (O) 
The (O) standard (O) [TTS (B) corpora (I)] are (O) : a (O) subset (O) of (O) the (O) database (O) called (O) ‘ (O) Nina’ (O) in, (O) a (O) subset (O) of (O) a (O) corpus (O) of (O) Finnish (O) [speech (B)] recorded (O) from (O) a (O) [female (B) speaker (I)] specifically (O) for (O) [TTS (B)] purposes, (O) SEV (O) neutral (O) and (O) RSS. (O) 

http://librivox.org/a-tramp-abroad-by-mark-twain/ (O) 


Table (O) : [Simple4All (B) Tundra (I) Corpus (I) overview (I)] 

Figure (O) : logF0 (O) comparison (O) of (O) conventional (O) [TTS (B) corpora (I)] versus (O) [audiobook (B) data (I)] in (O) four (O) languages (O) : English (O) (EN), (O) Spanish (O) (ES), (O) Finnish (O) (FI) (O) and (O) Romanian (O) (RM). (O) 
A (O) denotes (O) the (O) [audiobook (B) data (I)], and (O) S (O) denotes (O) the (O) standard (O) [TTS (B) database (I)]. 
The (O) standard (O) [corpora (B) speaker (I)] genders (O) are (O) the (O) same (O) as (O) the (O) selected (O) audiobooks. (O) 

Figure (O) : logF0 (O) boxplots (O) for (O) all (O) languages. (O) Language (O) codes (O) are (O) given (O) in (O) Table (O) 

It (O) can (O) be (O) easily (O) observed (O) that (O) the (O) audiobooks (O) have (O) a (O) greater (O) standard (O) deviation (O) compared (O) with (O) conventional (O) corpora, (O) which (O) means (O) that (O) they (O) could (O) easily (O) provide (O) a (O) much (O) richer (O) prosodic (O) context. (O) 
This (O) aspect (O) can (O) also (O) be (O) noticed (O) from (O) Fig. (O) where (O) logF0 (O) distributions (O) are (O) plotted (O) for (O) all (O) the (O) languages (O) of (O) the (O) corpus. (O) 
As (O) a (O) result, (O) [Tundra (B)] 1.0 (O) includes (O) 14 (O) audiobooks (O) in (O) 14 (O) languages (O) : Bulgarian, (O) Danish, (O) Dutch, (O) English, (O) Finnish, (O) French, (O) German, (O) Hungarian, (O) Italian, (O) Polish, (O) Portuguese, (O) Romanian, (O) Russian (O) and (O) Spanish. (O) 
Language (O) selection (O) was (O) based (O) on (O) the (O) availability (O) of (O) both (O) [speech (B) and (I) text (I) data (I)], as (O) well (O) as (O) the (O) language (O) having (O) an (O) alphabetic (O) writing (O) system (O) (in (O) this (O) case, (O) Latin (O) and (O) Cyrillic (O) alphabets). (O) 
Important (O) resources (O) for (O) these (O) are (O) the (O) Librivox (O) and (O) Gutenberg4 (O) projects, (O) which (O) are (O) the (O) sources (O) for (O) most (O) of (O) the (O) data (O) used (O) to (O) compile (O) [Tundra (B)]. 
The (O) complete (O) list (O) [speech (B)] and (O) text (O) sources (O) can (O) be (O) found (O) here (O) http://tundra.simple4all.org/. (O) 

http://librivox.org (O) and (O) http://gutenberg.org/ (O) 

Table (O) presents (O) an (O) overview (O) of (O) the (O) [entire (B) corpus (I)], including (O) title (O) and (O) author (O) of (O) the (O) audiobook, (O) [speaker (B) gender (I)] and (O) total (O) duration. (O) 
There (O) are (O) 8 (O) male (O) and (O) 6 (O) [female (B) speakers (I)], and (O) the (O) aligned (O) corpus (O) amounts (O) to (O) approximately (O) 60 (O) hours (O) of (O) [speech (B)]. 
For (O) the (O) final (O) set (O) of (O) utterances (O) included (O) in (O) this (O) corpus, (O) each (O) audiobook (O) underwent (O) the (O) steps (O) described (O) in (O) the (O) Section (O) and (O) which (O) are (O) schematically (O) depicted (O) in (O) Fig. (O) 
Audiobook (O) chapters (O) were (O) converted (O) from (O) mp3 (O) to (O) wav (O) format (O) and (O) then (O) cleaned (O) if (O) the (O) overall (O) quality (O) was (O) considered (O) low. (O) 
The (O) first (O) 10 (O) minutes (O) of (O) [speech (B)] were (O) then (O) annotated (O) with (O) silence (O) segments (O) and (O) manually (O) transcribed. (O) 
Manual (O) transcription (O) proved (O) to (O) be (O) a (O) trivial (O) task, (O) and (O) based (O) on (O) the (O) book (O) text, (O) the (O) authors (O) were (O) able (O) to (O) perform (O) it, (O) although (O) they (O) do (O) not (O) speak (O) most (O) of (O) the (O) languages (O) included (O) in (O) the (O) corpus. (O) 
For (O) the (O) Cyrillic (O) writing (O) system (O) languages (O) (i.e. (O) Bulgarian (O) and (O) Russian), (O) [native (B) speakers (I)] were (O) asked (O) to (O) correct (O) an (O) initial (O) transcription (O) provided (O) by (O) the (O) authors. (O) 
Data (O) was (O) then (O) segmented (O) using (O) the (O) VAD (O) algorithm, (O) and (O) the (O) resulting (O) number (O) of (O) [speech (B)] utterances (O) is (O) presented (O) in (O) Table (O) alongside (O) the (O) text-based (O) segmentation. (O) 

For (O) example, (O) the (O) Spanish (O) and (O) [Romanian (B) data (I)] are (O) professional (O) recordings (O) which (O) did (O) not (O) require (O) any (O) pre-processing. (O) 
We (O) currently (O) decide (O) whether (O) to (O) pre-process (O) recordings (O) based (O) on (O) informal (O) listening, (O) but (O) aim (O) to (O) automate (O) this (O) with (O) an (O) objective (O) measure (O) of (O) [speech (B) quality (I)] in (O) future (O) versions (O) of (O) our (O) [toolkit (B)].               

The (O) difference (O) between (O) the (O) number (O) of (O) VAD (O) and (O) text (O) utterances (O) results (O) from (O) the (O) writing (O) style (O) of (O) the (O) book (O) (i.e. (O) mostly (O) dialogue, (O) or (O) mostly (O) descriptive) (O) and (O) the (O) fact (O) that (O) in (O) the (O) alignment (O) process, (O) in (O) order (O) to (O) obtain (O) the (O) [most (B) data (I)] from (O) the (O) audiobook, (O) segmented (O) utterances (O) which (O) are (O) shorter (O) than (O) a (O) specified (O) threshold (O) (5 (O) seconds (O) for (O) these (O) data) (O) are (O) concatenated. (O) 
After (O) the (O) alignment (O) process, (O) an (O) average (O) of (O) 68 (O) % of (O) the (O) data (O) were (O) considered (O) confident (O) and (O) included (O) in (O) the (O) [final (B) corpus (I)]. 
Table (O)   presents (O) the (O) duration (O) of (O) the (O) aligned (O) data (O) and (O) its (O) percentage (O) from (O) the (O) total (O) duration. (O) This (O) percentage (O) appears (O) to (O) be (O) highly (O) dependent (O) on (O) : 
a) (O) the (O) total (O) amount (O) of (O) data (O) available (O) : see (O) the (O) low (O) percentage (O) of (O) the (O) Danish (O) audiobook (O) which (O) has (O) only (O) 2.1 (O) hours (O) ; 
b) (O) [speaker (B) gender (I)] : [female (B) voices (I)] seem (O) to (O) have (O) a (O) lower (O) alignment (O) percentage (O) ; 
c) (O) [grapheme-to-phoneme (B) language (I) complexity (I)] : see (O) English (O) and (O) French (O) versus (O) Italian (O) and (O) German (O) ; 
and (O) d) (O) [speaker (B) characteristics (I)] : speaking (O) rhythm, (O) degree (O) of (O) expresivity, (O) as (O) well (O) as (O) [general (B) voice (I)] quality (O) also (O) affect (O) the (O) results. (O) 
SER (O) and (O) [WER (B) values (I)] for (O) the (O) aligned (O) audiobooks (O) could (O) not (O) be (O) exactly (O) determined, (O) as (O) this (O) would (O) have (O) required (O) their (O) full (O) manual (O) transcription, (O) which (O) is (O) outside (O) the (O) scope (O) of (O) this (O) [corpus (B) building (I)] procedure. (O) 
However, (O) one (O) chapter (O) from (O) each (O) audiobook (O) in (O) the (O) languages (O) spoken (O) by (O) the (O) authors (O) was (O) evaluated, (O) and (O) the (O) errors (O) tend (O) to (O) be (O) similar (O) to (O) those (O) in, (O) meaning (O) a (O) less (O) than (O) 1 (O) % [WER (B)] and (O) a (O) 8 (O) % SER. (O) 
Higher (O) error (O) rates (O) were (O) reported (O) for (O) the (O) noisier (O) [speech (B) data (I)] (see (O) Table (O) for (O) general (O) signal-to-noise (O) ratios). (O) 
To (O) be (O) useful (O) as (O) a (O) standardised (O) [TTS (B) corpus (I)], [Tundra (B)] is (O) also (O) partitioned (O) into (O) training (O) and (O) test (O) sets. (O) 
To (O) ensure (O) a (O) satisfactory (O) amount (O) of (O) [testing (B) data (I)] even (O) for (O) the (O) shortest (O) audiobook, (O) the (O) [test (B) data (I)] were (O) selected (O) from (O) the (O) final (O) chapters (O) / parts (O) of (O) the (O) audiobooks, (O) so (O) that (O) they (O) amount (O) to (O) at (O) least (O) 10 (O) % of (O) the (O) aligned (O) duration (O) of (O) it. (O) 
The (O) entire (O) segmented (O) and (O) [aligned (B) corpus (I)], along (O) with (O) the (O) chapter-wise (O) time (O) alignment (O) and (O) training (O) / test (O) set (O) division (O) of (O) can (O) be (O) downloaded (O) from (O) http://tundra.simple4all.org (O) 

Spanish (O) and (O) Romanian (O) also (O) have (O) very (O) simple (O) [G2P (B)] rules, (O) but (O) the (O) speakers’ (O) greater (O) expressivity (O) limits (O) the (O) alignner’s (O) performance. (O) 
This (O) being (O) a (O) subjective (O) measure, (O) we (O) encourage (O) readers (O) to (O) listen (O) to (O) samples (O) of (O) the (O) audiobooks. (O) 
        
Figure (O) : Outline (O) of (O) [corpus (B) construction (I)] and (O) [voice (B) building (I)] 

Demo (O) 
To (O) show (O) the (O) feasibility (O) of (O) using (O) a (O) corpus (O) that (O) has (O) been (O) compiled (O) with (O) such (O) minimal (O) intervention (O) and (O) [language-specific (B) expertise (I)], we (O) have (O) used (O) it (O) to (O) build (O) demo (O) [TTS (B) voices (I)] in (O) the (O) corpuslanguages. (O) 
To (O) build (O) these (O) voices (O) we (O) first (O) select (O) a (O) subset (O) of (O) utterances (O) spoken (O) in (O) a (O) homogenous (O) style (O) using (O) a (O) slightly (O) supervised (O) active (O) learning-based (O) approach. (O) 
We (O) then (O) employ (O) a (O) [toolkit (B)] which (O) has (O) been (O) specifically (O) designed (O) to (O) construct (O) [TTS (B) front-ends (I)] while (O) making (O) as (O) few (O) implicit (O) assumptions (O) about (O) the (O) [target (B) language (I)] as (O) possible, (O) and (O) to (O) be (O) configurable (O) with (O) minimal (O) effort (O) and (O) expert (O) knowledge (O) to (O) suit (O) arbitrary (O) new (O) [target (B) languages (I)]. 
The (O) modules (O) of (O) our (O) [toolkit (B)] therefore (O) rely (O) where (O) possible (O) on (O) resources (O) which (O) are (O) intended (O) to (O) be (O) universal. (O) 
For (O) example, (O) to (O) tokenise (O) input (O) text (O) we (O) rely (O) on (O) character (O) properties (O) given (O) in (O) the (O) Unicode (O) [character (B) database (I)] – (O) a (O) regular (O) expression (O) defined (O) over (O) these (O) properties (O) has (O) so (O) far (O) produced (O) sensible (O) tokenisations (O) in (O) a (O) variety (O) of (O) alphabetic (O) (Latin-based, (O) Cyrillic) (O) and (O) alphasyllabic (O) (Brahmic) (O) scripts.) (O) 
A (O) [letter-based (B) approach (I)] is (O) used, (O) in (O) which (O) the (O) names (O) of (O) letters (O) are (O) used (O) directly (O) as (O) the (O) names (O) of (O) [speech (B)] modelling (O) units (O) (in (O) place (O) of (O) the (O) [phonemes (B)] of (O) a (O) conventional (O) [front-end (B)]). 
This (O) has (O) given (O) good (O) results (O) for (O) languages (O) with (O) transparent (O) alphabetic (O) orthographies (O) such (O) as (O) Romanian, (O) Spanish (O) and (O) Finnish, (O) and (O) can (O) give (O) acceptable (O) results (O) even (O) for (O) languages (O) with (O) less (O) transparent (O) orthographies, (O) such (O) as (O) English. (O) 
Furthermore, (O) our (O) tools (O) make (O) no (O) use (O) of (O) expert-specified (O) categories (O) of (O) letter (O) and (O) word, (O) such (O) as (O) [phonetic (B) categories (I)] (vowel, (O) nasal, (O) approximant, (O) etc.) (O) and (O) [part (B) of (I) speech (I) categories (I)] (noun, (O) verb, (O) adjective, (O) etc.). (O) 
Instead, (O) we (O) use (O) features (O) that (O) are (O) designed (O) to (O) stand (O) in (O) for (O) such (O) expert (O) knowledge (O) but (O) which (O) are (O) derived (O) fully (O) automatically (O) from (O) the (O) distributional (O) analysis (O) of (O) plain (O) text (O) in (O) the (O) [target (B) language (I)]. 
Samples (O) of (O) the (O) voices (O) can (O) be (O) heard (O) at (O) http://tundra.simple4all.org/demo/. (O) 
For (O) reasons (O) of (O) space (O) we (O) refer (O) readers (O) interested (O) in (O) full (O) presentation (O) and (O) evaluation (O) of (O) thesesystems (O) to. (O) 

Conclusion (O) 
We (O) have (O) introduced (O) a (O) first (O) version (O) of (O) the (O) [Simple4All (B) Tundra (I) corpus (I)], and (O) described (O) its (O) construction (O) from (O) readily (O) available (O) [speech (B) data (I)]. 
14 (O) audiobooks (O) in (O) 14 (O) languages (O) have (O) been (O) so (O) far (O) included (O) in (O) the (O) corpus (O) along (O) with (O) their (O) orthographic (O) transcripts. (O) 
[Tundra (B)] will (O) be (O) extended (O) in (O) the (O) future (O) with (O) other (O) types (O) of (O) imperfect, (O) found (O) data, (O) such (O) as (O) lectures, (O) or (O) parliamentary (O) [speech (B)], data (O) which (O) have (O) a (O) higher (O) degree (O) of (O) spontaneity (O) and (O) expressivity. (O) 
We (O) will (O) also (O) aim (O) at (O) making (O) available (O) finer-grained (O) alignments (O) of (O) the (O) data, (O) and (O) also (O) more (O) elaborate (O) prosodic (O) annotations, (O) such (O) as (O) style (O) diarisation, (O) emphasis (O) or (O) sentiment (O) analysis. (O) 
The (O) [TTS (B) systems (I)] built (O) from (O) this (O) corpus (O) demonstrate (O) a (O) first (O) application (O) of (O)   the (O) [Tundra (B) corpus (I)], and (O) support (O) its (O) usefulness. (O) 

Acknowledgements (O) 
The (O) research (O) leading (O) to (O) these (O) results (O) has (O) received (O) funding (O) from (O) the (O) European (O) Community’s (O) Seventh (O) Framework (O) Programme (O) (FP7/2007-2013) (O) under (O) grant (O) agreement (O) No (O) 287678. (O) 
The (O) research (O) presented (O) here (O) has (O) made (O) use (O) of (O) the (O) resources (O) provided (O) by (O) the (O) Edinburgh (O) Compute (O) and (O) [Data (B) Facility (I)] (ECDF (O) : http://www.ecdf.ed.ac.uk). (O) 
The (O) ECDF (O) is (O) partially (O) supported (O) by (O) the (O) eDIKT (O) initiative (O) (http://www.edikt.org.uk). (O) 
We (O) would (O) like (O) to (O) thank (O) Mihai (O) Nae (O) from (O) Cartea (O) Sonora (O) for (O) releasing (O) the (O) [Romanian (B) data (I)], as (O) well (O) as (O) to (O) all (O) the (O) volunteers (O) at (O) Librivox (O) and (O) Gutenberg (O) for (O) dedicating (O) their (O) time (O) to (O) distribute (O) this (O) wide (O) variety (O) of (O) data. (O)