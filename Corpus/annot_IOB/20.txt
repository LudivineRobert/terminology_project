Unsupervised (O) and (O) [lightly-supervised (B) learning (I)] for (O) rapid (O) construction (O) of (O) [TTS (B) systems (I)] in (O) multiple (O) languages (O) from (O) ‘ (O) found’ (O) data (O) : evaluation (O) and (O) analysis (O) 

Abstract (O) 

This (O) paper (O) presents (O) techniques (O) for (O) building (O) [text-to-speech (B) frontends (I)] in (O) a (O) way (O) that (O) avoids (O) the (O) need (O) for (O) [language-specific (B) expert (I) knowledge (I)], but (O) instead (O) relies (O) on (O) universal (O) resources (O) (such (O) as (O) the (O) Unicode (O) [character (B) database (I)]) and (O) [unsupervised (B) learning (I)] from (O) [unannotated (B) data (I)] to (O) ease (O) system (O) development. (O) 
The (O) acquisition (O) of (O) expert (O) [language-specific (B) knowledge (I)] and (O) expert (O) [annotated (B) data (I)] is (O) a (O) major (O) bottleneck (O) in (O) the (O) development (O) of (O) corpusbased (O) [TTS (B) systems (I)] in (O) new (O) languages. (O) 
The (O) methods (O) presented (O) here (O) side-step (O) the (O) need (O) for (O) such (O) resources (O) as (O) [pronunciation (B) lexicons (I)], [phonetic (B) feature (I)] sets, (O) [part (B) of (I) speech (I)] tagged (O) data, (O) etc. (O) 
The (O) paper (O) explains (O) how (O) the (O) techniques (O) introduced (O) are (O) applied (O) to (O) the (O) 14 (O) languages (O) of (O) a (O) corpus (O) of (O) ‘ (O) found’ (O) audiobook (O) data. (O) 
Results (O) of (O) an (O) evaluation (O) of (O) the (O) intelligibility (O) of (O) the (O) systems (O) resulting (O) from (O) applying (O) these (O) novel (O) techniques (O) to (O) this (O) data (O) are (O) presented. (O) 
Index (O) Terms (O) : [multilingual (B) speech (I) synthesis (I)], [unsupervised (B) learning (I)], [vector (B) space (I) model (I)], [text-to-speech (B)], [audiobook (B) data (I)]   

Introduction (O) 

Collecting (O) and (O) annotating (O) the (O) data (O) necessary (O) for (O) training (O) a (O) [corpus-based (B) text-to-speech (I) (TTS) (I) conversion (I) system (I)] in (O) a (O) new (O) language (O) requires (O) considerable (O) time (O) and (O) expert (O) knowledge. (O) 
Conventionally, (O) [audio (B) data (I)] for (O) training (O) a (O) [synthesiser (B) back-end (I)] (or (O) [waveform (B) generator (I)]) will (O) be (O) gathered (O) during (O) a (O) speciallyarranged (O) recording (O) session. (O) 
For (O) this, (O) a (O) recording (O) script (O) must (O) be (O) prepared, (O) a (O) suitable (O) studio (O) must (O) be (O) found, (O) a (O) [voice (B) talent (I)] must (O) be (O) recruited (O) and (O) [speech (B) recording (I)] must (O) be (O) carefully (O) supervised. (O) 
One (O) of (O) the (O) primary (O) goals (O) of (O) the (O) [Simple4All (B)] 1 (O) project (O) is (O) to (O) reduce (O) the (O) time (O) and (O) expert (O) knowledge (O) needed (O) to (O) produce (O) new (O) [TTS (B) systems (I)]. 
In (O) we (O) presented (O) a (O) [toolkit (B)] – (O) developed (O) as (O) part (O) of (O) this (O) project (O) – (O) for (O) segmenting (O) and (O) aligning (O) existing (O) freely-available (O) recordings (O) (audiobooks), (O) circumventing (O) to (O) some (O) extent (O) the (O) need (O) to (O) engineer (O) purpose-recorded (O) [speech (B) corpora (I)]. 
The (O) outcome (O) of (O) applying (O) those (O) tools (O) to (O) audiobooks (O) in (O) 14 (O) languages (O) is (O) what (O) we (O) have (O) released (O) under (O) the (O) name (O) of (O) the (O) [Tundra (B) corpus (I)]. 
However, (O) the (O) problems (O) associated (O) with (O) [TTS (B) data-collection (I)] do (O) not (O) stop (O) when (O) we (O) have (O) obtained (O) transcribed (O) [speech (B) data (I)] for (O) training (O) a (O) [synthesiser (B) back-end (I)]. 
[TTS (B) systems (I)] also (O) require (O) a (O) [front-end (B)] (or (O) text (O) analysis (O) module), (O) which (O) accepts (O) input (O) text (O) and (O) outputs (O) a (O) representation (O) of (O) an (O) utterance (O) suitable (O) for (O) input (O) into (O) the (O) [back-end (B)]. 
[TTS (B) systems (I)] generally (O) represent (O) utterances (O) in (O) terms (O) of (O) units (O) and (O) features (O) based (O) on (O) [linguistic (B) knowledge (I)], such (O) as (O) [phonemes (B)], syllables, (O) lexical (O) stress, (O) phrase (O) boundaries (O) etc. (O) 
The (O) components (O) of (O) the (O) [front-end (B)] that (O) predict (O) these (O) from (O) input (O) text (O) are (O) either (O) made (O) up (O) of (O) hand-written (O) rules (O) or (O) statistical (O) modules (O) ; acquiring (O) the (O) expert (O) knowledge (O) required (O) either (O) to (O) manually (O) specify (O) those (O) rules, (O) or (O) to (O) annotate (O) a (O) learning (O) sample (O) on (O) which (O) to (O) train (O) the (O) [statistical (B) models (I)], represents (O) a (O) major (O) obstacle (O) to (O) creating (O) a (O) [TTS (B) system (I)] for (O) a (O) new (O) [target (B) language (I)] and (O) requires (O) highly (O) specialised (O) knowledge. (O) 
Such (O) non-trivial (O) tasks (O) include, (O) for (O) example, (O) specifying (O) a (O) [phoneme-set (B)] or (O) [part (B) of (I) speech (I)] (POS) (O) [tag-set (B)] for (O) a (O) language (O) where (O) one (O) has (O) not (O) already (O) been (O) defined (O) ; annotating (O) plain (O) text (O) with (O) POS (O) tags, (O) as (O) required (O) to (O) train (O) a (O) [POS (B) tagger (I)] and (O) annotating (O) the (O) surface (O) forms (O) of (O) words (O) with (O) [phonemes (B)] to (O) build (O) a (O) [pronunciation (B) lexicon (I)]. 
The (O) [toolkit (B)] we (O) are (O) developing (O) in (O) [Simple4All (B)] includes (O) tools (O) for (O) constructing (O) [TTS (B) front-ends (I)] which (O) make (O) as (O) few (O) implicit (O) assumptions (O) about (O) the (O) [target (B) language (I)] as (O) possible, (O) and (O) which (O) can (O) be (O) configured (O) with (O) minimal (O) effort (O) and (O) expert (O) knowledge (O) to (O) suit (O) arbitrary (O) new (O) [target (B) languages (I)]. 
To (O) this (O) end, (O) the (O) modules (O) rely (O) on (O) resources (O) which (O) are (O) intended (O) to (O) be (O) universal, (O) such (O) as (O) the (O) Unicode (O) [character (B) database (I)], and (O) employ (O) [unsupervised (B) learning (I)] so (O) that (O) unlabelled (O) text (O) resources (O) can (O) be (O) exploited (O) without (O) the (O) need (O) for (O) costly (O) annotation. (O) 
The (O) current (O) paper (O) presents (O) these (O) tools (O) and (O) explains (O) how (O) they (O) were (O) applied (O) to (O) the (O) data (O) of (O) the (O) [Tundra (B) corpus (I)] to (O) produce (O) [TTS (B) systems (I)] in (O) 14 (O) languages. (O) 
We (O) present (O) the (O) results (O) of (O) a (O) listening (O) test (O) of (O) the (O) intelligibility (O) of (O) those (O) systems, (O) and (O) thus (O) evaluate (O) the (O) entire (O) pipeline (O) implemented (O) by (O) our (O) [toolkit (B)], which (O) begins (O) with (O) raw (O) found (O) data (O) and (O) ends (O) with (O) trained (O) [TTS (B) systems (I)]. 
An (O) initial (O) public (O) version (O) of (O) tools (O) for (O) this (O) whole (O) pipeline (O) (for (O) segmenting (O) and (O) aligning (O) found (O) data (O) and (O) for (O) producing (O) [TTS (B) systems (I)] with (O) minimal (O) expert (O) knowledge) (O) is (O) due (O) to (O) be (O) released (O) in (O) November (O) 2013. (O) 
In (O) prior (O) work (O) addressing (O) the (O) bottleneck (O) in (O) [TTS (B) system (I)] construction (O) represented (O) by (O) the (O) [front-end (B)], unified (O) systems (O) aimed (O) at (O) producing (O) complete (O) systems (O) have (O) generally (O) taken (O) the (O) strategy (O) of (O) providing (O) infrastructure (O) to (O) ease (O) the (O) collection (O) by (O) non-experts (O) of (O) the (O) conventional (O) resources (O) necessary (O) for (O) system (O) construction. (O) 
This (O) infrastructure (O) might (O) take (O) the (O) form (O) of (O) user-friendly (O) development (O) environments, (O) or (O) training (O) and (O) on-going (O) support. (O) 
Prior (O) work (O) has (O) also (O) presented (O) unsupervised (O) methods (O) for (O) building (O) systems (O) based (O) on (O) letters (O) rather (O) than (O) [phonemes (B)], induction (O) of (O) [phone-sets (B)], syllable-like (O) units, (O) or (O) [lexicons (B)]. 
However, (O) this (O) work (O) has (O) not (O) been (O) presented (O) as (O) an (O) integrated (O) framework (O) for (O) producing (O) [end-to-end (B) TTS (I) systems (I)]. 
Furthermore, (O) despite (O) the (O) significant (O) work (O) on (O) [unsupervised (B) learning (I)] in (O) [Natural (B) Language (I) Processing (I)] and (O) Information (O) Retrieval, (O) potentially (O) useful (O) techniques (O) developed (O) in (O) those (O) fields (O) have (O) not (O) been (O) applied (O) to (O) the (O) problem (O) of (O) [TTS (B) front-end (I) induction (I)]. 

Database (O) 

The (O) [Tundra (B) corpus (I)] is (O) a (O) standardised (O) [multilingual (B) corpus (I)] designed (O) for (O) [text-to-speech (B) research (I)] with (O) imperfect (O) or (O) found (O) data. (O) 
It (O) consists (O) of (O) 14 (O) audiobooks (O) in (O) 14 (O) different (O) languages (O) (Bulgarian, (O) Danish, (O) Dutch, (O) English, (O) Finnish, (O) French, (O) German, (O) Hungarian, (O) Italian, (O) Polish, (O) Portuguese, (O) Romanian, (O) Russian (O) and (O) Spanish) (O) and (O) amounts (O) to (O) approximately (O) 60 (O) hours (O) of (O) [speech (B)]. 
A (O) complete (O) list (O) of (O) the (O) audiobooks (O) with (O) their (O) sources (O) and (O) durations (O) can (O) be (O) found (O) here (O) http://tundra.simple4all.org. (O) 
The (O) corpus (O) provides (O) [utterance-level (B) alignments (I)] obtained (O) with (O) a (O) [lightly (B) supervised (I) process (I)] described (O) in (O) and. (O) 
The (O) accuracy (O) of (O) the (O) alignment (O) method, (O) as (O) described (O) in (O) is (O) of (O) 7 (O) % SER (O) and (O) 0.8 (O) % [WER (B)], therefore (O) some (O) light (O) [post-processing (B)] is (O) required (O) in (O) order (O) to (O) eliminate (O) some (O) of (O) the (O) erroneous (O) utterances. (O) 
Initial (O) segmentation (O) of (O) the (O) audiobooks (O) into (O) utterancesize (O) chunks (O) was (O) performed (O) using (O) the (O) [lightly (B) supervised (I) GMMbased (I) VAD (I)] described (O) in. (O) 
As (O) most (O) of (O) the (O) used (O) audiobooks (O) are (O) recorded (O) in (O) non-specialised (O) environments, (O) the (O) [speech (B) data (I)] underwent (O) a (O) light (O) cleaning (O) process (O) : normalising (O) the (O) DC (O) offset, (O) applying (O) a (O) multi-band (O) noise (O) gate (O) removal (O) and (O) an (O) RMS-based (O) deverberation (O) method, (O) as (O) described (O) in. (O) 

System (O) Construction (O) 

For (O) each (O) of (O) the (O) 14 (O) languages (O) of (O) the (O) [Tundra (B) corpus (I)], a (O) [TTS (B) system (I)] was (O) trained (O) with (O) no (O) reliance (O) of (O) [language-specific (B) expertise (I)]. 
Although (O) speaker (O) and (O) recording (O) differences (O) mean (O) that (O) meaningful (O) comparison (O) between (O) languages (O) is (O) difficult, (O) we (O) wished (O) to (O) make (O) the (O) training (O) conditions (O) for (O) the (O) 14 (O) voices (O) as (O) uniform (O) as (O) possible. (O) 
Therefore, (O) we (O) selected (O) a (O) 1 (O) hour (O) subset (O) of (O) each (O) of (O) the (O) languages’ (O) data (O) on (O) which (O) to (O) train (O) voices (O) for (O) this (O) evaluation (O) : the (O) method (O) of (O) [data (B) selection (I)] we (O) used (O) is (O) explained (O) in (O) Section (O) 3.1. (O) 
Then (O) text (O) analysis (O) and (O) [waveform (B) generation (I)] components (O) were (O) trained (O) on (O) that (O) selected (O) data (O) as (O) explained (O) in (O) Sections (O) 3.2 (O) and (O) 3.3, (O) respectively. (O) 

[Lightly-supervised (B) data (I) selection (I)] 

Our (O) principal (O) current (O) interest (O) in (O) [audiobook (B) data (I)] is (O) that (O) it (O) presents (O) a (O) source (O) of (O) ‘ (O) found’ (O) data (O) from (O) which (O) [TTS (B) training (I) databases (I)] can (O) be (O) harvested (O) without (O) the (O) need (O) to (O) construct (O) a (O) recording (O) script, (O) recruit (O) a (O) [native (B) speaker (I)] of (O) the (O) [target (B) language (I)], and (O) supervise (O) the (O) recording (O) of (O) a (O) script (O) from (O) scratch. (O) 
In (O) the (O) present (O) work, (O) therefore, (O) we (O) ignore (O) the (O) other (O) possible (O) advantage (O) of (O) using (O) [audiobook (B) data (I)] : that (O) harnessing (O) the (O) variety (O) of (O) speaking (O) styles (O) present (O) in (O) audiobooks (O) might (O) enable (O) us (O) to (O) produce (O) less (O) ‘ (O) mechanical’-sounding (O) [TTS (B) systems (I)]. 
Although (O) this (O) is (O) a (O) longer-term (O) goal, (O) we (O) here (O) follow (O) an (O) approach (O) similar (O) to (O) the (O) one (O) presented (O) in, (O) which (O) aims (O) to (O) select (O) a (O) neutral (O) subset (O) of (O) a (O) database (O) containing (O) diverse (O) [speech (B)]. 
In (O) that (O) paper, (O) 9 (O) utterancelevel (O) [acoustic (B) features (I)] are (O) used (O) along (O) with (O) several (O) textual (O) cues (O) to (O) exclude (O) diverse (O) [speech (B)] from (O) the (O) training (O) set. (O) 
Thresholds (O) over (O) these (O) features (O) are (O) set (O) manually (O) by (O) the (O) system (O) builder (O) to (O) exclude (O) non-neutral (O) utterances. (O) 
For (O) the (O) current (O) work (O) we (O) perform (O) utterance (O) selection (O) using (O) an (O) active (O) learning (O) approach, (O) with (O) uncertainty (O) sampling. (O) 
Rather (O) than (O) being (O) required (O) to (O) tune (O) thresholds (O) manually, (O) the (O) system (O) builder (O) is (O) presented (O) with (O) example (O) utterances (O) and (O) asked (O) to (O) indicate (O) whether (O) or (O) not (O) they (O) are (O) spoken (O) in (O) a (O) neutral (O) style. (O) 
The (O) interface (O) therefore (O) insulates (O) the (O) user (O) from (O) the (O) details (O) of (O) the (O) features (O) used, (O) and (O) lets (O) the (O) user (O) focus (O) on (O) what (O) should (O) be (O) key (O) : their (O) intuitive (O) response (O) to (O) hearing (O) [speech (B) samples (I)]. 
The (O) procedure (O) we (O) used (O) is (O) as (O) follows (O) : 1) (O) [Feature (B) extraction (I)] First, (O) [frame-level (B) features (I)] (F (O) 0, (O) energy (O) and (O) [spectral (B) tilt (I)] – (O) approximated (O) by (O) 1st (O) [mel (B) cepstral (I) coefficient (I)]) are (O) obtained, (O) from (O) which (O) [utterance-level (B) features (I)] are (O) computed. (O) 
The (O) fact (O) that (O) no (O) thresholds (O) need (O) to (O) be (O) manually (O) tuned (O) means (O) that (O) we (O) can (O) afford (O) to (O) use (O) a (O) great (O) many (O) [more (B) features (I)] than (O) the (O) 9 (O) employed (O) in. (O) 
Our (O) feature (O) set (O) is (O) based (O) on (O) the (O) one (O) described (O) in (O) : we (O) compute (O) mean, (O) standard (O) deviation, (O) range, (O) slope, (O) minimum (O) and (O) maximum (O) (6-level (O) factor) (O) for (O) F (O) 0, (O) [spectral (B) tilt (I)], and (O) energy (O) (3-level (O) factor) (O) in (O) the (O) following (O) sub-segments (O) of (O) each (O) utterance (O) : entire (O) utterance, (O) 1st (O) and (O) 2nd (O) halfs, (O) all (O) 4 (O) quarters, (O) first (O) and (O) last (O) 100ms, (O) first (O) and (O) last (O) 200ms (O) (11-level (O) factor), (O) giving (O) a (O) total (O) of (O) 198 (O) features. (O) 
2) (O) Initial (O) labelling (O) The (O) user (O) is (O) presented (O) with (O) the (O) [audio (B)] of (O) s (O) randomly-selected (O) seed (O) utterances (O) from (O) the (O) [whole (B) corpus (I)] (via (O) a (O) text-based (O) user (O) interface) (O) and (O) asked (O) to (O) label (O) them (O) keep (O) or (O) discard (O) – (O) utterances (O) are (O) labelled (O) with (O) the (O) user’s (O) decision. (O) 
3) (O) Classifier (O) training (O) A (O) classifier (O) is (O) trained (O) on (O) the (O) labelled (O) examples. (O) 
Our (O) choice (O) of (O) classifier (O) is (O) a (O) bagged (O) ensemble (O) of (O) [decision (B) trees (I)] because (O) it (O) can (O) be (O) trained (O) quickly (O) (allowing (O) online (O) active (O) learning (O) in (O) real (O) time), (O) is (O) robust (O) against (O) [noisy (B) features (I)] and (O) able (O) to (O) accept (O) unnormalised (O) input (O) variables, (O) and (O) mixtures (O) of (O) discrete (O) and (O) continuous (O) input (O) variables (O) (allowing (O) a (O) great (O) many (O) different (O) [acoustic (B) features (I)] to (O) be (O) used, (O) and (O) different (O) types (O) of (O) features), (O) allows (O) the (O) space (O) of (O) utterances (O) to (O) be (O) partitioned (O) recursively (O) (enabling (O) complex (O) interactions (O) between (O) features (O) to (O) be (O) detected), (O) and (O) provides (O) robust (O) estimates (O) of (O) class (O) probabilities (O) (important (O) for (O) step (O) 4). (O) 
4) (O) Uncertainty (O) sampling (O) The (O) set (O) of (O) u (O) uncertain (O) examples (O) (utterances (O) about (O) which (O) the (O) classifier (O) is (O) most (O) uncertain (O) – (O) in (O) the (O) present (O) case, (O) the (O) utterances (O) which (O) have (O) closest (O) to (O) 0.5 (O) keep (O) probability). (O) 
The (O) utterances (O) in (O) this (O) set (O) are (O) presented (O) to (O) the (O) user (O) for (O) labelling. (O) 
5) (O) Steps (O) 3 (O) and (O) 4 (O) are (O) repeated (O) as (O) many (O) times (O) as (O) time (O) allows. (O) 
6) (O) The (O) set (O) of (O) utterances (O) either (O) labelled (O) keep (O) by (O) the (O) user (O) are (O) kept (O) for (O) training, (O) as (O) well (O) as (O) enough (O) of (O) the (O) utterances (O) to (O) which (O) the (O) trained (O) classifier (O) gives (O) the (O) highest (O) keep (O) probability (O) to, (O) to (O) make (O) up (O) the (O) desired (O) quantity (O) of (O) [training (B) data (I)]. 
For (O) the (O) work (O) presented (O) here, (O) s (O) was (O) set (O) to (O) 15 (O) and (O) u (O) was (O) set (O) to (O) 1. (O) 
That (O) is, (O) the (O) user (O) was (O) asked (O) to (O) provide (O) 15 (O) labels (O) at (O) the (O) outset, (O) and (O) presented (O) with (O) a (O) single (O) uncertain (O) example (O) at (O) each (O) iteration. (O) 
The (O) stopping (O) criterion (O) we (O) used (O) in (O) this (O) work (O) was (O) to (O) limit (O) the (O) number (O) of (O) iterations (O) to (O) 15 (O) – (O) in (O) the (O) present, (O) utterance (O) selection (O) time (O) was (O) limited (O) to (O) approximately (O) 20 (O) minutes (O) per (O) language, (O) and (O) 15 (O) was (O) found (O) to (O) be (O) a (O) reasonable (O) number (O) of (O) iterations (O) in (O) that (O) time. (O) 
Informal (O) comparison (O) suggested (O) the (O) approach (O) outlined (O) is (O) beneficial (O) for (O) this (O) task, (O) but (O) in (O) ongoing (O) work (O) we (O) are (O) testing (O) this (O) rigorously (O) and (O) comparing (O) uncertainty (O) sampling (O) with (O) random (O) sampling, (O) as (O) well (O) as (O) applying (O) our (O) active (O) learning (O) tool (O) to (O) other (O) [TTS (B) tasks (I)]. 

[Front-end (B) construction (I)] with (O) [unsupervised (B) learning (I)] 

The (O) [TTS (B) front-end (I) building (I) tools (I)] used (O) for (O) this (O) work (O) are (O) based (O) on (O) ideas (O) outlined (O) in (O) and (O) applied (O) to (O) Spanish (O) [TTS (B)] in. (O) 
Input (O) to (O) the (O) system (O) consists (O) of (O) the (O) [audio (B)] of (O) utterances (O) selected (O) as (O) described (O) in (O) Section (O) 3.1, (O) together (O) with (O) their (O) text (O) transcription (O) (aligned (O) at (O) the (O) utterance (O) level) (O) : in (O) the (O) present (O) case, (O) these (O) are (O) taken (O) from (O) the (O) [Tundra (B) corpus (I)], and (O) had (O) been (O) obtained (O) as (O) summarised (O) in (O) Section (O) 2. (O) 
As (O) an (O) additional (O) input, (O) 5 (O) million (O) words (O) of (O) running (O) [text (B) data (I)] were (O) obtained (O) from (O) Wikipedia (O) in (O) the (O) [target (B) languages (I)] for (O) construction (O) of (O) the (O) wordand (O) letterrepresentations (O) described (O) below. (O) 
Text (O) which (O) is (O) input (O) to (O) the (O) system (O) is (O) assumed (O) to (O) be (O) UTF-8 (O) encoded (O) : given (O) UTF-8 (O) text, (O) text (O) processing (O) is (O) fully (O) automatic (O) and (O) makes (O) use (O) of (O) a (O) theoretically (O) universal (O) resource (O) : the (O) [Unicode (B) database (I)]. 

Figure (O) : Use (O) of (O) a (O) letter (O) space (O) to (O) replace (O) [phonetic (B) knowledge (I)] in (O) [decision-tree (B) based (I) state (I)]-tying. 
Shown (O) here (O) are (O) 2 (O) dimensions (O) of (O) the (O) actual (O) letter (O) space (O) induced (O) in (O) training (O) the (O) Romanian (O) system (O) described (O) in (O) the (O) paper. (O) 
The (O) 3 (O) lines (O) bisecting (O) the (O) space (O) represent (O) the (O) 3 (O) questions (O) actually (O) asked (O) in (O) the (O) uppermost (O) fragment (O) (first (O) three (O) ‘ (O) generations’) (O) of (O) the (O) state-tying (O) [decision (B) tree (I)] for (O) the (O) central (O) state (O) of (O) the (O) model (O) for (O) [spectral (B) envelope (I) features (I)]. Letters (O) shown (O) in (O) black (O) are (O) ‘ (O) heard’ (O) by (O) the (O) system (O) (i.e. (O) are (O) present (O) in (O) the (O) transcriptions (O) of (O) the (O) [audio (B) training (I) data (I)]) but (O) ones (O) shown (O) in (O) grey (O) are (O) only (O) ‘ (O) seen’ (O) (i.e. (O) appear (O) only (O) in (O) textual (O) [training (B) data (I)]) and (O) are (O) mainly (O) foreign (O) language (O) letters. (O) 

Unicode (O) character (O) properties (O) are (O) used (O) to (O) tokenise (O) the (O) text (O) and (O) characterise (O) tokens (O) as (O) words, (O) whitespace, (O) punctuation (O) etc. (O) 
Our (O) modules (O) have (O) so (O) far (O) been (O) successfully (O) applied (O) to (O) a (O) variety (O) of (O) alphabetic (O) (Latin-based, (O) Cyrillic) (O) and (O) alphasyllabic (O) (Brahmic) (O) scripts. (O) 
Our (O) [front-ends (B)] currently (O) expect (O) text (O) without (O) abbreviations, (O) numerals, (O) and (O) symbols (O) (e.g. (O) for (O) currency) (O) which (O) require (O) expansion (O) ; however, (O) the (O) [lightly (B) supervised (I) learning (I)] of (O) modules (O) to (O) expand (O) such (O) non-standard (O) words (O) is (O) an (O) active (O) topic (O) of (O) research, (O) and (O) we (O) hope (O) to (O) integrate (O) such (O) modules (O) into (O) our (O) [toolkit (B)] in (O) the (O) near (O) future. (O) 
A (O) [letter-based (B) approach (I)] is (O) used, (O) in (O) which (O) the (O) names (O) of (O) letters (O) are (O) used (O) directly (O) as (O) the (O) names (O) of (O) [speech (B)] modelling (O) units (O) (in (O) place (O) of (O) the (O) [phonemes (B)] of (O) a (O) conventional (O) [front-end (B)]). 
This (O) has (O) given (O) good (O) results (O) for (O) languages (O) with (O) transparent (O) alphabetic (O) orthographies (O) such (O) as (O) Romanian, (O) Spanish (O) and (O) Finnish, (O) and (O) can (O) give (O) acceptable (O) results (O) even (O) for (O) languages (O) with (O) less (O) transparent (O) orthographies, (O) such (O) as (O) English. (O) 
The (O) induced (O) [front-ends (B) make (I) use (I)] of (O) no (O) expert-specified (O) categories (O) of (O) letter (O) and (O) word, (O) such (O) as (O) [phonetic (B) categories (I)] (vowel, (O) nasal, (O) approximant, (O) etc.) (O) and (O) [part (B) of (I) speech (I) categories (I)] (noun, (O) verb, (O) adjective, (O) etc.). (O) 
Instead, (O) features (O) that (O) are (O) designed (O) to (O) stand (O) in (O) for (O) such (O) expert (O) knowledge (O) but (O) which (O) are (O) derived (O) fully (O) automatically (O) from (O) the (O) distributional (O) analysis (O) of (O) unannotated (O) text (O) ([speech (B) transcriptions (I)] and (O) Wikipedia (O) text) (O) are (O) used. (O) 
The (O) distributional (O) analysis (O) is (O) conducted (O) via (O) [vector (B) space (I) models (I)] (VSMs) (O) ; the (O) VSM (O) was (O) originally (O) applied (O) to (O) the (O) characterisation (O) of (O) documents (O) for (O) purposes (O) of (O) Information (O) Retrieval. (O) 
VSMs (O) are (O) applied (O) to (O) [TTS (B)] in, (O) where (O) models (O) are (O) built (O) at (O) various (O) levels (O) of (O) analysis (O) (letter, (O) word (O) and (O) utterance) (O) from (O) large (O) bodies (O) of (O) unlabelled (O) text. (O) 
To (O) build (O) these (O) models, (O) [co-occurrence (B) statistics (I)] are (O) gathered (O) in (O) matrix (O) form (O) to (O) produce (O) high-dimensional (O) representations (O) of (O) the (O) distributional (O) behaviour (O) of (O) e.g. (O) word (O) and (O) letter (O) types (O) in (O) the (O) corpus. (O) 
[Lower-dimensional (B) representations (I)] are (O) obtained (O) by (O) approximately (O) factorising (O) the (O) matrix (O) of (O) raw (O) cooccurrence (O) counts (O) by (O) the (O) application (O) of (O) slim (O) singular (O) value (O) decomposition. (O) 
This (O) distributional (O) analysis (O) places (O) textual (O) objects (O) in (O) a (O) continuous-valued (O) space, (O) which (O) is (O) then (O) partitioned (O) by (O) [decision (B) tree (I)] questions (O) during (O) the (O) training (O) of (O) [TTS (B) system (I)] components (O) such (O) as (O) [acoustic (B) models (I)] for (O) synthesis (O) or (O) [decision (B) trees (I)] for (O) pause (O) prediction. (O) 
For (O) the (O) [present (B) voices (I)], a (O) VSM (O) of (O) letters (O) was (O) constructed (O) by (O) producing (O) a (O) matrix (O) of (O) counts (O) of (O) immediate (O) left (O) and (O) right (O) [co-occurrences (B)] of (O) each (O) letter (O) type, (O) and (O) from (O) this (O) matrix (O) a (O) 5-dimensional (O) space (O) was (O) produced (O) to (O) characterise (O) letters. (O) 
Token (O) [co-occurrence (B)] was (O) counted (O) with (O) the (O) nearest (O) left (O) and (O) right (O) neighbour (O) tokens (O) (excluding (O) whitespace (O) tokens) (O) ; [co-occurrence (B)] was (O) counted (O) with (O) the (O) most (O) frequent (O) 250 (O) tokens (O) in (O) the (O) corpus. (O) 
A (O) 10-dimensional (O) space (O) was (O) produced (O) to (O) characterise (O) tokens. (O) 
Two (O) dimensions (O) of (O) the (O) letter (O) space (O) induced (O) in (O) training (O) the (O) Romanian (O) system (O) are (O) shown (O) in (O) Figure (O) 1. (O) 
It (O) can (O) be (O) seen (O) that (O) in (O) these (O) dimensions (O) of (O) the (O) space, (O) vowel (O) and (O) consonant (O) symbols (O) are (O) clearly (O) separable. (O) 
When (O) a (O) [decision (B) tree (I)] for (O) clustering (O) [acoustic (B) model (I)] states (O) is (O) built (O) and (O) allowed (O) to (O) query (O) items’ (O) positions (O) in (O) these (O) 2 (O) dimensions, (O) it (O) can (O) use (O) all (O) partitions (O) of (O) the (O) space (O) orthogonal (O) to (O) its (O) axes. (O) 
A (O) [decision (B) tree (I)] question (O) such (O) as (O) Is (O) the (O) letter’s (O) value (O) in (O) VSM (O) dimension (O) 3 (O) < -0.03 (O) ? is (O) very (O) nearly (O) equivalent (O) to (O) a (O) question (O) based (O) on (O) [linguistic (B) knowledge (I)] such (O) as (O) Is (O) the (O) letter (O) a (O) consonant (O) ? The (O) categories (O) of (O) vowel (O) and (O) consonant (O) are (O) useful (O) for (O) clustering (O) [acoustic (B) models (I)], and (O) so (O) [decision (B) trees (I)] actually (O) built (O) using (O) this (O) space (O) use (O) such (O) partitions (O) of (O) the (O) space (O) : the (O) 3 (O) lines (O) shown (O) bisecting (O) the (O) space (O) in (O) the (O) figure (O) represent (O) the (O) 3 (O) questions (O) actually (O) asked (O) in (O) the (O) uppermost (O) fragment (O) (first (O) three (O) ‘ (O) generations’) (O) of (O) the (O) state-tying (O) [decision (B) tree (I)] for (O) the (O) central (O) state (O) of (O) the (O) model (O) for (O) [spectral (B) envelope (I) features (I)]. 
Distributional (O) analysis (O) places (O) linguistic (O) or (O) textual (O) units (O) in (O) a (O) continuous (O) space (O) which (O) is (O) then (O) partitioned (O) on (O) acoustic (O) evidence. (O) 
The (O) space (O) constrains (O) the (O) possible (O) groupings (O) of (O) objects (O) that (O) can (O) be (O) considered (O) during (O) [decision (B) tree (I)] growing. (O) 
Distributional (O) analysis (O) also (O) allows (O) splits (O) made (O) to (O) generalise (O) to (O) items (O) that (O) are (O) ‘ (O) seen’ (O) by (O) the (O) system (O) in (O) [text (B) data (I)] but (O) not (O) ‘ (O) heard’ (O) in (O) the (O) [audio (B) data (I)]. 
This (O) is (O) most (O) obviously (O) useful (O) where (O) units (O) such (O) as (O) words (O) are (O) concerned, (O) where (O) many (O) items (O) not (O) present (O) in (O) the (O) [training (B) speech (I) corpus (I)] are (O) likely (O) to (O) occur (O) at (O) run-time. (O) 
It (O) can, (O) however, (O) also (O) be (O) useful (O) where (O) letters (O) are (O) concerned, (O) and (O) some (O) examples (O) that (O) illustrate (O) our (O) models’ (O) ability (O) to (O) generalise (O) beyond (O) what (O) is (O) heard (O) can (O) be (O) seen (O) in (O) the (O) letter (O) space (O) shown (O) in (O) Figure (O) 1. (O) 
There, (O) letters (O) shown (O) in (O) black (O) are (O) ‘ (O) heard’ (O) by (O) the (O) system (O) but (O) ones (O) shown (O) in (O) grey (O) are (O) only (O) ‘ (O) seen’ (O) – (O) these (O) are (O) mainly (O) due (O) to (O) foreign (O) language (O) words (O) within (O) Romanian (O) Wikipedia (O) entries. (O) 
It (O) can (O) be (O) seen (O) that (O) unheard (O) foreign (O) vowels (O) such (O) as (O) á (O) and (O) ö (O) are (O) suitably (O) placed (O) near (O) the (O) Romanian (O) vowels, (O) and (O) unheard (O) consonants (O) such (O) as (O) ß (O) and (O) q (O) are (O) placed (O) near (O) the (O) consonants (O) that (O) are (O) actually (O) heard. (O) 
Splits (O) such (O) as (O) those (O) shown (O) – (O) made (O) only (O) on (O) the (O) basis (O) of (O) the (O) heard (O) items (O) – (O) therefore (O) generalise (O) to (O) unheard (O) items. (O) 
In (O) the (O) case (O) of (O) letters, (O) this (O) allows (O) rare (O) and (O) foreign (O) letters (O) to (O) be (O) handled (O) despite (O) their (O) absence (O) in (O) the (O) transcriptions (O) of (O) [acoustic (B) training (I) data (I)]. 
It (O) can (O) also (O) allow (O) better (O) handling (O) of (O) non-standard (O) spellings (O) : in (O) the (O) case (O) of (O) the (O) vowel (O) î (O) (i (O) with (O) circumflex), (O) there (O) is (O) a (O) variant (O) (with (O) inverted (O) breve (O) instead (O) of (O) circumflex) (O) which (O) is (O) not (O) present (O) in (O) any (O) of (O) the (O) [speech (B) transcriptions (I)] but (O) which (O) is (O) used (O) in (O) a (O) few (O) Wikipedia (O) articles. (O) 
From (O) Figure (O) 1 (O) it (O) can (O) be (O) seen (O) that (O) almost (O) identical (O) representations (O) are (O) learned (O) for (O) these (O) two (O) letters, (O) meaning (O) a (O) [decision (B) tree (I)] built (O) using (O) those (O) representations (O) will (O) be (O) able (O) to (O) handle (O) the (O) variant (O) form (O) correctly (O) at (O) run-time, (O) even (O) though (O) no (O) instances (O) of (O) that (O) variant (O) were (O) seen (O) in (O) the (O) transcription (O) of (O) the (O) [speech (B) training (I) corpus (I)]. 
The (O) front (O) ends (O) make (O) use (O) of (O) [decision (B) trees (I)] to (O) predict (O) pauses (O) at (O) the (O) junctures (O) between (O) words. (O) 
Data (O) for (O) training (O) these (O) trees (O) are (O) acquired (O) automatically (O) by (O) force-aligning (O) the (O) [training (B) data (I)] with (O) their (O) transcriptions, (O) and (O) allowing (O) the (O) optional (O) insertion (O) of (O) silence (O) between (O) words. (O) 
The (O) independent (O) variables (O) used (O) by (O) the (O) trees (O) are (O) whether (O) words (O) are (O) separated (O) by (O) punctuation (O) or (O) space, (O) and (O) the (O) [VSM (B) features (I)] of (O) the (O) tokens (O) preceding (O) and (O) following (O) the (O) juncture. (O) 
A (O) rich (O) set (O) of (O) contexts (O) is (O) created (O) using (O) the (O) results (O) of (O) the (O) analysis (O) described (O) here (O) for (O) each (O) letter (O) token (O) in (O) the (O) database. (O) 
Features (O) include (O) the (O) identity (O) of (O) the (O) letter (O) and (O) the (O) identities (O) of (O) its (O) neighbours (O) (within (O) a (O) 5-letter (O) window), (O) the (O) VSM (O) values (O) of (O) each (O) of (O) those (O) letters, (O) and (O) the (O) distance (O) from (O) and (O) until (O) a (O) word (O) boundary, (O) pause, (O) and (O) utterance (O) boundary. (O) 
In (O) the (O) current (O) systems, (O) word (O) [VSM (B) features (I)] are (O) not (O) included (O) directly (O) in (O) the (O) letter (O) contexts, (O) but (O) are (O) used (O) by (O) the (O) [decision (B) tree (I)] for (O) predicting (O) pauses (O) at (O) runtime. (O) 

[Back-end (B) construction (I)] 

For (O) training (O) the (O) [waveform (B) generation (I)] modules (O) for (O) the (O) 14 (O) voices, (O) the (O) [waveforms (B)] of (O) the (O) training (O) corpora (O) were (O) parameterised (O) almost (O) as (O) described (O) in. (O) 
The (O) one (O) difference (O) is (O) that (O) instead (O) of (O) the (O) committee (O) of (O) different (O) [pitch (B)]-trackers used (O) in (O) the (O) earlier (O) work, (O) [pitch (B) tracks (I)] obtained (O) from (O) a (O) glottal (O) source (O) signal (O) estimated (O) by (O) glottal (O) inverse (O) filtering (O) were (O) used (O) for (O) their (O) greater (O) accuracy. (O) 
For (O) all (O) systems, (O) speaker-dependent (O) [acoustic (B) models (I)] were (O) built (O) from (O) this (O) parameterised (O) [speech (B) data (I)] and (O) the (O) annotation (O) described (O) in (O) Section (O) 3.2, (O) using (O) the (O) speaker-dependent (O) modelbuilding (O) recipe (O) described (O) in. (O) 
Static (O) and (O) interactive (O) demos (O) of (O) the (O) resulting (O) voices (O) are (O) available (O) at (O) http://tundra.simple4all.org/demo. (O) 
A (O) screen (O) shot (O) of (O) the (O) geographically-organised (O) demo (O) page (O) is (O) shown (O) in (O) Figure (O) 2. (O) 

Figure (O) : Demo (O) screenshot (O) : this (O) geographical (O) interface (O) to (O) voices (O) can (O) be (O) found (O) at (O) http://tundra.simple4all.org/demo. (O) 

System (O) Evaluation (O) 

Procedure (O) 

We (O) are (O) primarily (O) interested (O) in (O) having (O) our (O) systems (O) produce (O) [intelligible (B) speech (I)] ; evaluation (O) therefore (O) focused (O) on (O) the (O) intelligibility (O) of (O) [TTS (B) output (I)] as (O) measured (O) by (O) the (O) word (O) and (O) letter (O) error (O) rates (O) of (O) listeners’ (O) transcriptions (O) of (O) those (O) outputs. (O) 
Conventionally (O) in (O) [TTS (B) evaluation (I)], listeners (O) are (O) asked (O) to (O) transcribe (O) semantically (O) unpredictable (O) sentences (O) (SUS). (O) 
However, (O) such (O) SUS (O) are (O) not (O) currently (O) available (O) in (O) all (O) the (O) [Tundra (B)] languages (O) and (O) it (O) is (O) not (O) trivial (O) to (O) construct (O) new (O) SUS, (O) and (O) so (O) we (O) resorted (O) to (O) using (O) short (O) natural (O) sentences (O) from (O) the (O) held-out (O) test (O) sets (O) of (O) the (O) [Tundra (B) corpus (I)]. 
For (O) all (O) 14 (O) [Tundra (B)] languages, (O) 40 (O) sentences (O) were (O) manually (O) segmented (O) from (O) the (O) held-out (O) chapters (O) of (O) the (O) relevant (O) audiobook. (O) 
Note (O) that (O) these (O) test (O) sets (O) are (O) distributed (O) with (O) the (O) [Tundra (B) corpus (I)], and (O) so (O) the (O) results (O) presented (O) below (O) can (O) be (O) considered (O) benchmarks (O) for (O) future (O) work. (O) 
An (O) attempt (O) was (O) made (O) to (O) select (O) sentences (O) of (O) 6–8 (O) words (O) in (O) order (O) to (O) make (O) the (O) inherent (O) difficulty (O) of (O) transcription (O) as (O) uniform (O) as (O) possible. (O) 
However, (O) in (O) some (O) languages (O) these (O) thresholds (O) had (O) to (O) be (O) relaxed (O) ; Table (O) 1 (O) gives (O) statistics (O) of (O) test-sentence (O) lengths (O) in (O) all (O) languages. (O) 
Subjects (O) for (O) the (O) evaluation (O) were (O) recruited (O) through (O) a (O) webbased (O) crowdsourcing (O) service. (O) 
The (O) advert (O) for (O) the (O) evaluation (O) specified (O) that (O) [native (B) speakers (I)] of (O) the (O) relevant (O) language (O) were (O) required (O) ; in (O) addition, (O) participation (O) in (O) each (O) part (O) of (O) the (O) evaluation (O) was (O) restricted (O) to (O) users (O) registered (O) in (O) countries (O) where (O) the (O) relevant (O) language (O) is (O) an (O) official (O) or (O) majority (O) language. (O) 
We (O) attempted (O) to (O) recruit (O) listeners (O) to (O) evaluate (O) all (O) 14 (O) systems (O) built. (O) 
However, (O) as (O) the (O) option (O) to (O) restrict (O) participation (O) to (O) workers (O) registered (O) in (O) Denmark, (O) Finland (O) and (O) Hungary (O) was (O) not (O) available (O) in (O) the (O) service (O) we (O) used, (O) listening (O) test (O) for (O) only (O) 11 (O) of (O) the (O) systems (O) were (O) publicised. (O) 
The (O) number (O) of (O) responses (O) from (O) participants (O) varied (O) greatly (O) between (O) languages. (O) 
At (O) the (O) time (O) of (O) writing, (O) responses (O) from (O) a (O) sufficient (O) number (O) of (O) listeners (O) (25 (O) +) (O) had (O) been (O) collected (O) in (O) only (O) 5 (O) of (O) the (O) languages (O) (Bulgarian, (O) English, (O) Italian, (O) Polish (O) and (O) Romanian). (O) 
Results (O) for (O) these (O) five (O) languages (O) are (O) presented (O) here (O) ; evaluation (O) of (O) the (O) remaining (O) voices (O) is (O) left (O) for (O) future (O) work. (O) 
In (O) all (O) languages, (O) two (O) conditions (O) were (O) evaluated (O) : the (O) natural (O) [speech (B)] of (O) the (O) natural (O) sentences (O) from (O) the (O) test (O) set, (O) and (O) the (O) [TTS (B) system (I)] reading (O) the (O) same (O) text. (O) 

Table (O) : Statistics (O) of (O) [Tundra (B) test (I)]-sentence lengths (O) (number (O) of (O) words) (O) 

In (O) the (O) four (O) languages (O) of (O) the (O) [Simple4All (B)] consortium (O) members (O) (including (O) two (O) of (O) the (O) languages (O) for (O) which (O) results (O) are (O) presented (O) here (O) : Romanian (O) and (O) English), (O) however, (O) SUS (O) were (O) available, (O) and (O) so (O) for (O) those (O) languages (O) a (O) third (O) condition (O) was (O) evaluated (O) : the (O) [TTS (B) system (I)] producing (O) SUS (O) texts. (O) 
This (O) is (O) designed (O) to (O) provide (O) a (O) way (O) of (O) broadly (O) gauging (O) the (O) relative (O) difficulty (O) of (O) transcribing (O) natural (O) and (O) SUS (O) sentences, (O) although (O) language (O) and (O) text (O) differences (O) mean (O) it (O) is (O) obviously (O) not (O) advisable (O) to (O) treat (O) extrapolation (O) of (O) the (O) differences (O) to (O) the (O) remaining (O) languages (O) with (O) any (O) great (O) confidence. (O) 
The (O) evaluation (O) was (O) run (O) as (O) a (O) set (O) of (O) webpages (O) where (O) participants (O) were (O) asked (O) – (O) using (O) headphones (O) – (O) to (O) listen (O) to (O) the (O) samples (O) and (O) to (O) type (O) in (O) what (O) they (O) heard. (O) 
Multiple (O) listens (O) were (O) allowed (O) as (O) some (O) of (O) the (O) the (O) natural (O) sentences (O) were (O) longer (O) than (O) the (O) short (O) SUS (O) we (O) would (O) typically (O) use. (O) 
For (O) the (O) first (O) two (O) conditions, (O) a (O) balanced (O) design (O) was (O) used (O) so (O) that (O) each (O) listener (O) heard (O) each (O) utterance (O) text (O) only (O) once, (O) while (O) each (O) text (O) was (O) heard (O) an (O) equal (O) number (O) of (O) times (O) in (O) both (O) conditions (O) over (O) the (O) whole (O) evaluation. (O) 
Each (O) listener (O) heard (O) 20 (O) sentences (O) spoken (O) in (O) each (O) condition. (O) 
For (O) English (O) and (O) Romanian (O) where (O) the (O) SUS (O) condition (O) was (O) also (O) included, (O) listeners (O) heard (O) a (O) further (O) set (O) of (O) 20 (O) SUS (O) sentences. (O) 

Results (O) 

[Word (B) error (I) rates (I)] for (O) the (O) first (O) 2 (O) conditions (O) are (O) shown (O) in (O) Figure (O) 3. (O) 
For (O) all (O) languages (O) besides (O) English, (O) a (O) similar (O) pattern (O) can (O) be (O) observed (O) : listeners’ (O) transcriptions (O) of (O) natural (O) [speech (B)] attain (O) a (O) [WER (B)] of (O) 8–12 (O) %, (O) and (O) in (O) all (O) cases (O) the (O) [TTS (B) system (I)] attain (O) [WERs (B)] approximately (O) 1.5 (O) times (O) worse. (O) 
This (O) is (O) consistent (O) with (O) the (O) difference (O) between (O) [WERs (B)] for (O) natural (O) [speech (B)] and (O) decent (O) benchmark (O) systems (O) in (O) larger (O) scale (O) evaluations (O) on (O) standard (O) corpora. (O) 
For (O) example, (O) natural (O) [speech (B)] and (O) the (O) Festival (O) benchmark (O) system (O) attained (O) [WERs (B)] of (O) 17 (O) % and (O) 25 (O) % respectively (O) in (O) the (O) 2011 (O) [Blizzard (B) Challenge (I) evaluation (I)]. 
The (O) results (O) for (O) English (O) are (O) the (O) exception (O) to (O) the (O) general (O) pattern (O) : the (O) [WER (B)] for (O) [synthetic (B) speech (I)] is (O) over (O) 4 (O) times (O) worse (O) than (O) that (O) of (O) natural (O) [speech (B)]. 
From (O) prior (O) knowledge (O) and (O) from (O) looking (O) at (O) listeners’ (O) transcriptions, (O) it (O) seems (O) clear (O) that (O) this (O) is (O) due (O) to (O) the (O) fact (O) that (O) [TTS (B)] is (O) based (O) on (O) letters (O) in (O) a (O) language (O) with (O) such (O) an (O) opaque (O) [letter-to-sound (B) relationship (I)]. 
In (O) all (O) languages (O) except (O) Polish, (O) the (O) difference (O) between (O) the (O) first (O) two (O) conditions (O) (natural (O) [speech (B)] and (O) [TTS (B)]) found (O) to (O) be (O) statistically (O) significant (O) (with (O) α (O) = 0.05) (O) using (O) the (O) bootstrap (O) procedure (O) of. (O) 
As (O) expected, (O) [WERs (B)] for (O) the (O) SUS (O) sentences (O) are (O) much (O) higher (O) than (O) those (O) for (O) natural (O) sentences (O) : 24.8 (O) % and (O) 69.4 (O) % for (O) Romanian (O) and (O) English, (O) respectively. (O) 

Figure (O) : [Word (B) error (I) rates (I)] for (O) [TTS (B) systems (I)] and (O) natural (O) [speech (B)] for (O) 5 (O) of (O) the (O) 14 (O) systems (O) built (O) from (O) the (O) [Tundra (B) corpus (I)]. 

Conclusions (O) 

We (O) have (O) presented (O) tools (O) for (O) building (O) [TTS (B) front-ends (I)] in (O) a (O) way (O) that (O) exploits (O) unsupervised (O) learning (O) techniques (O) to (O) side-step (O) the (O) need (O) for (O) [language-specific (B) expert (I) knowledge (I)] and (O) resources (O) such (O) as (O) [pronunciation (B) lexicons (I)], [phoneme (B)] inventories (O) and (O) [part (B) of (I) speech (I) taggers (I)]. 
We (O) have (O) shown (O) how (O) the (O) tools (O) were (O) applied (O) to (O) the (O) languages (O) of (O) the (O) [Tundra (B) corpus (I)] to (O) produce (O) [TTS (B) systems (I)] in (O) 14 (O) languages. (O) 
As (O) we (O) had (O) previously (O) built (O) the (O) [Tundra (B) corpus (I)] from (O) found (O) data (O) using (O) minimal (O) supervision (O) and (O) language (O) specific (O) knowledge, (O) these (O) [TTS (B) systems (I)] represent (O) the (O) output (O) of (O) our (O) entire (O) pipeline (O) of (O) tools, (O) and (O) show (O) the (O) type (O) of (O) voice (O) which (O) any (O) interested (O) developer (O) should (O) be (O) able (O) to (O) build (O) using (O) our (O) [toolkit (B)] (which (O) will (O) be (O) made (O) freely (O) available) (O) despite (O) a (O) lack (O) of (O) [language-specific (B)] or (O) [speech (B) technology (I) expertise (I)], if (O) a (O) source (O) of (O) [speech (B) and (I) text (I) data (I)] can (O) be (O) found. (O) 
Five (O) of (O) the (O) voices (O) were (O) evaluated (O) in (O) a (O) listening (O) test (O) for (O) intelligibility, (O) which (O) we (O) consider (O) to (O) show (O) that (O) systems (O) of (O) reasonable (O) quality (O) can (O) be (O) built (O) by (O) applying (O) our (O) tools (O) to (O) publicly (O) available (O) [audiobook (B) data (I)], assuming (O) orthographies (O) of (O) similar (O) transparency (O) to (O) those (O) of (O) Bulgarian, (O) Italian, (O) Polish (O) and (O) Romanian. (O) 
While (O) evaluation (O) of (O) the (O) remaining (O) systems (O) that (O) can (O) be (O) heard (O) in (O) the (O) demo (O) is (O) still (O) ongoing, (O) the (O) results (O) for (O) five (O) languages (O) published (O) here (O) – (O) having (O) been (O) obtained (O) from (O) a (O) standardised, (O) publicly (O) [available (B) corpus (I)] – (O) are (O) intended (O) to (O) be (O) useful (O) benchmarks (O) against (O) which (O) future (O) work (O) can (O) be (O) compared. (O) 
