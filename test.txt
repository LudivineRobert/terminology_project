Abstract: Grapheme-to-phoneme conversion is the process of generating pronunciation for words based on their written form.
It has a highly essential role for natural language processing, text-to-speech synthesis and automatic speech recognition systems.
In this paper, we investigate convolutional neural networks (CNN) for G2P conversion.
We propose a novel CNN-based sequence-to-sequence (seq2seq) architecture for G2P conversion.
Our approach includes an end-to-end CNN G2P conversion with residual connections and, furthermore, a model that utilizes a convolutional neural network (with and without residual connections) as encoder and Bi-LSTM as a decoder.
We compare our approach with state-of-the-art methods, including Encoder-Decoder LSTM and Encoder-Decoder Bi-LSTM.
Training and inference times, phoneme and word error rates were evaluated on the public CMUDict dataset for US English, and the best performing convolutional neural network-based architecture was also evaluated on the NetTalk dataset.
Our method approaches the accuracy of previous state-of-the-art results in terms of phoneme error rate.
Keywords: grapheme-to-phoneme (G2P); encoder-decoder; LSTM; 1D convolution; Bi-LSTM; residual architecture



Introduction 
The process of grapheme-to-phoneme (G2P) conversion generates a phonetic transcription from the written form of words.
The spelling of a word is called a grapheme sequence (or graphemes), the phonetic form is called a phoneme sequence (or phonemes).
It is essential to develop a phonemic lexicon in text-to-speech (TTS) and automatic speech recognition (ASR) systems.
For this purpose, G2P techniques are used, and getting state-of-the-art performance in these systems depends on the accuracy of G2P conversion.
For instance, in ASR acoustic models, the pronunciation lexicons and language models are critical components.
Acoustic and language models are built automatically from large corpora.
Pronunciation lexicons are the middle layer between acoustic and language models.
For a new speech recognition task, the performance of the overall system depends on the quality of the pronunciation component.
In other words, the system’s performance depends on G2P accuracy.
For example, the G2P conversion of word ‘speaker’ is ‘S P IY K ER’.
In TTS systems, a high-quality G2P model is also an essential part and has a great influence on the overall quality.
Inaccurate G2P conversion results in unnatural pronunciation or even incomprehensible synthetic speech.
